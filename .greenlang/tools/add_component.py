#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Component Addition Tool

Add components to existing GreenLang applications.
Supports agents, LLM integration, caching, databases, and monitoring.
"""

import argparse
import os
import sys
from pathlib import Path
from typing import Dict, Any, Optional


class ComponentGenerator:
    """Generate components for existing applications."""

    @staticmethod
    def generate_agent(name: str, template: str = 'basic') -> str:
        """Generate agent code."""

        templates = {
            'basic': {
                'llm': False,
                'cache': False,
                'description': 'Basic agent with validation'
            },
            'calculator': {
                'llm': False,
                'cache': True,
                'description': 'Calculator agent with caching'
            },
            'llm-analyzer': {
                'llm': True,
                'cache': True,
                'description': 'LLM-powered analysis agent'
            },
            'validator': {
                'llm': False,
                'cache': False,
                'description': 'Data validation agent'
            }
        }

        config = templates.get(template, templates['basic'])

        imports = ['from shared.infrastructure.agents import BaseAgent']

        if config['llm']:
            imports.append('from shared.infrastructure.llm import ChatSession')
        if config['cache']:
            imports.append('from shared.infrastructure.cache import CacheManager')

        imports.extend([
            'from shared.infrastructure.logging import Logger',
            'from typing import Dict, Any'
        ])

        return f'''"""
{name}

{config['description']}

Generated by GreenLang Component Generator
"""

{chr(10).join(imports)}


class {name}(BaseAgent):
    """
    {name} - {config['description']}
    """

    def __init__(self):
        """Initialize agent."""
        super().__init__()
        self.logger = Logger(name=__name__)
{'        self.chat_session = ChatSession(provider="openai", model="gpt-4")' if config['llm'] else ''}
{'        self.cache = CacheManager(ttl=3600)' if config['cache'] else ''}

    def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute the agent.

        Args:
            input_data: Input data dictionary

        Returns:
            Result dictionary
        """
        self.logger.info(f"Executing {{self.__class__.__name__}}", extra={{"input": input_data}})

        # Validate input
        if not self.validate_input(input_data):
            return {{
                "status": "error",
                "error": "Invalid input data"
            }}

        try:
            # Process data
            result = self._process(input_data)

            self.logger.info("Execution completed successfully")
            return {{
                "status": "success",
                "result": result
            }}

        except Exception as e:
            self.logger.error(f"Execution failed: {{e}}", exc_info=True)
            return {{
                "status": "error",
                "error": str(e)
            }}

    def _process(self, data: Dict[str, Any]) -> Any:
        """
        Core processing logic.

        Args:
            data: Input data

        Returns:
            Processed result
        """
        # TODO: Implement processing logic

        result = {{
            "processed": True,
            "data": data
        }}

        return result

    def validate_input(self, input_data: Dict[str, Any]) -> bool:
        """
        Validate input data.

        Args:
            input_data: Data to validate

        Returns:
            True if valid
        """
        required_fields = ["data"]

        for field in required_fields:
            if field not in input_data:
                self.logger.error(f"Missing required field: {{field}}")
                return False

        return True

    def validate_output(self, output_data: Dict[str, Any]) -> bool:
        """
        Validate output data.

        Args:
            output_data: Data to validate

        Returns:
            True if valid
        """
        return "result" in output_data
'''

    @staticmethod
    def generate_test(agent_name: str) -> str:
        """Generate test file for agent."""

        return f'''"""
Tests for {agent_name}

Generated by GreenLang Component Generator
"""

import pytest
from app.agents.{agent_name.lower()} import {agent_name}


class Test{agent_name}:
    """Test suite for {agent_name}."""

    @pytest.fixture
    def agent(self):
        """Create agent instance."""
        return {agent_name}()

    def test_execute_success(self, agent):
        """Test successful execution."""
        input_data = {{
            "data": "test input"
        }}

        result = agent.execute(input_data)

        assert result["status"] == "success"
        assert "result" in result

    def test_execute_invalid_input(self, agent):
        """Test execution with invalid input."""
        input_data = {{}}

        result = agent.execute(input_data)

        assert result["status"] == "error"

    def test_validate_input(self, agent):
        """Test input validation."""
        valid_data = {{"data": "valid"}}
        assert agent.validate_input(valid_data) is True

        invalid_data = {{}}
        assert agent.validate_input(invalid_data) is False

    def test_batch_execute(self, agent):
        """Test batch execution."""
        batch_data = [
            {{"data": "input1"}},
            {{"data": "input2"}},
            {{"data": "input3"}}
        ]

        results = agent.batch_execute(batch_data)

        assert len(results) == 3
        assert all(r["status"] == "success" for r in results)
'''

    @staticmethod
    def add_llm_to_requirements() -> str:
        """Get LLM requirements."""
        return '''
# LLM Integration
openai>=1.0.0
anthropic>=0.18.0
'''

    @staticmethod
    def add_cache_to_requirements(cache_type: str) -> str:
        """Get cache requirements."""
        if cache_type == 'redis':
            return '''
# Caching
redis>=5.0.0
'''
        return ''

    @staticmethod
    def add_database_to_requirements(db_type: str) -> str:
        """Get database requirements."""
        if db_type == 'postgresql':
            return '''
# Database
sqlalchemy>=2.0.0
psycopg2-binary>=2.9.0
'''
        elif db_type == 'mongodb':
            return '''
# Database
pymongo>=4.0.0
'''
        return ''

    @staticmethod
    def add_monitoring_to_requirements() -> str:
        """Get monitoring requirements."""
        return '''
# Monitoring
prometheus-client>=0.18.0
'''


class ComponentAdder:
    """Add components to existing applications."""

    def __init__(self, app_dir: str = '.'):
        self.app_dir = Path(app_dir)
        self.generator = ComponentGenerator()

        # Verify it's a GreenLang app
        if not (self.app_dir / 'app').exists():
            raise ValueError(f"Not a GreenLang application: {app_dir}")

    def add_agent(self, name: str, template: str = 'basic'):
        """Add an agent to the application."""

        print(f"\nAdding agent: {name}")
        print(f"Template: {template}\n")

        # Generate agent file
        agent_code = self.generator.generate_agent(name, template)
        agent_file = self.app_dir / 'app' / 'agents' / f'{name.lower()}.py'

        if agent_file.exists():
            overwrite = input(f"Agent {name} already exists. Overwrite? (y/n): ")
            if overwrite.lower() != 'y':
                print("Cancelled.")
                return

        agent_file.write_text(agent_code, encoding='utf-8')
        print(f"Created: {agent_file}")

        # Generate test file
        test_code = self.generator.generate_test(name)
        test_file = self.app_dir / 'tests' / f'test_{name.lower()}.py'
        test_file.write_text(test_code, encoding='utf-8')
        print(f"Created: {test_file}")

        print(f"\nAgent {name} added successfully!")
        print(f"\nNext steps:")
        print(f"  1. Implement processing logic in _process() method")
        print(f"  2. Customize validation in validate_input() method")
        print(f"  3. Run tests: pytest tests/test_{name.lower()}.py -v")

    def add_llm(self, provider: str = 'openai', caching: bool = False):
        """Add LLM integration to the application."""

        print(f"\nAdding LLM integration")
        print(f"Provider: {provider}")
        print(f"Caching: {caching}\n")

        # Update requirements.txt
        requirements_file = self.app_dir / 'requirements.txt'
        current_reqs = requirements_file.read_text() if requirements_file.exists() else ''

        if 'openai' not in current_reqs and 'anthropic' not in current_reqs:
            new_reqs = current_reqs + self.generator.add_llm_to_requirements()
            requirements_file.write_text(new_reqs, encoding='utf-8')
            print("Updated: requirements.txt")

        # Update .env.example
        env_example = self.app_dir / '.env.example'
        if env_example.exists():
            current_env = env_example.read_text()

            if provider == 'openai' and 'OPENAI_API_KEY' not in current_env:
                new_env = current_env + '\n# LLM Configuration\n'
                new_env += 'LLM_PROVIDER=openai\n'
                new_env += 'LLM_MODEL=gpt-4\n'
                new_env += 'OPENAI_API_KEY=your-api-key\n'
                new_env += 'LLM_TEMPERATURE=0.7\n'
                env_example.write_text(new_env, encoding='utf-8')
                print("Updated: .env.example")

        print(f"\nLLM integration added successfully!")
        print(f"\nNext steps:")
        print(f"  1. pip install -r requirements.txt")
        print(f"  2. Add {provider.upper()}_API_KEY to .env file")
        print(f"  3. Use ChatSession in your agents")

    def add_cache(self, cache_type: str = 'redis'):
        """Add caching to the application."""

        print(f"\nAdding caching")
        print(f"Type: {cache_type}\n")

        # Update requirements.txt
        if cache_type == 'redis':
            requirements_file = self.app_dir / 'requirements.txt'
            current_reqs = requirements_file.read_text() if requirements_file.exists() else ''

            if 'redis' not in current_reqs:
                new_reqs = current_reqs + self.generator.add_cache_to_requirements(cache_type)
                requirements_file.write_text(new_reqs, encoding='utf-8')
                print("Updated: requirements.txt")

        # Update .env.example
        env_example = self.app_dir / '.env.example'
        if env_example.exists():
            current_env = env_example.read_text()

            if 'CACHE_TYPE' not in current_env:
                new_env = current_env + '\n# Cache Configuration\n'
                new_env += f'CACHE_TYPE={cache_type}\n'
                new_env += 'CACHE_TTL=3600\n'
                if cache_type == 'redis':
                    new_env += 'REDIS_URL=redis://localhost:6379\n'
                env_example.write_text(new_env, encoding='utf-8')
                print("Updated: .env.example")

        # Update docker-compose.yml if it exists
        if cache_type == 'redis':
            docker_compose = self.app_dir / 'docker-compose.yml'
            if docker_compose.exists():
                current_compose = docker_compose.read_text()
                if 'redis' not in current_compose:
                    # Add Redis service
                    new_compose = current_compose.rstrip() + '''

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
'''
                    docker_compose.write_text(new_compose, encoding='utf-8')
                    print("Updated: docker-compose.yml")

        print(f"\nCaching added successfully!")
        print(f"\nNext steps:")
        print(f"  1. pip install -r requirements.txt")
        if cache_type == 'redis':
            print(f"  2. Start Redis: docker-compose up redis -d")
            print(f"  3. Add REDIS_URL to .env file")
        print(f"  4. Use CacheManager in your agents")

    def add_database(self, db_type: str = 'postgresql'):
        """Add database to the application."""

        print(f"\nAdding database")
        print(f"Type: {db_type}\n")

        # Update requirements.txt
        requirements_file = self.app_dir / 'requirements.txt'
        current_reqs = requirements_file.read_text() if requirements_file.exists() else ''

        if db_type == 'postgresql' and 'sqlalchemy' not in current_reqs:
            new_reqs = current_reqs + self.generator.add_database_to_requirements(db_type)
            requirements_file.write_text(new_reqs, encoding='utf-8')
            print("Updated: requirements.txt")

        # Update .env.example
        env_example = self.app_dir / '.env.example'
        if env_example.exists():
            current_env = env_example.read_text()

            if 'DATABASE_URL' not in current_env:
                new_env = current_env + '\n# Database Configuration\n'
                if db_type == 'postgresql':
                    new_env += 'DATABASE_URL=postgresql://user:password@localhost:5432/dbname\n'
                elif db_type == 'mongodb':
                    new_env += 'DATABASE_URL=mongodb://localhost:27017/dbname\n'
                new_env += 'DB_POOL_SIZE=10\n'
                env_example.write_text(new_env, encoding='utf-8')
                print("Updated: .env.example")

        # Update docker-compose.yml
        docker_compose = self.app_dir / 'docker-compose.yml'
        if docker_compose.exists():
            current_compose = docker_compose.read_text()

            if db_type == 'postgresql' and 'postgres' not in current_compose:
                new_compose = current_compose.rstrip() + '''

  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: greenlang
      POSTGRES_PASSWORD: greenlang
      POSTGRES_DB: greenlang
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  postgres_data:
'''
                docker_compose.write_text(new_compose, encoding='utf-8')
                print("Updated: docker-compose.yml")

        print(f"\nDatabase added successfully!")
        print(f"\nNext steps:")
        print(f"  1. pip install -r requirements.txt")
        print(f"  2. Start database: docker-compose up {db_type} -d")
        print(f"  3. Add DATABASE_URL to .env file")
        print(f"  4. Create database models and migrations")

    def add_monitoring(self, dashboard: str = 'grafana'):
        """Add monitoring to the application."""

        print(f"\nAdding monitoring")
        print(f"Dashboard: {dashboard}\n")

        # Update requirements.txt
        requirements_file = self.app_dir / 'requirements.txt'
        current_reqs = requirements_file.read_text() if requirements_file.exists() else ''

        if 'prometheus' not in current_reqs:
            new_reqs = current_reqs + self.generator.add_monitoring_to_requirements()
            requirements_file.write_text(new_reqs, encoding='utf-8')
            print("Updated: requirements.txt")

        # Create monitoring directory
        monitoring_dir = self.app_dir / 'monitoring'
        monitoring_dir.mkdir(exist_ok=True)

        # Create prometheus config
        prometheus_config = monitoring_dir / 'prometheus.yml'
        prometheus_config.write_text('''global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'greenlang-app'
    static_configs:
      - targets: ['app:9090']
''', encoding='utf-8')
        print("Created: monitoring/prometheus.yml")

        # Update docker-compose.yml
        docker_compose = self.app_dir / 'docker-compose.yml'
        if docker_compose.exists():
            current_compose = docker_compose.read_text()

            if 'prometheus' not in current_compose:
                new_compose = current_compose.rstrip() + '''

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana

volumes:
  grafana_data:
'''
                docker_compose.write_text(new_compose, encoding='utf-8')
                print("Updated: docker-compose.yml")

        print(f"\nMonitoring added successfully!")
        print(f"\nNext steps:")
        print(f"  1. pip install -r requirements.txt")
        print(f"  2. Start monitoring: docker-compose up prometheus grafana -d")
        print(f"  3. Access Prometheus: http://localhost:9090")
        print(f"  4. Access Grafana: http://localhost:3000 (admin/admin)")


def main():
    """CLI entry point."""
    parser = argparse.ArgumentParser(
        description='Add components to GreenLang applications',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Add an agent
  greenlang add agent DataProcessorAgent --template calculator

  # Add LLM integration
  greenlang add llm --provider openai --caching

  # Add caching
  greenlang add cache --type redis

  # Add database
  greenlang add database --type postgresql

  # Add monitoring
  greenlang add monitoring --dashboard grafana
        """
    )

    subparsers = parser.add_subparsers(dest='component', help='Component to add')

    # Agent
    agent_parser = subparsers.add_parser('agent', help='Add an agent')
    agent_parser.add_argument('name', help='Agent name')
    agent_parser.add_argument('--template', choices=['basic', 'calculator', 'llm-analyzer', 'validator'],
                              default='basic', help='Agent template')
    agent_parser.add_argument('--app-dir', default='.', help='Application directory')

    # LLM
    llm_parser = subparsers.add_parser('llm', help='Add LLM integration')
    llm_parser.add_argument('--provider', choices=['openai', 'anthropic'], default='openai', help='LLM provider')
    llm_parser.add_argument('--caching', action='store_true', help='Enable caching')
    llm_parser.add_argument('--app-dir', default='.', help='Application directory')

    # Cache
    cache_parser = subparsers.add_parser('cache', help='Add caching')
    cache_parser.add_argument('--type', choices=['memory', 'redis'], default='redis', help='Cache type')
    cache_parser.add_argument('--app-dir', default='.', help='Application directory')

    # Database
    db_parser = subparsers.add_parser('database', help='Add database')
    db_parser.add_argument('--type', choices=['postgresql', 'mongodb'], default='postgresql', help='Database type')
    db_parser.add_argument('--app-dir', default='.', help='Application directory')

    # Monitoring
    monitoring_parser = subparsers.add_parser('monitoring', help='Add monitoring')
    monitoring_parser.add_argument('--dashboard', choices=['grafana', 'prometheus'], default='grafana',
                                    help='Dashboard type')
    monitoring_parser.add_argument('--app-dir', default='.', help='Application directory')

    args = parser.parse_args()

    if not args.component:
        parser.print_help()
        sys.exit(1)

    try:
        adder = ComponentAdder(args.app_dir)

        if args.component == 'agent':
            adder.add_agent(args.name, args.template)
        elif args.component == 'llm':
            adder.add_llm(args.provider, args.caching)
        elif args.component == 'cache':
            adder.add_cache(args.type)
        elif args.component == 'database':
            adder.add_database(args.type)
        elif args.component == 'monitoring':
            adder.add_monitoring(args.dashboard)

    except Exception as e:
        print(f"\nError: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()
