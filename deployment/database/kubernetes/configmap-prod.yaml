# =============================================================================
# PostgreSQL/TimescaleDB ConfigMap - Production Environment
# =============================================================================
# Optimized resource settings for production workloads
# Optimized for: 32GB+ RAM, 8+ CPU cores, NVMe/SSD storage
# High Availability with streaming replication
# =============================================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgresql-config-prod
  namespace: greenlang-prod
  labels:
    app: postgresql
    environment: production
    tier: database
    managed-by: greenlang-devops
  annotations:
    description: "PostgreSQL configuration for production environment"
    last-updated: "2026-02-03"
    config-version: "v1.0.0"
data:
  # Main PostgreSQL configuration
  postgresql.conf: |
    # =============================================================================
    # PostgreSQL Production Configuration
    # =============================================================================
    # Optimized for: 32GB RAM, 8 CPU cores, NVMe storage
    # High availability with streaming replication
    # =============================================================================

    # -----------------------------------------------------------------------------
    # CONNECTION SETTINGS
    # -----------------------------------------------------------------------------
    listen_addresses = '*'
    port = 5432
    max_connections = 200
    superuser_reserved_connections = 3

    # TCP keepalive for connection health
    tcp_keepalives_idle = 600
    tcp_keepalives_interval = 30
    tcp_keepalives_count = 10

    # Authentication timeout
    authentication_timeout = 60s

    # -----------------------------------------------------------------------------
    # MEMORY CONFIGURATION (32GB RAM)
    # -----------------------------------------------------------------------------
    # Shared buffer pool (25% of RAM)
    shared_buffers = 8GB

    # Effective cache size (75% of RAM - hint to planner)
    effective_cache_size = 24GB

    # Work memory per operation
    work_mem = 256MB

    # Maintenance operations memory
    maintenance_work_mem = 2GB

    # Enable huge pages (requires OS configuration)
    huge_pages = try

    # Temporary buffer pool
    temp_buffers = 64MB

    # Hash aggregation memory
    hash_mem_multiplier = 2.0

    # -----------------------------------------------------------------------------
    # WAL CONFIGURATION
    # -----------------------------------------------------------------------------
    wal_level = replica
    wal_buffers = 64MB
    checkpoint_timeout = 15min
    checkpoint_completion_target = 0.9
    max_wal_size = 8GB
    min_wal_size = 2GB
    wal_compression = lz4
    archive_mode = on
    archive_command = '/usr/local/bin/wal-g wal-push %p'
    archive_timeout = 60

    # WAL sync method
    fsync = on
    synchronous_commit = on
    wal_sync_method = fdatasync
    full_page_writes = on

    # WAL writer tuning
    wal_writer_delay = 200ms
    wal_writer_flush_after = 1MB

    # -----------------------------------------------------------------------------
    # QUERY PLANNER
    # -----------------------------------------------------------------------------
    random_page_cost = 1.1
    seq_page_cost = 1.0
    effective_io_concurrency = 200
    default_statistics_target = 100

    # JIT compilation
    jit = on
    jit_above_cost = 100000
    jit_inline_above_cost = 500000
    jit_optimize_above_cost = 500000

    # Planner cost estimates
    cpu_tuple_cost = 0.01
    cpu_index_tuple_cost = 0.005
    cpu_operator_cost = 0.0025

    # Join optimization
    from_collapse_limit = 8
    join_collapse_limit = 8
    geqo = on
    geqo_threshold = 12

    # -----------------------------------------------------------------------------
    # PARALLEL QUERY
    # -----------------------------------------------------------------------------
    max_parallel_workers_per_gather = 4
    max_parallel_workers = 8
    max_parallel_maintenance_workers = 4
    parallel_leader_participation = on
    min_parallel_table_scan_size = 8MB
    min_parallel_index_scan_size = 512kB
    parallel_tuple_cost = 0.1
    parallel_setup_cost = 1000.0

    # -----------------------------------------------------------------------------
    # AUTOVACUUM (Aggressive for production)
    # -----------------------------------------------------------------------------
    autovacuum = on
    autovacuum_max_workers = 4
    autovacuum_naptime = 30s
    autovacuum_vacuum_threshold = 50
    autovacuum_analyze_threshold = 50
    autovacuum_vacuum_scale_factor = 0.02
    autovacuum_analyze_scale_factor = 0.01
    autovacuum_vacuum_cost_delay = 2ms
    autovacuum_vacuum_cost_limit = 1000

    # Freeze settings
    vacuum_freeze_min_age = 50000000
    vacuum_freeze_table_age = 150000000
    autovacuum_freeze_max_age = 200000000

    # -----------------------------------------------------------------------------
    # REPLICATION (Streaming replication)
    # -----------------------------------------------------------------------------
    max_wal_senders = 10
    max_replication_slots = 10
    wal_keep_size = 4GB
    hot_standby = on
    hot_standby_feedback = on
    max_standby_archive_delay = 30s
    max_standby_streaming_delay = 30s

    # Synchronous replication
    synchronous_commit = on
    synchronous_standby_names = 'FIRST 1 (postgresql-prod-1,postgresql-prod-2)'

    # Commit timestamp tracking
    track_commit_timestamp = on

    # -----------------------------------------------------------------------------
    # BACKGROUND WRITER
    # -----------------------------------------------------------------------------
    bgwriter_delay = 200ms
    bgwriter_lru_maxpages = 100
    bgwriter_lru_multiplier = 2.0
    bgwriter_flush_after = 512kB

    # -----------------------------------------------------------------------------
    # LOGGING
    # -----------------------------------------------------------------------------
    logging_collector = on
    log_directory = 'log'
    log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
    log_rotation_age = 1d
    log_rotation_size = 100MB
    log_min_duration_statement = 1000
    log_checkpoints = on
    log_connections = on
    log_disconnections = on
    log_lock_waits = on
    log_statement = 'ddl'
    log_temp_files = 0
    log_line_prefix = '%m [%p] %q%u@%d '
    log_timezone = 'UTC'
    log_autovacuum_min_duration = 1000
    log_replication_commands = on

    # Error verbosity
    log_error_verbosity = default
    log_min_error_statement = error

    # -----------------------------------------------------------------------------
    # SECURITY
    # -----------------------------------------------------------------------------
    ssl = on
    ssl_cert_file = '/etc/postgresql/certs/server.crt'
    ssl_key_file = '/etc/postgresql/certs/server.key'
    ssl_ca_file = '/etc/postgresql/certs/ca.crt'
    ssl_ciphers = 'HIGH:MEDIUM:+3DES:!aNULL'
    ssl_prefer_server_ciphers = on
    ssl_min_protocol_version = 'TLSv1.2'
    password_encryption = scram-sha-256

    # Row security
    row_security = on

    # -----------------------------------------------------------------------------
    # LOCK MANAGEMENT
    # -----------------------------------------------------------------------------
    deadlock_timeout = 1s
    max_locks_per_transaction = 64
    max_pred_locks_per_transaction = 64
    lock_timeout = 0
    statement_timeout = 0
    idle_in_transaction_session_timeout = 60min

    # -----------------------------------------------------------------------------
    # CLIENT DEFAULTS
    # -----------------------------------------------------------------------------
    search_path = '"$user", public'
    timezone = 'UTC'
    datestyle = 'iso, mdy'
    lc_messages = 'en_US.UTF-8'
    lc_monetary = 'en_US.UTF-8'
    lc_numeric = 'en_US.UTF-8'
    lc_time = 'en_US.UTF-8'
    default_text_search_config = 'pg_catalog.english'

    # -----------------------------------------------------------------------------
    # RESOURCE CONSUMPTION
    # -----------------------------------------------------------------------------
    max_files_per_process = 1000
    vacuum_cost_delay = 0
    vacuum_cost_page_hit = 1
    vacuum_cost_page_miss = 10
    vacuum_cost_page_dirty = 20
    vacuum_cost_limit = 200

  # TimescaleDB configuration
  timescaledb.conf: |
    # =============================================================================
    # TimescaleDB Production Configuration
    # =============================================================================
    shared_preload_libraries = 'timescaledb,pg_stat_statements,auto_explain'

    # Background workers
    timescaledb.max_background_workers = 8
    timescaledb.telemetry_level = off

    # License
    timescaledb.license = 'timescale'

    # Query optimizations
    timescaledb.enable_optimizations = on
    timescaledb.enable_chunk_append = on
    timescaledb.enable_parallel_chunk_append = on
    timescaledb.enable_constraint_aware_append = on
    timescaledb.enable_ordered_append = on
    timescaledb.enable_runtime_exclusion = on
    timescaledb.enable_qual_propagation = on
    timescaledb.enable_cagg_watermark_constify = on
    timescaledb.enable_transparent_decompression = on
    timescaledb.enable_dml_decompression = on
    timescaledb.enable_bulk_decompression = on

    # Constraint exclusion for partitioning
    constraint_exclusion = partition

    # pg_stat_statements
    pg_stat_statements.max = 10000
    pg_stat_statements.track = all
    pg_stat_statements.track_utility = on
    pg_stat_statements.track_planning = on
    pg_stat_statements.save = on

    # auto_explain for slow query analysis
    auto_explain.log_min_duration = '3s'
    auto_explain.log_analyze = on
    auto_explain.log_buffers = on
    auto_explain.log_timing = on
    auto_explain.log_triggers = on
    auto_explain.log_verbose = on
    auto_explain.log_format = 'text'
    auto_explain.log_nested_statements = on
    auto_explain.sample_rate = 0.01

  # Replication configuration
  replication.conf: |
    # =============================================================================
    # Replication Configuration for Production HA
    # =============================================================================
    max_wal_senders = 10
    max_replication_slots = 10
    wal_keep_size = 4GB
    hot_standby = on
    hot_standby_feedback = on
    max_standby_archive_delay = 30s
    max_standby_streaming_delay = 30s

    # Synchronous replication (quorum-based)
    synchronous_commit = on
    synchronous_standby_names = 'FIRST 1 (postgresql-prod-1,postgresql-prod-2)'

    # WAL receiver settings (for standby)
    wal_receiver_timeout = 60s
    wal_receiver_status_interval = 10s
    wal_retrieve_retry_interval = 5s

    # Commit timestamp for conflict resolution
    track_commit_timestamp = on

  # pg_hba.conf for production
  pg_hba.conf: |
    # TYPE  DATABASE        USER            ADDRESS                 METHOD
    # Local connections (Unix socket)
    local   all             postgres                                peer
    local   all             all                                     scram-sha-256

    # IPv4 connections from Kubernetes cluster
    hostssl all             all             10.0.0.0/8              scram-sha-256
    hostssl all             all             172.16.0.0/12           scram-sha-256
    hostssl all             all             192.168.0.0/16          scram-sha-256

    # Replication connections
    hostssl replication     replicator      10.0.0.0/8              scram-sha-256
    hostssl replication     replicator      172.16.0.0/12           scram-sha-256

    # Monitoring
    hostssl all             monitoring      10.0.0.0/8              scram-sha-256

    # Reject all other connections
    host    all             all             0.0.0.0/0               reject

  # Recovery configuration for standby
  recovery.conf: |
    # Standby configuration
    standby_mode = 'on'
    primary_conninfo = 'host=postgresql-prod-0.postgresql-prod port=5432 user=replicator password=REPLICATION_PASSWORD application_name=postgresql-prod-N sslmode=require'
    recovery_target_timeline = 'latest'
    restore_command = '/usr/local/bin/wal-g wal-fetch %f %p'

---
# External Secret for production credentials
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: postgresql-credentials-prod
  namespace: greenlang-prod
  labels:
    app: postgresql
    environment: production
spec:
  refreshInterval: 15m
  secretStoreRef:
    kind: ClusterSecretStore
    name: aws-secrets-manager
  target:
    name: postgresql-credentials-prod
    creationPolicy: Owner
    template:
      type: Opaque
      data:
        POSTGRES_USER: "{{ .username }}"
        POSTGRES_PASSWORD: "{{ .password }}"
        POSTGRES_DB: "{{ .database }}"
        DATABASE_URL: "{{ .connection_string }}"
        REPLICATION_USER: "{{ .replication_user }}"
        REPLICATION_PASSWORD: "{{ .replication_password }}"
        PGPASSFILE: |
          *:*:*:{{ .username }}:{{ .password }}
          *:*:replication:{{ .replication_user }}:{{ .replication_password }}
  data:
    - secretKey: username
      remoteRef:
        key: greenlang/prod/postgresql
        property: username
    - secretKey: password
      remoteRef:
        key: greenlang/prod/postgresql
        property: password
    - secretKey: database
      remoteRef:
        key: greenlang/prod/postgresql
        property: database
    - secretKey: connection_string
      remoteRef:
        key: greenlang/prod/postgresql
        property: connection_string
    - secretKey: replication_user
      remoteRef:
        key: greenlang/prod/postgresql
        property: replication_user
    - secretKey: replication_password
      remoteRef:
        key: greenlang/prod/postgresql
        property: replication_password

---
# StorageClass for high-performance volumes
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: postgresql-fast
  labels:
    app: postgresql
provisioner: ebs.csi.aws.com
parameters:
  type: gp3
  iops: "16000"
  throughput: "1000"
  encrypted: "true"
  fsType: ext4
reclaimPolicy: Retain
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer

---
# PostgreSQL StatefulSet for production HA
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgresql-prod
  namespace: greenlang-prod
  labels:
    app: postgresql
    environment: production
    cluster: greenlang-postgresql
spec:
  serviceName: postgresql-prod
  replicas: 3
  podManagementPolicy: OrderedReady
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: postgresql
      environment: production
  template:
    metadata:
      labels:
        app: postgresql
        environment: production
        cluster: greenlang-postgresql
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9187"
        checksum/config: "{{ include (print $.Template.BasePath '/configmap.yaml') . | sha256sum }}"
    spec:
      serviceAccountName: postgresql-prod
      terminationGracePeriodSeconds: 120
      securityContext:
        runAsUser: 999
        runAsGroup: 999
        fsGroup: 999
        fsGroupChangePolicy: OnRootMismatch

      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - postgresql
                  - key: environment
                    operator: In
                    values:
                      - production
              topologyKey: kubernetes.io/hostname
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - postgresql
                topologyKey: topology.kubernetes.io/zone

      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: topology.kubernetes.io/zone
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
            matchLabels:
              app: postgresql
              environment: production

      initContainers:
        # Set permissions on data directory
        - name: init-permissions
          image: busybox:1.36
          command:
            - sh
            - -c
            - |
              chown -R 999:999 /var/lib/postgresql/data
              chmod 700 /var/lib/postgresql/data
          volumeMounts:
            - name: postgresql-data
              mountPath: /var/lib/postgresql/data
          securityContext:
            runAsUser: 0

      containers:
        - name: postgresql
          image: timescale/timescaledb-ha:pg15-ts2.14-latest
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 5432
              name: postgresql
          envFrom:
            - secretRef:
                name: postgresql-credentials-prod
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: PGDATA
              value: /var/lib/postgresql/data/pgdata
          volumeMounts:
            - name: postgresql-data
              mountPath: /var/lib/postgresql/data
            - name: postgresql-config
              mountPath: /etc/postgresql/postgresql.conf
              subPath: postgresql.conf
            - name: postgresql-config
              mountPath: /etc/postgresql/timescaledb.conf
              subPath: timescaledb.conf
            - name: postgresql-config
              mountPath: /etc/postgresql/pg_hba.conf
              subPath: pg_hba.conf
            - name: postgresql-certs
              mountPath: /etc/postgresql/certs
              readOnly: true
            - name: postgresql-wal
              mountPath: /var/lib/postgresql/wal
          args:
            - -c
            - config_file=/etc/postgresql/postgresql.conf
            - -c
            - hba_file=/etc/postgresql/pg_hba.conf
          resources:
            requests:
              memory: "16Gi"
              cpu: "4000m"
            limits:
              memory: "32Gi"
              cpu: "8000m"

          startupProbe:
            exec:
              command:
                - pg_isready
                - -U
                - $(POSTGRES_USER)
                - -d
                - $(POSTGRES_DB)
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 30

          livenessProbe:
            exec:
              command:
                - pg_isready
                - -U
                - $(POSTGRES_USER)
                - -d
                - $(POSTGRES_DB)
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 6

          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - |
                  pg_isready -U $POSTGRES_USER -d $POSTGRES_DB
                  if [ $? -ne 0 ]; then exit 1; fi
                  # Check if this is primary or standby is caught up
                  psql -U $POSTGRES_USER -d $POSTGRES_DB -c "SELECT 1" > /dev/null 2>&1
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 3
            successThreshold: 1

          lifecycle:
            preStop:
              exec:
                command:
                  - /bin/sh
                  - -c
                  - |
                    # Graceful shutdown
                    pg_ctl stop -D $PGDATA -m fast -t 60

        # Postgres Exporter sidecar
        - name: postgres-exporter
          image: quay.io/prometheuscommunity/postgres-exporter:v0.15.0
          ports:
            - containerPort: 9187
              name: metrics
          env:
            - name: DATA_SOURCE_URI
              value: "localhost:5432/$(POSTGRES_DB)?sslmode=disable"
            - name: DATA_SOURCE_USER
              valueFrom:
                secretKeyRef:
                  name: postgresql-credentials-prod
                  key: POSTGRES_USER
            - name: DATA_SOURCE_PASS
              valueFrom:
                secretKeyRef:
                  name: postgresql-credentials-prod
                  key: POSTGRES_PASSWORD
            - name: PG_EXPORTER_EXTEND_QUERY_PATH
              value: /etc/postgres-exporter/queries.yaml
          volumeMounts:
            - name: postgres-exporter-queries
              mountPath: /etc/postgres-exporter
          resources:
            requests:
              memory: "64Mi"
              cpu: "50m"
            limits:
              memory: "128Mi"
              cpu: "200m"

      volumes:
        - name: postgresql-config
          configMap:
            name: postgresql-config-prod
        - name: postgresql-certs
          secret:
            secretName: postgresql-tls-prod
            defaultMode: 0600
        - name: postgres-exporter-queries
          configMap:
            name: postgres-exporter-queries

  volumeClaimTemplates:
    - metadata:
        name: postgresql-data
        labels:
          app: postgresql
          environment: production
      spec:
        accessModes:
          - ReadWriteOnce
        storageClassName: postgresql-fast
        resources:
          requests:
            storage: 500Gi
    - metadata:
        name: postgresql-wal
        labels:
          app: postgresql
          environment: production
      spec:
        accessModes:
          - ReadWriteOnce
        storageClassName: postgresql-fast
        resources:
          requests:
            storage: 100Gi

---
# Headless Service for StatefulSet
apiVersion: v1
kind: Service
metadata:
  name: postgresql-prod
  namespace: greenlang-prod
  labels:
    app: postgresql
    environment: production
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - port: 5432
      targetPort: 5432
      name: postgresql
    - port: 9187
      targetPort: 9187
      name: metrics
  selector:
    app: postgresql
    environment: production

---
# Service for primary (read-write)
apiVersion: v1
kind: Service
metadata:
  name: postgresql-prod-primary
  namespace: greenlang-prod
  labels:
    app: postgresql
    environment: production
    role: primary
spec:
  type: ClusterIP
  ports:
    - port: 5432
      targetPort: 5432
      name: postgresql
  selector:
    app: postgresql
    environment: production
    role: primary

---
# Service for replicas (read-only)
apiVersion: v1
kind: Service
metadata:
  name: postgresql-prod-replica
  namespace: greenlang-prod
  labels:
    app: postgresql
    environment: production
    role: replica
spec:
  type: ClusterIP
  ports:
    - port: 5432
      targetPort: 5432
      name: postgresql
  selector:
    app: postgresql
    environment: production
    role: replica

---
# ServiceMonitor for Prometheus
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: postgresql-prod
  namespace: greenlang-prod
  labels:
    app: postgresql
    environment: production
spec:
  selector:
    matchLabels:
      app: postgresql
      environment: production
  endpoints:
    - port: metrics
      interval: 15s
      path: /metrics
      scrapeTimeout: 10s
  namespaceSelector:
    matchNames:
      - greenlang-prod

---
# PodDisruptionBudget for HA
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: postgresql-prod-pdb
  namespace: greenlang-prod
  labels:
    app: postgresql
    environment: production
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: postgresql
      environment: production

---
# NetworkPolicy
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: postgresql-prod-netpol
  namespace: greenlang-prod
spec:
  podSelector:
    matchLabels:
      app: postgresql
      environment: production
  policyTypes:
    - Ingress
    - Egress
  ingress:
    # Allow from application pods
    - from:
        - namespaceSelector:
            matchLabels:
              name: greenlang-prod
          podSelector:
            matchLabels:
              access: postgresql
      ports:
        - protocol: TCP
          port: 5432
    # Allow replication between pods
    - from:
        - podSelector:
            matchLabels:
              app: postgresql
              environment: production
      ports:
        - protocol: TCP
          port: 5432
    # Allow monitoring
    - from:
        - namespaceSelector:
            matchLabels:
              name: monitoring
      ports:
        - protocol: TCP
          port: 9187
  egress:
    # Allow DNS
    - to:
        - namespaceSelector: {}
          podSelector:
            matchLabels:
              k8s-app: kube-dns
      ports:
        - protocol: UDP
          port: 53
    # Allow replication
    - to:
        - podSelector:
            matchLabels:
              app: postgresql
              environment: production
      ports:
        - protocol: TCP
          port: 5432
    # Allow S3 access for backups
    - to:
        - ipBlock:
            cidr: 0.0.0.0/0
      ports:
        - protocol: TCP
          port: 443

---
# Postgres Exporter custom queries
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-exporter-queries
  namespace: greenlang-prod
  labels:
    app: postgresql
    environment: production
data:
  queries.yaml: |
    pg_replication:
      query: |
        SELECT
          CASE WHEN pg_is_in_recovery() THEN 1 ELSE 0 END AS is_replica,
          COALESCE(EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp())), 0) AS lag_seconds
      master: true
      metrics:
        - is_replica:
            usage: "GAUGE"
            description: "Whether the server is a replica"
        - lag_seconds:
            usage: "GAUGE"
            description: "Replication lag in seconds"

    pg_postmaster:
      query: "SELECT pg_postmaster_start_time as start_time_seconds from pg_postmaster_start_time()"
      master: true
      metrics:
        - start_time_seconds:
            usage: "GAUGE"
            description: "Time at which postmaster started"

    pg_stat_user_tables:
      query: |
        SELECT
          current_database() datname,
          schemaname,
          relname,
          seq_scan,
          seq_tup_read,
          idx_scan,
          idx_tup_fetch,
          n_tup_ins,
          n_tup_upd,
          n_tup_del,
          n_tup_hot_upd,
          n_live_tup,
          n_dead_tup,
          n_mod_since_analyze,
          COALESCE(last_vacuum, '1970-01-01Z') as last_vacuum,
          COALESCE(last_autovacuum, '1970-01-01Z') as last_autovacuum,
          COALESCE(last_analyze, '1970-01-01Z') as last_analyze,
          COALESCE(last_autoanalyze, '1970-01-01Z') as last_autoanalyze,
          vacuum_count,
          autovacuum_count,
          analyze_count,
          autoanalyze_count
        FROM pg_stat_user_tables
      metrics:
        - datname:
            usage: "LABEL"
            description: "Database name"
        - schemaname:
            usage: "LABEL"
            description: "Schema name"
        - relname:
            usage: "LABEL"
            description: "Table name"
        - seq_scan:
            usage: "COUNTER"
            description: "Sequential scans"
        - seq_tup_read:
            usage: "COUNTER"
            description: "Tuples read by sequential scans"
        - idx_scan:
            usage: "COUNTER"
            description: "Index scans"
        - idx_tup_fetch:
            usage: "COUNTER"
            description: "Tuples fetched by index scans"
        - n_tup_ins:
            usage: "COUNTER"
            description: "Tuples inserted"
        - n_tup_upd:
            usage: "COUNTER"
            description: "Tuples updated"
        - n_tup_del:
            usage: "COUNTER"
            description: "Tuples deleted"
        - n_live_tup:
            usage: "GAUGE"
            description: "Live tuples"
        - n_dead_tup:
            usage: "GAUGE"
            description: "Dead tuples"
        - vacuum_count:
            usage: "COUNTER"
            description: "Manual vacuum count"
        - autovacuum_count:
            usage: "COUNTER"
            description: "Autovacuum count"

    timescaledb_chunks:
      query: |
        SELECT
          hypertable_schema,
          hypertable_name,
          COUNT(*) AS chunk_count,
          SUM(CASE WHEN is_compressed THEN 1 ELSE 0 END) AS compressed_chunks,
          pg_size_pretty(SUM(total_bytes)) AS total_size
        FROM timescaledb_information.chunks
        GROUP BY hypertable_schema, hypertable_name
      metrics:
        - hypertable_schema:
            usage: "LABEL"
            description: "Hypertable schema"
        - hypertable_name:
            usage: "LABEL"
            description: "Hypertable name"
        - chunk_count:
            usage: "GAUGE"
            description: "Number of chunks"
        - compressed_chunks:
            usage: "GAUGE"
            description: "Number of compressed chunks"
