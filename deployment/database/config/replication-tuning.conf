# =============================================================================
# PostgreSQL Replication Tuning Configuration
# =============================================================================
# GreenLang High Availability Replication Settings
# Supports: Streaming Replication, Logical Replication, Hot Standby
# Last Updated: 2026-02-03
# =============================================================================

# -----------------------------------------------------------------------------
# WAL SENDER CONFIGURATION
# -----------------------------------------------------------------------------
# Maximum number of concurrent WAL sender processes
# Set to: (number of replicas) + (backup slots) + (reserve slots)
max_wal_senders = 10

# Maximum number of replication slots
# Each replica and logical replication subscriber needs a slot
max_replication_slots = 10

# Minimum WAL to retain for replication
# Prevents WAL removal before replicas have received it
wal_keep_size = 4GB

# WAL sender timeout (disconnect inactive senders)
wal_sender_timeout = 60s

# Track commit timestamps for conflict resolution
track_commit_timestamp = on

# -----------------------------------------------------------------------------
# HOT STANDBY CONFIGURATION
# -----------------------------------------------------------------------------
# Enable read queries on standby servers
hot_standby = on

# Feedback from standby to prevent query-cancelling WAL cleanup
hot_standby_feedback = on

# Maximum delay before cancelling queries on standby
max_standby_archive_delay = 30s
max_standby_streaming_delay = 30s

# Vacuum defer cleanup age (number of transactions)
# Allows old row versions to persist for standby queries
vacuum_defer_cleanup_age = 0

# Standby server parameters
# hot_standby_wal_receiver = on

# -----------------------------------------------------------------------------
# SYNCHRONOUS REPLICATION
# -----------------------------------------------------------------------------
# Synchronous commit level
# Options: off, local, remote_write, remote_apply, on
# - off: No waiting for WAL (fastest, risk of data loss)
# - local: Wait for local disk write
# - remote_write: Wait for standby to receive WAL
# - remote_apply: Wait for standby to apply WAL (strongest)
# - on: Same as remote_apply when sync standbys exist
synchronous_commit = on

# Synchronous standby configuration
# FIRST N (...): Wait for N standbys from list
# ANY N (...): Wait for any N standbys from list
# * : Match all standbys
synchronous_standby_names = 'FIRST 1 (*)'

# Example configurations:
# Single named standby: synchronous_standby_names = 'standby1'
# First of two: synchronous_standby_names = 'FIRST 1 (standby1, standby2)'
# Any two of three: synchronous_standby_names = 'ANY 2 (standby1, standby2, standby3)'
# Priority list: synchronous_standby_names = 'FIRST 2 (s1, s2, s3)'

# -----------------------------------------------------------------------------
# WAL RECEIVER CONFIGURATION (Standby Server)
# -----------------------------------------------------------------------------
# WAL receiver timeout
wal_receiver_timeout = 60s

# WAL receiver status interval
wal_receiver_status_interval = 10s

# WAL retrieval mode when primary unavailable
# Options: any, first, prefer-local, prefer-standby
wal_retrieve_retry_interval = 5s

# Primary connection info (set on standby only)
# primary_conninfo = 'host=primary port=5432 user=replicator password=secret application_name=standby1'

# Trigger file for failover (legacy, use pg_promote() instead)
# promote_trigger_file = '/tmp/postgresql.trigger'

# Recovery target settings (for PITR)
# recovery_target_time = '2024-01-01 00:00:00'
# recovery_target_xid = '12345'
# recovery_target_name = 'backup_point_1'
# recovery_target_lsn = '0/1000000'
# recovery_target_inclusive = true
# recovery_target_timeline = 'latest'
# recovery_target_action = 'pause'

# -----------------------------------------------------------------------------
# LOGICAL REPLICATION
# -----------------------------------------------------------------------------
# Maximum number of logical replication workers
max_logical_replication_workers = 4

# Maximum number of synchronization workers per subscription
max_sync_workers_per_subscription = 2

# Logical decoding work memory
logical_decoding_work_mem = 64MB

# -----------------------------------------------------------------------------
# REPLICATION SLOT CONFIGURATION
# -----------------------------------------------------------------------------
# Maximum WAL size per replication slot
# Prevents runaway disk usage from inactive slots
max_slot_wal_keep_size = 16GB

# Replication slot inactive timeout (PostgreSQL 17+)
# idle_replication_slot_timeout = 0

# -----------------------------------------------------------------------------
# CONFLICT RESOLUTION (Logical Replication)
# -----------------------------------------------------------------------------
# Subscription conflict handling
# Options: error, apply_remote, keep_local, discard
# Default subscriber behavior (set on subscriber)
# subscription_conflict_resolution = 'error'

# -----------------------------------------------------------------------------
# ARCHIVE RECOVERY
# -----------------------------------------------------------------------------
# Archive recovery settings
# restore_command = 'cp /archive/%f %p'
# archive_cleanup_command = 'pg_archivecleanup /archive %r'

# Recovery prefetch
recovery_prefetch = try

# Recovery init sync method
recovery_init_sync_method = fsync

# -----------------------------------------------------------------------------
# REPLICATION SECURITY
# -----------------------------------------------------------------------------
# Replication connections in pg_hba.conf:
# TYPE  DATABASE        USER            ADDRESS                 METHOD
# host  replication     replicator      10.0.0.0/8             scram-sha-256
# host  replication     replicator      192.168.0.0/16         scram-sha-256

# SSL for replication connections
# ssl = on
# ssl_cert_file = 'server.crt'
# ssl_key_file = 'server.key'
# ssl_ca_file = 'root.crt'

# -----------------------------------------------------------------------------
# MONITORING REPLICATION
# -----------------------------------------------------------------------------
# Views for monitoring replication status:
#
# -- Check replication status on primary
# SELECT * FROM pg_stat_replication;
#
# -- Check replication slots
# SELECT * FROM pg_replication_slots;
#
# -- Check WAL receiver status on standby
# SELECT * FROM pg_stat_wal_receiver;
#
# -- Calculate replication lag
# SELECT
#     client_addr,
#     application_name,
#     state,
#     sent_lsn,
#     write_lsn,
#     flush_lsn,
#     replay_lsn,
#     pg_wal_lsn_diff(sent_lsn, replay_lsn) AS lag_bytes,
#     pg_size_pretty(pg_wal_lsn_diff(sent_lsn, replay_lsn)) AS lag_size
# FROM pg_stat_replication;
#
# -- Monitor slot lag
# SELECT
#     slot_name,
#     slot_type,
#     active,
#     pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn) AS lag_bytes,
#     pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn)) AS lag_size
# FROM pg_replication_slots;

# -----------------------------------------------------------------------------
# FAILOVER CONFIGURATION
# -----------------------------------------------------------------------------
# For automated failover, use tools like:
# - Patroni (recommended)
# - pg_auto_failover
# - repmgr
# - Pgpool-II

# Patroni example configuration reference:
# scope: greenlang-cluster
# name: node1
# postgresql:
#   use_pg_rewind: true
#   parameters:
#     max_connections: 200
#     hot_standby: on
#     wal_level: replica
#     max_wal_senders: 10
#     max_replication_slots: 10
#     wal_keep_size: 4GB

# -----------------------------------------------------------------------------
# CASCADING REPLICATION
# -----------------------------------------------------------------------------
# Enable cascading replication for multi-tier setups
# Standby servers can act as replication sources

# On cascading standby, set:
# primary_conninfo pointing to another standby instead of primary

# -----------------------------------------------------------------------------
# QUORUM-BASED SYNCHRONOUS REPLICATION
# -----------------------------------------------------------------------------
# For high availability with multiple synchronous standbys
# Example: Require 2 of 3 standbys to acknowledge
# synchronous_standby_names = 'ANY 2 (standby1, standby2, standby3)'

# This ensures:
# - Data durability even if one standby fails
# - Lower latency than requiring all standbys
# - Automatic failover between standbys

# =============================================================================
# END OF REPLICATION CONFIGURATION
# =============================================================================
