# =============================================================================
# GreenLang Infrastructure - Complete End-to-End Deployment
# Task ID: INFRA-001-COMPLETE
# Ralphy CLI Version: v4.7.1
# =============================================================================
#
# This configuration orchestrates a complete end-to-end deployment including:
# - Pre-deployment validation and quality gates
# - Full infrastructure deployment via INFRA-001-TASKS.yaml
# - Post-deployment verification and smoke tests
# - Production readiness validation
# - Rollback capabilities
#
# Usage:
#   ralphy run .ralphy/tasks/infra-001-complete.yaml --environment dev
#   ralphy run .ralphy/tasks/infra-001-complete.yaml --environment staging
#   ralphy run .ralphy/tasks/infra-001-complete.yaml --environment prod --require-approval
#
# Dry Run:
#   ralphy run .ralphy/tasks/infra-001-complete.yaml --environment prod --dry-run
#
# Rollback:
#   ralphy rollback .ralphy/tasks/infra-001-complete.yaml --environment prod --to-version v1.2.3
#
# =============================================================================

version: "4.7.1"
kind: TaskConfiguration
metadata:
  name: greenlang-complete-deployment
  description: Complete end-to-end deployment orchestration for GreenLang
  owner: devops-team
  labels:
    project: greenlang
    type: infrastructure
    scope: complete
    criticality: high
  annotations:
    ralphy.io/task-id: "INFRA-001-COMPLETE"
    ralphy.io/estimated-duration: "90m"
    ralphy.io/requires-approval: "true"
    ralphy.io/rollback-enabled: "true"
    ralphy.io/includes:
      - "deployment/terraform/INFRA-001-TASKS.yaml"
      - ".ralphy/tasks/infra-001-local.yaml"

# =============================================================================
# Project Configuration
# =============================================================================
project:
  name: greenlang-complete
  repository: github.com/greenlang/infrastructure

  environments:
    - name: dev
      aws_region: us-east-1
      terraform_workspace: dev
      auto_approve: true
      skip_quality_gates: false
      enable_canary: false
      notifications:
        slack_channel: "#greenlang-dev"
        on_start: true
        on_success: true
        on_failure: true

    - name: staging
      aws_region: us-east-1
      terraform_workspace: staging
      auto_approve: true
      skip_quality_gates: false
      enable_canary: true
      canary_percentage: 10
      notifications:
        slack_channel: "#greenlang-staging"
        on_start: true
        on_success: true
        on_failure: true

    - name: prod
      aws_region: us-east-1
      terraform_workspace: prod
      auto_approve: false
      skip_quality_gates: false
      enable_canary: true
      canary_percentage: 5
      requires_approval:
        min_approvers: 2
        teams:
          - platform-engineering
          - security
          - sre
        timeout: 60m
      notifications:
        slack_channel: "#greenlang-prod"
        pagerduty_service: greenlang-prod-infra
        on_start: true
        on_success: true
        on_failure: true
        on_rollback: true

  # Global variables
  variables:
    PROJECT_NAME: greenlang
    TERRAFORM_VERSION: "1.6.0"
    AWS_DEFAULT_REGION: "{{ environment.aws_region }}"
    KUBECONFIG_PATH: "/tmp/kubeconfig-{{ environment.name }}"
    DEPLOYMENT_ID: "deploy-{{ environment.name }}-{{ timestamp }}"
    ARTIFACT_BUCKET: "greenlang-{{ environment.name }}-artifacts"
    BACKUP_BUCKET: "greenlang-{{ environment.name }}-backups"

  # Required secrets
  secrets:
    provider: aws-secrets-manager
    prefix: "greenlang/{{ environment.name }}"
    required:
      - database-credentials
      - redis-auth-token
      - github-oidc-token
      - slack-webhook-url

# =============================================================================
# Global Settings
# =============================================================================
settings:
  execution:
    max_parallel_tasks: 5
    default_timeout: 30m
    retry_policy:
      max_retries: 3
      backoff_multiplier: 2
      initial_delay: 10s
    fail_fast: false

  logging:
    level: INFO
    format: json
    include_timestamps: true
    include_task_context: true
    destinations:
      - type: console
      - type: file
        path: ".ralphy/logs/deployment-{{ timestamp }}.log"
      - type: s3
        bucket: "{{ ARTIFACT_BUCKET }}"
        prefix: "logs/deployments"

  notifications:
    on_start: true
    on_success: true
    on_failure: true
    on_rollback: true
    providers:
      - type: slack
        webhook_url: "{{ secrets.slack_webhook_url }}"
        channel: "{{ environment.notifications.slack_channel }}"

  artifacts:
    storage: s3
    bucket: "{{ ARTIFACT_BUCKET }}"
    prefix: "ralphy/{{ DEPLOYMENT_ID }}"
    retention_days: 90

  checkpoints:
    enabled: true
    storage: s3
    bucket: "{{ ARTIFACT_BUCKET }}"
    prefix: "checkpoints"

# =============================================================================
# Pre-flight Checks
# =============================================================================
preflight:
  name: complete-preflight-validation
  description: Comprehensive pre-deployment validation
  fail_fast: true
  timeout: 15m

  checks:
    - name: aws-credentials
      description: Verify AWS credentials
      command: aws sts get-caller-identity
      expect:
        exit_code: 0

    - name: required-tools
      description: Verify all required tools
      command: |
        MISSING=""
        for tool in aws terraform kubectl helm jq curl git; do
          if ! command -v $tool &> /dev/null; then
            MISSING="$MISSING $tool"
          fi
        done
        [ -z "$MISSING" ] || { echo "Missing:$MISSING"; exit 1; }
      expect:
        exit_code: 0

    - name: terraform-version
      description: Verify Terraform version
      command: terraform version -json | jq -r '.terraform_version'
      expect:
        output_contains: "1.6"

    - name: state-bucket
      description: Verify state bucket exists
      command: aws s3 ls s3://greenlang-terraform-state --region us-east-1
      expect:
        exit_code: 0

    - name: secrets-accessible
      description: Verify secrets are accessible
      command: |
        aws secretsmanager get-secret-value \
          --secret-id "greenlang/{{ environment.name }}/database-credentials" \
          --query 'Name' --output text
      expect:
        exit_code: 0

    - name: git-clean
      description: Verify git working directory is clean
      command: |
        if [ -n "$(git status --porcelain)" ]; then
          echo "WARNING: Git working directory has uncommitted changes"
          git status --porcelain
        fi
      expect:
        exit_code: 0

    - name: branch-check
      description: Verify deployment branch
      command: |
        BRANCH=$(git rev-parse --abbrev-ref HEAD)
        if [ "{{ environment.name }}" = "prod" ] && [ "$BRANCH" != "main" ] && [ "$BRANCH" != "master" ]; then
          echo "WARNING: Deploying to prod from branch: $BRANCH"
        fi
        echo "Current branch: $BRANCH"
      expect:
        exit_code: 0

# =============================================================================
# Task Definitions
# =============================================================================
tasks:

  # ---------------------------------------------------------------------------
  # Phase 1: Pre-Deployment Quality Gates
  # ---------------------------------------------------------------------------
  - id: quality-gate-local
    name: Run Local Quality Gates
    phase: 1
    stage: 1
    description: Run all local validation tasks

    commands:
      - name: run-local-validation
        command: |
          echo "=== Running Local Validation Tasks ==="
          cd "$(git rev-parse --show-toplevel)"

          # Run terraform fmt check
          echo "Checking Terraform formatting..."
          terraform fmt -check -recursive deployment/terraform || {
            echo "ERROR: Terraform formatting issues found"
            exit 1
          }

          # Validate all modules
          echo "Validating Terraform modules..."
          for module in vpc eks rds elasticache s3 iam; do
            if [ -d "deployment/terraform/modules/$module" ]; then
              cd "deployment/terraform/modules/$module"
              terraform init -backend=false >/dev/null 2>&1
              terraform validate || { echo "ERROR: Module $module validation failed"; exit 1; }
              cd - >/dev/null
            fi
          done

          # Validate environment config
          echo "Validating environment configuration..."
          cd "deployment/terraform/environments/{{ environment.name }}"
          terraform init -backend=false >/dev/null 2>&1
          terraform validate || { echo "ERROR: Environment validation failed"; exit 1; }

          echo "Local validation passed!"
        timeout: 10m
        working_directory: "."

    validation:
      - name: validation-passed
        command: echo "Quality gate passed"
        expect:
          exit_code: 0

    on_failure:
      action: abort
      message: "Local quality gates failed - fix issues before deploying"

    checkpoint:
      name: quality-gate-passed
      on_restore: skip

  # ---------------------------------------------------------------------------
  - id: security-scan
    name: Security Scan
    phase: 1
    stage: 1
    parallel_group: pre-deploy-checks
    description: Run security scans on infrastructure code

    commands:
      - name: run-tfsec
        command: |
          if command -v tfsec &> /dev/null; then
            echo "=== Running tfsec security scan ==="
            cd deployment/terraform
            tfsec . --format json --out /tmp/tfsec-results.json || true

            CRITICAL=$(jq '[.results[] | select(.severity == "CRITICAL")] | length' /tmp/tfsec-results.json 2>/dev/null || echo "0")
            HIGH=$(jq '[.results[] | select(.severity == "HIGH")] | length' /tmp/tfsec-results.json 2>/dev/null || echo "0")

            echo "Critical: $CRITICAL, High: $HIGH"

            if [ "$CRITICAL" -gt 0 ]; then
              echo "ERROR: Critical security issues found!"
              jq '.results[] | select(.severity == "CRITICAL")' /tmp/tfsec-results.json
              exit 1
            fi
          else
            echo "SKIP: tfsec not installed"
          fi
        timeout: 5m
        working_directory: "."

    artifacts:
      - name: security-scan-results
        path: /tmp/tfsec-results.json
        retention: 30d

    on_failure:
      action: abort
      message: "Security scan failed - critical issues found"

  # ---------------------------------------------------------------------------
  - id: helm-validation
    name: Helm Chart Validation
    phase: 1
    stage: 1
    parallel_group: pre-deploy-checks
    description: Validate Helm charts

    commands:
      - name: lint-helm-chart
        command: |
          echo "=== Validating Helm charts ==="
          cd deployment/infrastructure/helm/greenlang
          helm lint . --strict
          helm template . -f values-{{ environment.name }}.yaml --debug > /dev/null
        timeout: 3m
        working_directory: "."

    validation:
      - name: helm-valid
        command: |
          cd deployment/infrastructure/helm/greenlang
          helm lint . --strict
        expect:
          exit_code: 0
        working_directory: "."

  # ---------------------------------------------------------------------------
  # Phase 2: Infrastructure Deployment
  # ---------------------------------------------------------------------------
  - id: create-deployment-record
    name: Create Deployment Record
    phase: 2
    stage: 2
    description: Create deployment tracking record

    commands:
      - name: create-record
        command: |
          DEPLOYMENT_RECORD=$(cat <<EOF
          {
            "deployment_id": "{{ DEPLOYMENT_ID }}",
            "environment": "{{ environment.name }}",
            "started_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "git_commit": "$(git rev-parse HEAD)",
            "git_branch": "$(git rev-parse --abbrev-ref HEAD)",
            "triggered_by": "${USER:-unknown}",
            "status": "in_progress"
          }
          EOF
          )
          echo "$DEPLOYMENT_RECORD" > /tmp/deployment-record.json
          echo "$DEPLOYMENT_RECORD"

          # Upload to S3
          aws s3 cp /tmp/deployment-record.json \
            "s3://{{ ARTIFACT_BUCKET }}/deployments/{{ DEPLOYMENT_ID }}/record.json"
        timeout: 2m
        working_directory: "."

    outputs:
      - name: deployment_id
        value: "{{ DEPLOYMENT_ID }}"
      - name: started_at
        from: date -u +%Y-%m-%dT%H:%M:%SZ

  # ---------------------------------------------------------------------------
  - id: run-infra-deployment
    name: Run Infrastructure Deployment
    phase: 2
    stage: 3
    depends_on:
      - quality-gate-local
      - security-scan
      - helm-validation
      - create-deployment-record
    description: Execute main infrastructure deployment

    commands:
      - name: execute-infra-tasks
        command: |
          echo "=== Starting Infrastructure Deployment ==="
          echo "Environment: {{ environment.name }}"
          echo "Deployment ID: {{ DEPLOYMENT_ID }}"

          # Run the main INFRA-001 tasks
          cd "$(git rev-parse --show-toplevel)"

          # Note: In a real Ralphy implementation, this would be:
          # ralphy run deployment/terraform/INFRA-001-TASKS.yaml --environment {{ environment.name }}

          # For now, execute key terraform commands directly
          cd deployment/terraform/environments/{{ environment.name }}

          # Initialize
          terraform init \
            -backend-config="bucket=greenlang-terraform-state" \
            -backend-config="key=environments/{{ environment.name }}/terraform.tfstate" \
            -backend-config="region={{ environment.aws_region }}" \
            -backend-config="encrypt=true" \
            -backend-config="dynamodb_table=greenlang-terraform-locks" \
            -reconfigure

          # Select workspace
          terraform workspace select {{ environment.name }} || terraform workspace new {{ environment.name }}

          # Plan
          terraform plan \
            -var-file="environments/{{ environment.name }}/terraform.tfvars" \
            -out=tfplan.binary \
            -detailed-exitcode || true

          # Apply (if auto_approve or after approval)
          if [ "{{ environment.auto_approve }}" = "true" ]; then
            terraform apply tfplan.binary
          else
            echo "Manual approval required for {{ environment.name }}"
            echo "Run: terraform apply tfplan.binary"
          fi
        timeout: 60m
        working_directory: "."

    checkpoint:
      name: infrastructure-deployed
      on_restore: validate

    rollback:
      enabled: true
      strategy: terraform-previous-state
      commands:
        - name: rollback-terraform
          command: |
            cd deployment/terraform/environments/{{ environment.name }}
            # Restore from backup state if available
            LATEST_BACKUP=$(aws s3 ls "s3://{{ BACKUP_BUCKET }}/terraform-state-backup-" --recursive | sort | tail -1 | awk '{print $4}')
            if [ -n "$LATEST_BACKUP" ]; then
              aws s3 cp "s3://{{ BACKUP_BUCKET }}/$LATEST_BACKUP" terraform.tfstate.backup
              echo "Backup state retrieved: $LATEST_BACKUP"
            fi
          timeout: 10m
          working_directory: "."

    on_failure:
      notify:
        - slack
        - pagerduty
      action: rollback
      collect_diagnostics: true

  # ---------------------------------------------------------------------------
  # Phase 3: Application Deployment
  # ---------------------------------------------------------------------------
  - id: configure-kubernetes
    name: Configure Kubernetes Access
    phase: 3
    stage: 4
    depends_on:
      - run-infra-deployment
    description: Configure kubectl for the deployed cluster

    commands:
      - name: update-kubeconfig
        command: |
          aws eks update-kubeconfig \
            --name greenlang-{{ environment.name }}-eks \
            --region {{ environment.aws_region }} \
            --kubeconfig {{ KUBECONFIG_PATH }}
          export KUBECONFIG={{ KUBECONFIG_PATH }}

          echo "=== Cluster Info ==="
          kubectl cluster-info
          kubectl get nodes
        timeout: 5m
        working_directory: "."

    validation:
      - name: kubectl-connected
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          kubectl get nodes -o name | wc -l
        expect:
          output_gte: 1

  # ---------------------------------------------------------------------------
  - id: deploy-k8s-addons
    name: Deploy Kubernetes Add-ons
    phase: 3
    stage: 5
    depends_on:
      - configure-kubernetes
    description: Deploy required Kubernetes add-ons

    commands:
      - name: deploy-cert-manager
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          helm repo add jetstack https://charts.jetstack.io
          helm repo update

          helm upgrade --install cert-manager jetstack/cert-manager \
            --namespace cert-manager \
            --create-namespace \
            --version v1.13.3 \
            --set installCRDs=true \
            --wait \
            --timeout 10m
        timeout: 15m
        working_directory: "."

      - name: deploy-ingress-controller
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx

          helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
            --namespace ingress-nginx \
            --create-namespace \
            --version 4.9.0 \
            --set controller.service.type=LoadBalancer \
            --wait \
            --timeout 10m
        timeout: 15m
        working_directory: "."

      - name: deploy-external-secrets
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          helm repo add external-secrets https://charts.external-secrets.io

          helm upgrade --install external-secrets external-secrets/external-secrets \
            --namespace external-secrets \
            --create-namespace \
            --version 0.9.11 \
            --wait \
            --timeout 10m
        timeout: 15m
        working_directory: "."

    validation:
      - name: addons-running
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          kubectl get deployment cert-manager -n cert-manager -o jsonpath='{.status.readyReplicas}'
          kubectl get deployment ingress-nginx-controller -n ingress-nginx -o jsonpath='{.status.readyReplicas}'
          kubectl get deployment external-secrets -n external-secrets -o jsonpath='{.status.readyReplicas}'
        expect:
          exit_code: 0

    checkpoint:
      name: k8s-addons-deployed

  # ---------------------------------------------------------------------------
  - id: deploy-monitoring
    name: Deploy Monitoring Stack
    phase: 3
    stage: 6
    depends_on:
      - deploy-k8s-addons
    description: Deploy Prometheus and Grafana

    commands:
      - name: deploy-prometheus-stack
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts

          helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
            --namespace monitoring \
            --create-namespace \
            --version 55.5.0 \
            --set prometheus.prometheusSpec.retention=30d \
            --set grafana.enabled=true \
            --wait \
            --timeout 15m
        timeout: 20m
        working_directory: "."

      - name: deploy-custom-alerts
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          if [ -f deployment/monitoring/alerts-unified.yml ]; then
            kubectl apply -f deployment/monitoring/alerts-unified.yml -n monitoring
          fi
        timeout: 2m
        working_directory: "."

    validation:
      - name: monitoring-running
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          kubectl get statefulset prometheus-kube-prometheus-stack-prometheus -n monitoring -o jsonpath='{.status.readyReplicas}'
        expect:
          output_gte: 1

  # ---------------------------------------------------------------------------
  - id: deploy-application
    name: Deploy GreenLang Application
    phase: 3
    stage: 7
    depends_on:
      - deploy-monitoring
    description: Deploy the GreenLang application

    commands:
      - name: create-namespaces
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          kubectl create namespace greenlang --dry-run=client -o yaml | kubectl apply -f -
          kubectl create namespace greenlang-agents --dry-run=client -o yaml | kubectl apply -f -
        timeout: 2m
        working_directory: "."

      - name: deploy-helm-release
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          helm upgrade --install greenlang deployment/infrastructure/helm/greenlang \
            --namespace greenlang \
            -f deployment/infrastructure/helm/greenlang/values-{{ environment.name }}.yaml \
            --set global.environment={{ environment.name }} \
            --set image.tag={{ image_tag | default('latest') }} \
            --wait \
            --timeout 15m
        timeout: 20m
        working_directory: "."

    validation:
      - name: application-running
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          kubectl get pods -n greenlang -l app=greenlang --field-selector=status.phase=Running -o name | wc -l
        expect:
          output_gte: 1

    checkpoint:
      name: application-deployed

    rollback:
      enabled: true
      commands:
        - name: rollback-helm
          command: |
            export KUBECONFIG={{ KUBECONFIG_PATH }}
            helm rollback greenlang -n greenlang
          timeout: 10m
          working_directory: "."

  # ---------------------------------------------------------------------------
  # Phase 4: Post-Deployment Validation
  # ---------------------------------------------------------------------------
  - id: smoke-tests
    name: Run Smoke Tests
    phase: 4
    stage: 8
    depends_on:
      - deploy-application
    description: Run post-deployment smoke tests

    commands:
      - name: api-health-check
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}

          # Get service endpoint
          kubectl wait --for=condition=available deployment/greenlang-app -n greenlang --timeout=300s || true

          # Port-forward and test health
          kubectl port-forward svc/greenlang-app 8080:80 -n greenlang &
          PF_PID=$!
          sleep 5

          # Test health endpoint
          HEALTH_STATUS=$(curl -sf http://localhost:8080/api/v1/health || echo "failed")
          echo "Health check: $HEALTH_STATUS"

          kill $PF_PID 2>/dev/null || true

          if [ "$HEALTH_STATUS" = "failed" ]; then
            echo "WARNING: Health check failed, but continuing..."
          fi
        timeout: 5m
        working_directory: "."
        continue_on_error: true

      - name: database-connectivity
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}

          # Test database connectivity from within the cluster
          kubectl run db-test-{{ environment.name }} \
            --image=postgres:14-alpine \
            --restart=Never \
            --rm \
            --attach \
            --namespace greenlang \
            --command -- pg_isready -h greenlang-postgres -p 5432 || echo "DB test skipped"
        timeout: 3m
        working_directory: "."
        continue_on_error: true

    validation:
      - name: pods-healthy
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          UNHEALTHY=$(kubectl get pods -n greenlang --field-selector=status.phase!=Running,status.phase!=Succeeded -o name 2>/dev/null | wc -l)
          echo "Unhealthy pods: $UNHEALTHY"
          [ "$UNHEALTHY" -eq 0 ] || [ "$UNHEALTHY" -lt 2 ]
        expect:
          exit_code: 0

  # ---------------------------------------------------------------------------
  - id: production-validation
    name: Production Readiness Validation
    phase: 4
    stage: 9
    depends_on:
      - smoke-tests
    description: Validate production readiness

    commands:
      - name: check-replicas
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          echo "=== Deployment Replica Status ==="
          kubectl get deployments -n greenlang -o wide
          kubectl get hpa -n greenlang 2>/dev/null || echo "No HPA configured"
        timeout: 2m
        working_directory: "."

      - name: check-resources
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          echo "=== Resource Usage ==="
          kubectl top pods -n greenlang 2>/dev/null || echo "Metrics not available"
          kubectl top nodes 2>/dev/null || echo "Node metrics not available"
        timeout: 2m
        working_directory: "."

      - name: check-monitoring
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          echo "=== Monitoring Status ==="
          kubectl get pods -n monitoring
          kubectl get servicemonitors -A 2>/dev/null || echo "No ServiceMonitors"
        timeout: 2m
        working_directory: "."

      - name: generate-report
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}

          REPORT=$(cat <<EOF
          {
            "deployment_id": "{{ DEPLOYMENT_ID }}",
            "environment": "{{ environment.name }}",
            "completed_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "git_commit": "$(git rev-parse HEAD)",
            "status": "SUCCESS",
            "infrastructure": {
              "cluster": "greenlang-{{ environment.name }}-eks",
              "region": "{{ environment.aws_region }}",
              "node_count": $(kubectl get nodes -o name | wc -l)
            },
            "application": {
              "namespace": "greenlang",
              "helm_release": "greenlang",
              "pods_running": $(kubectl get pods -n greenlang --field-selector=status.phase=Running -o name | wc -l)
            },
            "monitoring": {
              "prometheus": "$(kubectl get statefulset prometheus-kube-prometheus-stack-prometheus -n monitoring -o jsonpath='{.status.readyReplicas}' 2>/dev/null || echo '0')",
              "grafana": "$(kubectl get deployment kube-prometheus-stack-grafana -n monitoring -o jsonpath='{.status.readyReplicas}' 2>/dev/null || echo '0')"
            }
          }
          EOF
          )

          echo "$REPORT" | jq .
          echo "$REPORT" > /tmp/deployment-report-final.json

          # Upload report
          aws s3 cp /tmp/deployment-report-final.json \
            "s3://{{ ARTIFACT_BUCKET }}/deployments/{{ DEPLOYMENT_ID }}/final-report.json"
        timeout: 5m
        working_directory: "."

    artifacts:
      - name: deployment-report
        path: /tmp/deployment-report-final.json
        retention: 365d

    outputs:
      - name: deployment_status
        value: SUCCESS
      - name: completed_at
        from: date -u +%Y-%m-%dT%H:%M:%SZ

  # ---------------------------------------------------------------------------
  - id: notify-completion
    name: Send Completion Notification
    phase: 4
    stage: 10
    depends_on:
      - production-validation
    description: Send deployment completion notification

    commands:
      - name: send-slack-notification
        command: |
          WEBHOOK_URL="{{ secrets.slack_webhook_url | default('') }}"
          if [ -n "$WEBHOOK_URL" ]; then
            curl -X POST "$WEBHOOK_URL" \
              -H 'Content-Type: application/json' \
              -d '{
                "text": "GreenLang Deployment Complete",
                "attachments": [{
                  "color": "good",
                  "fields": [
                    {"title": "Environment", "value": "{{ environment.name }}", "short": true},
                    {"title": "Deployment ID", "value": "{{ DEPLOYMENT_ID }}", "short": true},
                    {"title": "Status", "value": "SUCCESS", "short": true},
                    {"title": "Git Commit", "value": "'$(git rev-parse --short HEAD)'", "short": true}
                  ]
                }]
              }'
          else
            echo "Slack webhook not configured - skipping notification"
          fi
        timeout: 1m
        working_directory: "."
        continue_on_error: true

      - name: create-git-tag
        command: |
          TAG_NAME="deploy-{{ environment.name }}-$(date +%Y%m%d%H%M%S)"
          git tag -a "$TAG_NAME" -m "Deployed to {{ environment.name }} - {{ DEPLOYMENT_ID }}"
          echo "Created tag: $TAG_NAME"
          # Note: Push tags manually or via CI
          # git push origin "$TAG_NAME"
        timeout: 1m
        working_directory: "."
        continue_on_error: true

# =============================================================================
# Quality Gates
# =============================================================================
quality_gates:

  - name: pre-deployment
    phase: 1
    description: Pre-deployment quality checks
    fail_fast: true
    checks:
      - name: terraform-valid
        command: |
          cd deployment/terraform/environments/{{ environment.name }}
          terraform init -backend=false >/dev/null 2>&1
          terraform validate
        expect:
          exit_code: 0

      - name: helm-valid
        command: helm lint deployment/infrastructure/helm/greenlang --strict
        expect:
          exit_code: 0

      - name: no-critical-vulnerabilities
        command: |
          if [ -f /tmp/tfsec-results.json ]; then
            CRITICAL=$(jq '[.results[] | select(.severity == "CRITICAL")] | length' /tmp/tfsec-results.json 2>/dev/null || echo "0")
            [ "$CRITICAL" -eq 0 ]
          fi
        expect:
          exit_code: 0

  - name: post-deployment
    phase: 4
    description: Post-deployment quality checks
    checks:
      - name: pods-running
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          RUNNING=$(kubectl get pods -n greenlang --field-selector=status.phase=Running -o name | wc -l)
          [ "$RUNNING" -gt 0 ]
        expect:
          exit_code: 0

      - name: no-pod-restarts
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          HIGH_RESTARTS=$(kubectl get pods -n greenlang -o jsonpath='{.items[*].status.containerStatuses[*].restartCount}' | tr ' ' '\n' | awk '$1 > 5' | wc -l)
          [ "$HIGH_RESTARTS" -eq 0 ]
        expect:
          exit_code: 0
        continue_on_error: true

      - name: monitoring-healthy
        command: |
          export KUBECONFIG={{ KUBECONFIG_PATH }}
          kubectl get statefulset prometheus-kube-prometheus-stack-prometheus -n monitoring -o jsonpath='{.status.readyReplicas}'
        expect:
          output_gte: 1
        continue_on_error: true

# =============================================================================
# Rollback Procedures
# =============================================================================
rollback:
  global:
    enabled: true
    strategy: phased
    notify_on_trigger: true
    approval_required_for_prod: true

  phases:
    - name: application-rollback
      description: Rollback application deployment
      order: 1
      tasks:
        - deploy-application
      commands:
        - name: helm-rollback
          command: |
            export KUBECONFIG={{ KUBECONFIG_PATH }}
            PREV_REVISION=$(helm history greenlang -n greenlang -o json | jq -r '.[-2].revision // empty')
            if [ -n "$PREV_REVISION" ]; then
              helm rollback greenlang $PREV_REVISION -n greenlang --wait
            else
              echo "No previous revision to rollback to"
            fi
          timeout: 10m

    - name: monitoring-rollback
      description: Rollback monitoring stack
      order: 2
      tasks:
        - deploy-monitoring
      commands:
        - name: helm-rollback-monitoring
          command: |
            export KUBECONFIG={{ KUBECONFIG_PATH }}
            helm rollback kube-prometheus-stack -n monitoring --wait || true
          timeout: 10m

    - name: addons-rollback
      description: Rollback Kubernetes add-ons
      order: 3
      tasks:
        - deploy-k8s-addons
      commands:
        - name: helm-rollback-addons
          command: |
            export KUBECONFIG={{ KUBECONFIG_PATH }}
            helm rollback cert-manager -n cert-manager --wait || true
            helm rollback ingress-nginx -n ingress-nginx --wait || true
            helm rollback external-secrets -n external-secrets --wait || true
          timeout: 15m

    - name: infrastructure-rollback
      description: Rollback infrastructure (requires approval)
      order: 4
      approval_required: true
      warning: "Infrastructure rollback may cause downtime"
      tasks:
        - run-infra-deployment
      commands:
        - name: restore-terraform-state
          command: |
            cd deployment/terraform/environments/{{ environment.name }}

            # Get latest backup
            LATEST_BACKUP=$(aws s3 ls "s3://{{ BACKUP_BUCKET }}/terraform-state-backup-" | sort | tail -1 | awk '{print $4}')

            if [ -n "$LATEST_BACKUP" ]; then
              echo "Restoring from: $LATEST_BACKUP"
              aws s3 cp "s3://{{ BACKUP_BUCKET }}/$LATEST_BACKUP" terraform.tfstate

              terraform init -reconfigure
              terraform refresh -var-file="environments/{{ environment.name }}/terraform.tfvars"
            else
              echo "No backup state found"
            fi
          timeout: 30m

# =============================================================================
# Cleanup
# =============================================================================
cleanup:
  on_success:
    - name: cleanup-temp-files
      command: |
        rm -f /tmp/deployment-record.json
        rm -f /tmp/tfsec-results.json
        rm -f /tmp/deployment-report-final.json

  on_failure:
    - name: collect-diagnostics
      command: |
        export KUBECONFIG={{ KUBECONFIG_PATH }}
        mkdir -p /tmp/diagnostics

        # Collect pod logs
        kubectl logs -l app=greenlang --all-containers --tail=500 -n greenlang > /tmp/diagnostics/pod-logs.txt 2>&1 || true

        # Collect events
        kubectl get events -n greenlang --sort-by='.lastTimestamp' > /tmp/diagnostics/events.txt 2>&1 || true

        # Collect describe
        kubectl describe pods -n greenlang > /tmp/diagnostics/pod-describe.txt 2>&1 || true

        # Package diagnostics
        tar -czf "/tmp/diagnostics-{{ DEPLOYMENT_ID }}.tar.gz" -C /tmp diagnostics/

        # Upload to S3
        aws s3 cp "/tmp/diagnostics-{{ DEPLOYMENT_ID }}.tar.gz" \
          "s3://{{ ARTIFACT_BUCKET }}/diagnostics/{{ DEPLOYMENT_ID }}.tar.gz"

        echo "Diagnostics uploaded to s3://{{ ARTIFACT_BUCKET }}/diagnostics/{{ DEPLOYMENT_ID }}.tar.gz"
      timeout: 5m
      working_directory: "."

# =============================================================================
# Documentation
# =============================================================================
documentation:
  runbook_url: "https://wiki.greenlang.io/runbooks/complete-deployment"
  architecture_url: "https://wiki.greenlang.io/architecture/infrastructure"
  troubleshooting_url: "https://wiki.greenlang.io/troubleshooting/deployment"
  contact:
    team: platform-engineering
    slack: "#greenlang-platform"
    oncall: "https://greenlang.pagerduty.com/schedules/platform"
