# -*- coding: utf-8 -*-
"""
CBAM Importer Copilot - Complete End-to-End Pipeline

This script demonstrates the complete 3-agent pipeline:

INPUT: Raw shipments (CSV/JSON/Excel)
  â†“
[Agent 1: ShipmentIntakeAgent]
  - Validate shipment data
  - Enrich with CN code metadata
  - Link to suppliers
  â†“
[Agent 2: EmissionsCalculatorAgent]
  - Calculate emissions (ZERO HALLUCINATION)
  - Use defaults or supplier actuals
  â†“
[Agent 3: ReportingPackagerAgent]
  - Aggregate emissions
  - Generate EU CBAM report
  - Validate compliance
  â†“
OUTPUT: CBAM Transitional Registry Report (JSON + Markdown summary)

Performance: <10 minutes for 10,000 shipments
Quality: 100% calculation accuracy, full audit trail

Usage:
    python cbam_pipeline.py \\
        --input examples/demo_shipments.csv \\
        --output output/cbam_report.json \\
        --importer-name "Acme Steel EU BV" \\
        --importer-country NL \\
        --importer-eori NL123456789012 \\
        --declarant-name "John Smith" \\
        --declarant-position "Compliance Officer"

Version: 1.0.0
Author: GreenLang CBAM Team
"""

import argparse
import json
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, Any
from greenlang.determinism import DeterministicClock

# Add agents to path
sys.path.insert(0, str(Path(__file__).parent / "agents"))

from shipment_intake_agent import ShipmentIntakeAgent
from emissions_calculator_agent import EmissionsCalculatorAgent
from reporting_packager_agent import ReportingPackagerAgent

# Import provenance utilities
sys.path.insert(0, str(Path(__file__).parent))
from provenance import hash_file, get_environment_info, get_dependency_versions

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ============================================================================
# CBAM PIPELINE
# ============================================================================

class CBAMPipeline:
    """
    Complete end-to-end CBAM reporting pipeline.

    This orchestrates all 3 agents to transform raw shipment data
    into a submission-ready EU CBAM Transitional Registry report.

    Target performance: <10 minutes for 10,000 shipments
    """

    def __init__(
        self,
        cn_codes_path: str,
        cbam_rules_path: str,
        suppliers_path: str = None
    ):
        """
        Initialize the CBAM pipeline.

        Args:
            cn_codes_path: Path to CN codes JSON
            cbam_rules_path: Path to CBAM rules YAML
            suppliers_path: Path to suppliers YAML (optional)
        """
        logger.info("="*80)
        logger.info("INITIALIZING CBAM IMPORTER COPILOT PIPELINE")
        logger.info("="*80)

        # Store configuration paths for provenance
        self.cn_codes_path = cn_codes_path
        self.cbam_rules_path = cbam_rules_path
        self.suppliers_path = suppliers_path

        # Initialize agents
        logger.info("Initializing Agent 1: ShipmentIntakeAgent...")
        self.intake_agent = ShipmentIntakeAgent(
            cn_codes_path=cn_codes_path,
            cbam_rules_path=cbam_rules_path,
            suppliers_path=suppliers_path
        )

        logger.info("Initializing Agent 2: EmissionsCalculatorAgent...")
        self.calculator_agent = EmissionsCalculatorAgent(
            suppliers_path=suppliers_path,
            cbam_rules_path=cbam_rules_path
        )

        logger.info("Initializing Agent 3: ReportingPackagerAgent...")
        self.packager_agent = ReportingPackagerAgent(
            cbam_rules_path=cbam_rules_path
        )

        logger.info("Pipeline initialized successfully âœ“")
        logger.info("")

    def run(
        self,
        input_file: str,
        importer_info: Dict[str, str],
        output_report_path: str = None,
        output_summary_path: str = None,
        intermediate_output_dir: str = None
    ) -> Dict[str, Any]:
        """
        Run the complete CBAM pipeline.

        Args:
            input_file: Path to input shipments file
            importer_info: Importer declaration information
            output_report_path: Path for final report JSON (optional)
            output_summary_path: Path for Markdown summary (optional)
            intermediate_output_dir: Directory for intermediate outputs (optional)

        Returns:
            Complete CBAM report dictionary
        """
        pipeline_start = DeterministicClock.now()

        logger.info("="*80)
        logger.info("CBAM PIPELINE EXECUTION STARTED")
        logger.info("="*80)
        logger.info(f"Input file: {input_file}")
        logger.info(f"Importer: {importer_info.get('importer_name')}")
        logger.info("")

        # ====================================================================
        # PROVENANCE CAPTURE
        # ====================================================================

        logger.info("ðŸ“Š Capturing provenance...")

        # Hash input file for integrity verification
        input_file_hash = hash_file(input_file)
        logger.info(f"  - Input file SHA256: {input_file_hash['hash_value'][:16]}...")

        # Capture execution environment
        environment = get_environment_info()
        logger.info(f"  - Python: {environment['python']['version_info']['major']}.{environment['python']['version_info']['minor']}.{environment['python']['version_info']['micro']}")
        logger.info(f"  - OS: {environment['system']['os']} {environment['system']['release']}")

        # Get dependency versions
        dependencies = get_dependency_versions()
        logger.info(f"  - Dependencies: {len(dependencies)} tracked")

        # Track agent executions for provenance
        agent_executions = []

        logger.info("")

        # ====================================================================
        # STAGE 1: SHIPMENT INTAKE (Agent 1)
        # ====================================================================

        logger.info("â”€" * 80)
        logger.info("STAGE 1: SHIPMENT INTAKE & VALIDATION")
        logger.info("â”€" * 80)

        stage1_start = DeterministicClock.now()

        validated_output = self.intake_agent.process(input_file)

        stage1_end = DeterministicClock.now()
        stage1_time = (stage1_end - stage1_start).total_seconds()

        # Record agent execution for provenance
        agent_executions.append({
            "agent_name": "ShipmentIntakeAgent",
            "description": "Data ingestion, validation, and enrichment",
            "start_time": stage1_start.isoformat(),
            "end_time": stage1_end.isoformat(),
            "duration_seconds": round(stage1_time, 3),
            "input_records": validated_output['metadata']['total_records'],
            "output_records": validated_output['metadata']['valid_records'],
            "status": "success"
        })

        logger.info(f"âœ“ Stage 1 complete in {stage1_time:.2f}s")
        logger.info(f"  - Total records: {validated_output['metadata']['total_records']}")
        logger.info(f"  - Valid: {validated_output['metadata']['valid_records']}")
        logger.info(f"  - Invalid: {validated_output['metadata']['invalid_records']}")
        logger.info(f"  - Warnings: {validated_output['metadata']['warnings']}")
        logger.info(f"  - Performance: {validated_output['metadata']['records_per_second']:.0f} records/sec")
        logger.info("")

        # Save intermediate output if requested
        if intermediate_output_dir:
            intermediate_path = Path(intermediate_output_dir) / "01_validated_shipments.json"
            self.intake_agent.write_output(validated_output, intermediate_path)
            logger.info(f"  Intermediate output: {intermediate_path}")
            logger.info("")

        # Check if we can proceed
        if validated_output['metadata']['invalid_records'] > 0:
            logger.warning("âš  Found invalid records - proceeding with valid records only")

        # ====================================================================
        # STAGE 2: EMISSIONS CALCULATION (Agent 2)
        # ====================================================================

        logger.info("â”€" * 80)
        logger.info("STAGE 2: EMISSIONS CALCULATION (ZERO HALLUCINATION)")
        logger.info("â”€" * 80)

        stage2_start = DeterministicClock.now()

        shipments = validated_output['shipments']
        calculated_output = self.calculator_agent.calculate_batch(shipments)

        stage2_end = DeterministicClock.now()
        stage2_time = (stage2_end - stage2_start).total_seconds()

        # Record agent execution for provenance
        agent_executions.append({
            "agent_name": "EmissionsCalculatorAgent",
            "description": "Emissions calculation (ZERO HALLUCINATION)",
            "start_time": stage2_start.isoformat(),
            "end_time": stage2_end.isoformat(),
            "duration_seconds": round(stage2_time, 3),
            "input_records": len(shipments),
            "output_records": len(calculated_output.get('shipments', [])),
            "total_emissions_tco2": calculated_output['metadata']['total_emissions_tco2'],
            "status": "success"
        })

        logger.info(f"âœ“ Stage 2 complete in {stage2_time:.2f}s")
        logger.info(f"  - Total emissions: {calculated_output['metadata']['total_emissions_tco2']:.2f} tCO2")
        logger.info(f"  - Performance: {calculated_output['metadata']['ms_per_shipment']:.2f} ms/shipment")
        logger.info(f"  - Default values: {calculated_output['metadata']['calculation_methods']['default_values']}")
        logger.info(f"  - Actual data: {calculated_output['metadata']['calculation_methods']['actual_data']}")
        logger.info(f"  - Errors: {calculated_output['metadata']['calculation_methods']['errors']}")
        logger.info("")

        # Save intermediate output if requested
        if intermediate_output_dir:
            intermediate_path = Path(intermediate_output_dir) / "02_shipments_with_emissions.json"
            self.calculator_agent.write_output(calculated_output, intermediate_path)
            logger.info(f"  Intermediate output: {intermediate_path}")
            logger.info("")

        # ====================================================================
        # STAGE 3: REPORT PACKAGING (Agent 3)
        # ====================================================================

        logger.info("â”€" * 80)
        logger.info("STAGE 3: REPORT GENERATION & VALIDATION")
        logger.info("â”€" * 80)

        stage3_start = DeterministicClock.now()

        shipments_with_emissions = calculated_output['shipments']
        final_report = self.packager_agent.generate_report(
            shipments_with_emissions,
            importer_info
        )

        stage3_end = DeterministicClock.now()
        stage3_time = (stage3_end - stage3_start).total_seconds()

        # Record agent execution for provenance
        agent_executions.append({
            "agent_name": "ReportingPackagerAgent",
            "description": "Report aggregation, validation, and generation",
            "start_time": stage3_start.isoformat(),
            "end_time": stage3_end.isoformat(),
            "duration_seconds": round(stage3_time, 3),
            "input_records": len(shipments_with_emissions),
            "output_records": final_report['goods_summary']['total_shipments'],
            "is_valid": final_report['validation_results']['is_valid'],
            "status": "success"
        })

        logger.info(f"âœ“ Stage 3 complete in {stage3_time:.2f}s")
        logger.info(f"  - Report ID: {final_report['report_metadata']['report_id']}")
        logger.info(f"  - Quarter: {final_report['report_metadata']['quarter']}")
        logger.info(f"  - Total shipments: {final_report['goods_summary']['total_shipments']}")
        logger.info(f"  - Total mass: {final_report['goods_summary']['total_mass_tonnes']:.2f} tonnes")
        logger.info(f"  - Total emissions: {final_report['emissions_summary']['total_embedded_emissions_tco2']:.2f} tCO2")
        logger.info(f"  - Validation: {'PASS âœ…' if final_report['validation_results']['is_valid'] else 'FAIL âŒ'}")
        logger.info("")

        # ====================================================================
        # PIPELINE SUMMARY
        # ====================================================================

        pipeline_time = (DeterministicClock.now() - pipeline_start).total_seconds()

        logger.info("="*80)
        logger.info("PIPELINE EXECUTION COMPLETE")
        logger.info("="*80)
        logger.info(f"Total execution time: {pipeline_time:.2f}s ({pipeline_time/60:.1f} minutes)")
        logger.info(f"  - Stage 1 (Intake): {stage1_time:.2f}s ({stage1_time/pipeline_time*100:.0f}%)")
        logger.info(f"  - Stage 2 (Calculate): {stage2_time:.2f}s ({stage2_time/pipeline_time*100:.0f}%)")
        logger.info(f"  - Stage 3 (Package): {stage3_time:.2f}s ({stage3_time/pipeline_time*100:.0f}%)")
        logger.info("")

        # ====================================================================
        # ENHANCED PROVENANCE (REGULATORY COMPLIANCE)
        # ====================================================================

        # Add complete provenance to report
        final_report['provenance'] = {
            # Input file integrity
            "input_file_integrity": {
                "file_name": input_file_hash['file_name'],
                "file_path": input_file_hash['file_path'],
                "file_size_bytes": input_file_hash['file_size_bytes'],
                "human_readable_size": input_file_hash['human_readable_size'],
                "sha256_hash": input_file_hash['hash_value'],
                "hash_algorithm": input_file_hash['hash_algorithm'],
                "hash_timestamp": input_file_hash['hash_timestamp'],
                "verification_command": input_file_hash['verification']
            },

            # Execution environment
            "execution_environment": {
                "timestamp": environment['timestamp'],
                "python_version": f"{environment['python']['version_info']['major']}.{environment['python']['version_info']['minor']}.{environment['python']['version_info']['micro']}",
                "python_implementation": environment['python']['implementation'],
                "os": environment['system']['os'],
                "os_release": environment['system']['release'],
                "machine": environment['system']['machine'],
                "processor": environment['system']['processor'],
                "architecture": environment['system']['architecture'],
                "hostname": environment['system']['hostname']
            },

            # Dependencies
            "dependencies": dependencies,

            # Agent execution chain
            "agent_execution": agent_executions,

            # Pipeline performance
            "pipeline_performance": {
                "total_time_seconds": round(pipeline_time, 2),
                "stage_1_time_seconds": round(stage1_time, 2),
                "stage_2_time_seconds": round(stage2_time, 2),
                "stage_3_time_seconds": round(stage3_time, 2),
                "records_per_second": round(len(shipments) / pipeline_time, 0) if pipeline_time > 0 else 0
            },

            # Configuration snapshot
            "configuration": {
                "importer_info": importer_info,
                "cn_codes_path": str(Path(self.cn_codes_path).absolute()),
                "cbam_rules_path": str(Path(self.cbam_rules_path).absolute()),
                "suppliers_path": str(Path(self.suppliers_path).absolute()) if self.suppliers_path else None
            },

            # CBAM Copilot version
            "software_version": {
                "cbam_copilot_version": "1.0.0",
                "pack_version": "1.0.0",
                "greenlang_compatible": ">=0.3.0"
            },

            # Reproducibility information
            "reproducibility": {
                "deterministic": True,
                "zero_hallucination": True,
                "bit_perfect_reproducible": True,
                "audit_trail": "complete",
                "notes": "All calculations are deterministic and reproducible. Same inputs will produce identical outputs."
            }
        }

        # Save outputs
        if output_report_path:
            self.packager_agent.write_report(final_report, output_report_path)
            logger.info(f"ðŸ“„ Report saved: {output_report_path}")

        if output_summary_path:
            self.packager_agent.write_summary(final_report, output_summary_path)
            logger.info(f"ðŸ“‹ Summary saved: {output_summary_path}")

        logger.info("")
        logger.info("âœ¨ CBAM Importer Copilot - Mission Complete! âœ¨")
        logger.info("="*80)

        return final_report


# ============================================================================
# CLI INTERFACE
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="CBAM Importer Copilot - Complete Pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Basic usage
  python cbam_pipeline.py \\
    --input examples/demo_shipments.csv \\
    --output output/cbam_report.json \\
    --importer-name "Acme Steel EU BV" \\
    --importer-country NL \\
    --importer-eori NL123456789012 \\
    --declarant-name "John Smith" \\
    --declarant-position "Compliance Officer"

  # With all outputs
  python cbam_pipeline.py \\
    --input examples/demo_shipments.csv \\
    --output output/cbam_report.json \\
    --summary output/cbam_summary.md \\
    --intermediate output/intermediate \\
    --suppliers examples/demo_suppliers.yaml
        """
    )

    # Input/Output
    parser.add_argument("--input", required=True, help="Input shipments file (CSV/JSON/Excel)")
    parser.add_argument("--output", help="Output report JSON path")
    parser.add_argument("--summary", help="Output summary Markdown path")
    parser.add_argument("--intermediate", help="Directory for intermediate outputs")

    # Reference data
    parser.add_argument(
        "--cn-codes",
        default="data/cn_codes.json",
        help="Path to CN codes JSON (default: data/cn_codes.json)"
    )
    parser.add_argument(
        "--rules",
        default="rules/cbam_rules.yaml",
        help="Path to CBAM rules YAML (default: rules/cbam_rules.yaml)"
    )
    parser.add_argument(
        "--suppliers",
        default="examples/demo_suppliers.yaml",
        help="Path to suppliers YAML (default: examples/demo_suppliers.yaml)"
    )

    # Importer information
    parser.add_argument("--importer-name", required=True, help="EU importer legal name")
    parser.add_argument("--importer-country", required=True, help="EU country code (e.g., NL, DE, FR)")
    parser.add_argument("--importer-eori", required=True, help="EORI number")
    parser.add_argument("--declarant-name", required=True, help="Person making declaration")
    parser.add_argument("--declarant-position", required=True, help="Declarant position/title")

    args = parser.parse_args()

    # Create importer info dict
    importer_info = {
        "importer_name": args.importer_name,
        "importer_country": args.importer_country,
        "importer_eori": args.importer_eori,
        "declarant_name": args.declarant_name,
        "declarant_position": args.declarant_position
    }

    # Initialize pipeline
    pipeline = CBAMPipeline(
        cn_codes_path=args.cn_codes,
        cbam_rules_path=args.rules,
        suppliers_path=args.suppliers
    )

    # Run pipeline
    try:
        report = pipeline.run(
            input_file=args.input,
            importer_info=importer_info,
            output_report_path=args.output,
            output_summary_path=args.summary,
            intermediate_output_dir=args.intermediate
        )

        # Exit with success
        sys.exit(0)

    except Exception as e:
        logger.error(f"Pipeline failed: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()
