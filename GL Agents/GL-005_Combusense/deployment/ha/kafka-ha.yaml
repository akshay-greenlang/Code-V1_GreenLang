# GL-005 Combusense - Kafka HA Configuration
# High-availability Kafka cluster for real-time control event streaming

apiVersion: v1
kind: ConfigMap
metadata:
  name: gl-005-kafka-config
  namespace: greenlang
data:
  server.properties: |
    # GL-005 Combusense Kafka Configuration
    # Optimized for real-time control system messaging

    # Broker Settings
    broker.id.generation.enable=true

    # Network
    listeners=PLAINTEXT://0.0.0.0:9092
    advertised.listeners=PLAINTEXT://${POD_NAME}.gl-005-kafka-headless.greenlang.svc.cluster.local:9092
    num.network.threads=8
    num.io.threads=16
    socket.send.buffer.bytes=102400
    socket.receive.buffer.bytes=102400
    socket.request.max.bytes=104857600

    # Log Settings
    log.dirs=/var/lib/kafka/data
    num.partitions=6
    default.replication.factor=3
    min.insync.replicas=2

    # Log Retention (7 days for control data)
    log.retention.hours=168
    log.retention.bytes=10737418240
    log.segment.bytes=1073741824
    log.retention.check.interval.ms=300000

    # Log Compaction (for control state topics)
    log.cleaner.enable=true
    log.cleaner.threads=2

    # Zookeeper
    zookeeper.connect=gl-005-zookeeper-0.gl-005-zookeeper-headless:2181,gl-005-zookeeper-1.gl-005-zookeeper-headless:2181,gl-005-zookeeper-2.gl-005-zookeeper-headless:2181
    zookeeper.connection.timeout.ms=18000
    zookeeper.session.timeout.ms=18000

    # Group Coordinator
    group.initial.rebalance.delay.ms=0

    # Transaction (for exactly-once semantics)
    transaction.state.log.replication.factor=3
    transaction.state.log.min.isr=2

    # Offsets
    offsets.topic.replication.factor=3

    # Producer Settings
    message.max.bytes=10485760

    # Controlled Shutdown
    controlled.shutdown.enable=true
    controlled.shutdown.max.retries=3
    controlled.shutdown.retry.backoff.ms=5000

    # Auto Topic Creation (disabled for control)
    auto.create.topics.enable=false

    # Unclean Leader Election (disabled for data safety)
    unclean.leader.election.enable=false

    # Metrics
    metric.reporters=org.apache.kafka.common.metrics.JmxReporter

  topics.yaml: |
    topics:
      - name: gl-005-control-outputs
        partitions: 6
        replication-factor: 3
        config:
          retention.ms: 604800000
          min.insync.replicas: 2
          cleanup.policy: delete

      - name: gl-005-sensor-data
        partitions: 12
        replication-factor: 3
        config:
          retention.ms: 604800000
          min.insync.replicas: 2
          cleanup.policy: delete

      - name: gl-005-alarms
        partitions: 3
        replication-factor: 3
        config:
          retention.ms: 2592000000
          min.insync.replicas: 2
          cleanup.policy: delete

      - name: gl-005-control-state
        partitions: 6
        replication-factor: 3
        config:
          cleanup.policy: compact
          min.insync.replicas: 2
          retention.ms: -1

      - name: gl-005-pid-parameters
        partitions: 3
        replication-factor: 3
        config:
          cleanup.policy: compact
          min.insync.replicas: 2
          retention.ms: -1

      - name: gl-005-cqi-metrics
        partitions: 6
        replication-factor: 3
        config:
          retention.ms: 2592000000
          min.insync.replicas: 2
          cleanup.policy: delete

      - name: gl-005-safety-events
        partitions: 3
        replication-factor: 3
        config:
          retention.ms: 31536000000
          min.insync.replicas: 2
          cleanup.policy: delete

---
# Zookeeper ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: gl-005-zookeeper-config
  namespace: greenlang
data:
  zoo.cfg: |
    dataDir=/var/lib/zookeeper/data
    dataLogDir=/var/lib/zookeeper/log
    tickTime=2000
    initLimit=10
    syncLimit=5
    maxClientCnxns=60
    standaloneEnabled=false
    dynamicConfigFile=/var/lib/zookeeper/data/zoo.cfg.dynamic
    4lw.commands.whitelist=*
    autopurge.snapRetainCount=3
    autopurge.purgeInterval=1

  log4j.properties: |
    log4j.rootLogger=INFO, stdout
    log4j.appender.stdout=org.apache.log4j.ConsoleAppender
    log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
    log4j.appender.stdout.layout.ConversionPattern=%d{ISO8601} [%t] %-5p %c - %m%n

---
# Zookeeper StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: gl-005-zookeeper
  namespace: greenlang
  labels:
    app: gl-005-zookeeper
spec:
  serviceName: gl-005-zookeeper-headless
  replicas: 3
  selector:
    matchLabels:
      app: gl-005-zookeeper
  template:
    metadata:
      labels:
        app: gl-005-zookeeper
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app: gl-005-zookeeper
              topologyKey: kubernetes.io/hostname

      containers:
        - name: zookeeper
          image: confluentinc/cp-zookeeper:7.5.0
          ports:
            - name: client
              containerPort: 2181
            - name: follower
              containerPort: 2888
            - name: election
              containerPort: 3888

          env:
            - name: ZOOKEEPER_SERVER_ID
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: ZOOKEEPER_CLIENT_PORT
              value: "2181"
            - name: ZOOKEEPER_TICK_TIME
              value: "2000"
            - name: ZOOKEEPER_INIT_LIMIT
              value: "10"
            - name: ZOOKEEPER_SYNC_LIMIT
              value: "5"
            - name: ZOOKEEPER_SERVERS
              value: "gl-005-zookeeper-0.gl-005-zookeeper-headless:2888:3888;gl-005-zookeeper-1.gl-005-zookeeper-headless:2888:3888;gl-005-zookeeper-2.gl-005-zookeeper-headless:2888:3888"

          command:
            - sh
            - -c
            - |
              export ZOOKEEPER_SERVER_ID=$((${HOSTNAME##*-} + 1))
              exec /etc/confluent/docker/run

          resources:
            requests:
              cpu: 200m
              memory: 512Mi
            limits:
              cpu: 1000m
              memory: 1Gi

          livenessProbe:
            exec:
              command:
                - sh
                - -c
                - 'echo ruok | nc localhost 2181 | grep imok'
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5

          readinessProbe:
            exec:
              command:
                - sh
                - -c
                - 'echo ruok | nc localhost 2181 | grep imok'
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 5

          volumeMounts:
            - name: data
              mountPath: /var/lib/zookeeper

  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: fast-ssd
        resources:
          requests:
            storage: 20Gi

---
# Kafka StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: gl-005-kafka
  namespace: greenlang
  labels:
    app: gl-005-kafka
spec:
  serviceName: gl-005-kafka-headless
  replicas: 3
  selector:
    matchLabels:
      app: gl-005-kafka
  template:
    metadata:
      labels:
        app: gl-005-kafka
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9404"
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app: gl-005-kafka
              topologyKey: kubernetes.io/hostname
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: gl-005-kafka
                topologyKey: topology.kubernetes.io/zone

      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: topology.kubernetes.io/zone
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
            matchLabels:
              app: gl-005-kafka

      initContainers:
        - name: wait-for-zookeeper
          image: busybox:1.36
          command:
            - sh
            - -c
            - |
              until nc -z gl-005-zookeeper-0.gl-005-zookeeper-headless 2181; do
                echo "Waiting for Zookeeper..."
                sleep 2
              done
              echo "Zookeeper is ready"
          resources:
            limits:
              cpu: 50m
              memory: 32Mi

      containers:
        - name: kafka
          image: confluentinc/cp-kafka:7.5.0
          ports:
            - name: kafka
              containerPort: 9092
            - name: jmx
              containerPort: 9999

          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: KAFKA_BROKER_ID_GENERATION_ENABLE
              value: "true"
            - name: KAFKA_ZOOKEEPER_CONNECT
              value: "gl-005-zookeeper-0.gl-005-zookeeper-headless:2181,gl-005-zookeeper-1.gl-005-zookeeper-headless:2181,gl-005-zookeeper-2.gl-005-zookeeper-headless:2181"
            - name: KAFKA_LISTENERS
              value: "PLAINTEXT://0.0.0.0:9092"
            - name: KAFKA_ADVERTISED_LISTENERS
              value: "PLAINTEXT://$(POD_NAME).gl-005-kafka-headless.greenlang.svc.cluster.local:9092"
            - name: KAFKA_LOG_DIRS
              value: "/var/lib/kafka/data"
            - name: KAFKA_NUM_PARTITIONS
              value: "6"
            - name: KAFKA_DEFAULT_REPLICATION_FACTOR
              value: "3"
            - name: KAFKA_MIN_INSYNC_REPLICAS
              value: "2"
            - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: "3"
            - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
              value: "3"
            - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
              value: "2"
            - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
              value: "false"
            - name: KAFKA_UNCLEAN_LEADER_ELECTION_ENABLE
              value: "false"
            - name: KAFKA_LOG_RETENTION_HOURS
              value: "168"
            - name: KAFKA_JMX_PORT
              value: "9999"
            - name: KAFKA_JMX_HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: KAFKA_HEAP_OPTS
              value: "-Xmx2g -Xms2g"

          resources:
            requests:
              cpu: 500m
              memory: 2Gi
            limits:
              cpu: 2000m
              memory: 4Gi

          livenessProbe:
            exec:
              command:
                - sh
                - -c
                - 'kafka-broker-api-versions --bootstrap-server localhost:9092'
            initialDelaySeconds: 60
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3

          readinessProbe:
            exec:
              command:
                - sh
                - -c
                - 'kafka-broker-api-versions --bootstrap-server localhost:9092'
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3

          volumeMounts:
            - name: data
              mountPath: /var/lib/kafka
            - name: config
              mountPath: /etc/kafka

        - name: jmx-exporter
          image: bitnami/jmx-exporter:0.19.0
          ports:
            - name: metrics
              containerPort: 9404
          env:
            - name: JMX_PORT
              value: "9999"
          args:
            - "9404"
            - "/etc/jmx-exporter/kafka.yaml"
          volumeMounts:
            - name: jmx-config
              mountPath: /etc/jmx-exporter
          resources:
            requests:
              cpu: 50m
              memory: 128Mi
            limits:
              cpu: 200m
              memory: 256Mi

      volumes:
        - name: config
          configMap:
            name: gl-005-kafka-config
        - name: jmx-config
          configMap:
            name: gl-005-kafka-jmx-config

  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: fast-ssd
        resources:
          requests:
            storage: 100Gi

---
# JMX Exporter ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: gl-005-kafka-jmx-config
  namespace: greenlang
data:
  kafka.yaml: |
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    rules:
      - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
        name: kafka_server_$1_$2
        type: GAUGE
        labels:
          clientId: "$3"
          topic: "$4"
          partition: "$5"
      - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)><>Value
        name: kafka_server_$1_$2
        type: GAUGE
        labels:
          clientId: "$3"
          broker: "$4:$5"
      - pattern: kafka.server<type=(.+), name=(.+)><>Value
        name: kafka_server_$1_$2
        type: GAUGE
      - pattern: kafka.server<type=(.+), name=(.+)><>Count
        name: kafka_server_$1_$2_count
        type: COUNTER
      - pattern: kafka.controller<type=(.+), name=(.+)><>Value
        name: kafka_controller_$1_$2
        type: GAUGE

---
# Zookeeper Headless Service
apiVersion: v1
kind: Service
metadata:
  name: gl-005-zookeeper-headless
  namespace: greenlang
  labels:
    app: gl-005-zookeeper
spec:
  clusterIP: None
  selector:
    app: gl-005-zookeeper
  ports:
    - name: client
      port: 2181
      targetPort: 2181
    - name: follower
      port: 2888
      targetPort: 2888
    - name: election
      port: 3888
      targetPort: 3888

---
# Kafka Headless Service
apiVersion: v1
kind: Service
metadata:
  name: gl-005-kafka-headless
  namespace: greenlang
  labels:
    app: gl-005-kafka
spec:
  clusterIP: None
  selector:
    app: gl-005-kafka
  ports:
    - name: kafka
      port: 9092
      targetPort: 9092

---
# Kafka Bootstrap Service
apiVersion: v1
kind: Service
metadata:
  name: gl-005-kafka-bootstrap
  namespace: greenlang
  labels:
    app: gl-005-kafka
spec:
  type: ClusterIP
  selector:
    app: gl-005-kafka
  ports:
    - name: kafka
      port: 9092
      targetPort: 9092

---
# PodDisruptionBudget for Zookeeper
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: gl-005-zookeeper-pdb
  namespace: greenlang
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: gl-005-zookeeper

---
# PodDisruptionBudget for Kafka
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: gl-005-kafka-pdb
  namespace: greenlang
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: gl-005-kafka

---
# Topic Creation Job
apiVersion: batch/v1
kind: Job
metadata:
  name: gl-005-kafka-topic-init
  namespace: greenlang
spec:
  template:
    spec:
      restartPolicy: OnFailure
      initContainers:
        - name: wait-for-kafka
          image: busybox:1.36
          command:
            - sh
            - -c
            - |
              until nc -z gl-005-kafka-0.gl-005-kafka-headless 9092; do
                echo "Waiting for Kafka..."
                sleep 5
              done
              echo "Kafka is ready"
      containers:
        - name: kafka-topics
          image: confluentinc/cp-kafka:7.5.0
          command:
            - sh
            - -c
            - |
              # Control outputs topic
              kafka-topics --bootstrap-server gl-005-kafka-bootstrap:9092 \
                --create --if-not-exists \
                --topic gl-005-control-outputs \
                --partitions 6 --replication-factor 3 \
                --config min.insync.replicas=2 \
                --config retention.ms=604800000

              # Sensor data topic
              kafka-topics --bootstrap-server gl-005-kafka-bootstrap:9092 \
                --create --if-not-exists \
                --topic gl-005-sensor-data \
                --partitions 12 --replication-factor 3 \
                --config min.insync.replicas=2 \
                --config retention.ms=604800000

              # Alarms topic
              kafka-topics --bootstrap-server gl-005-kafka-bootstrap:9092 \
                --create --if-not-exists \
                --topic gl-005-alarms \
                --partitions 3 --replication-factor 3 \
                --config min.insync.replicas=2 \
                --config retention.ms=2592000000

              # Control state topic (compacted)
              kafka-topics --bootstrap-server gl-005-kafka-bootstrap:9092 \
                --create --if-not-exists \
                --topic gl-005-control-state \
                --partitions 6 --replication-factor 3 \
                --config min.insync.replicas=2 \
                --config cleanup.policy=compact \
                --config retention.ms=-1

              # PID parameters topic (compacted)
              kafka-topics --bootstrap-server gl-005-kafka-bootstrap:9092 \
                --create --if-not-exists \
                --topic gl-005-pid-parameters \
                --partitions 3 --replication-factor 3 \
                --config min.insync.replicas=2 \
                --config cleanup.policy=compact \
                --config retention.ms=-1

              # CQI metrics topic
              kafka-topics --bootstrap-server gl-005-kafka-bootstrap:9092 \
                --create --if-not-exists \
                --topic gl-005-cqi-metrics \
                --partitions 6 --replication-factor 3 \
                --config min.insync.replicas=2 \
                --config retention.ms=2592000000

              # Safety events topic (1 year retention)
              kafka-topics --bootstrap-server gl-005-kafka-bootstrap:9092 \
                --create --if-not-exists \
                --topic gl-005-safety-events \
                --partitions 3 --replication-factor 3 \
                --config min.insync.replicas=2 \
                --config retention.ms=31536000000

              echo "All topics created successfully"
