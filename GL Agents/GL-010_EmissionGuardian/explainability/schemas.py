# -*- coding: utf-8 -*-
"""
Explainability Schemas for GL-010 EmissionsGuardian

This module defines all data models for the explainability subsystem,
supporting deterministic, template-based explanations for emissions
calculations, compliance decisions, ML model outputs, and audit trails.

Standards Compliance:
    - EPA 40 CFR Part 75 (Continuous Emissions Monitoring)
    - EPA 40 CFR Part 60 (NSPS)
    - EPA 40 CFR Part 63 (NESHAP)

Zero-Hallucination Principle:
    - All explanations use deterministic templates, NOT LLM generation
    - Provenance tracking via SHA-256 hashes
    - Version-controlled narrative templates
"""

from datetime import datetime
from decimal import Decimal
from enum import Enum
from typing import Any, Dict, List, Optional, Union
import hashlib

from pydantic import BaseModel, Field, field_validator


class AudienceLevel(str, Enum):
    """Target audience for explanation content."""
    TECHNICAL = "technical"
    OPERATIONAL = "operational"
    EXECUTIVE = "executive"
    REGULATORY = "regulatory"
    PUBLIC = "public"


class ExplanationType(str, Enum):
    """Types of explanations generated by the system."""
    CALCULATION = "calculation"
    COMPLIANCE = "compliance"
    ML_PREDICTION = "ml_prediction"
    ANOMALY = "anomaly"
    TREND = "trend"
    EXCEEDANCE = "exceedance"
    AUDIT = "audit"
    NARRATIVE = "narrative"


class ConfidenceLevel(str, Enum):
    """Confidence levels for explanations and predictions."""
    VERY_HIGH = "very_high"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    VERY_LOW = "very_low"


class UnitType(str, Enum):
    """Unit types for emissions measurements."""
    LB_MMBTU = "lb/MMBtu"
    LB_HR = "lb/hr"
    TON_YR = "ton/yr"
    KG_MWH = "kg/MWh"
    PPM = "ppm"
    PERCENT = "%"
    MTCO2E = "mtCO2e"
    KG_GJ = "kg/GJ"


class TemplateVersion(BaseModel):
    """Version tracking for narrative templates."""
    template_id: str = Field(..., description="Unique template identifier")
    version: str = Field(..., description="Semantic version string")
    effective_date: datetime = Field(..., description="When template became effective")
    deprecated_date: Optional[datetime] = Field(None, description="When template was deprecated")
    change_notes: str = Field("", description="Description of changes in this version")
    approved_by: str = Field(..., description="Approver identifier")
    checksum: str = Field(..., description="SHA-256 of template content")

    @field_validator("version")
    @classmethod
    def validate_version_format(cls, v: str) -> str:
        parts = v.split(".")
        if len(parts) < 2:
            raise ValueError("Version must be in semantic format (e.g., 1.0.0)")
        return v

    def is_active(self, reference_date: Optional[datetime] = None) -> bool:
        check_date = reference_date or datetime.now()
        if check_date < self.effective_date:
            return False
        if self.deprecated_date and check_date >= self.deprecated_date:
            return False
        return True


class FeatureContribution(BaseModel):
    """Individual feature contribution to a prediction or decision."""
    feature_name: str = Field(..., description="Name of the contributing feature")
    feature_value: Union[float, str, bool] = Field(..., description="Value of the feature")
    feature_unit: Optional[str] = Field(None, description="Unit of measurement")
    contribution_value: float = Field(..., description="Contribution to prediction")
    contribution_direction: str = Field(..., description="positive or negative")
    contribution_percent: float = Field(..., ge=0, le=100, description="Percent of total")
    rank: int = Field(..., ge=1, description="Importance rank (1=most important)")
    baseline_value: Optional[float] = Field(None, description="Expected/baseline value")
    deviation_from_baseline: Optional[float] = Field(None, description="How much feature deviates")
    explanation_text: str = Field("", description="Human-readable explanation")

    @field_validator("contribution_direction")
    @classmethod
    def validate_direction(cls, v: str) -> str:
        if v.lower() not in ("positive", "negative", "neutral"):
            raise ValueError("Direction must be positive, negative, or neutral")
        return v.lower()


class ReasoningStep(BaseModel):
    """Individual step in a reasoning chain."""
    step_number: int = Field(..., ge=1, description="Step sequence number")
    step_type: str = Field(..., description="Type of step")
    description: str = Field(..., description="Human-readable description")
    input_values: Dict[str, Any] = Field(default_factory=dict)
    output_values: Dict[str, Any] = Field(default_factory=dict)
    formula: Optional[str] = Field(None, description="Mathematical formula applied")
    formula_latex: Optional[str] = Field(None, description="LaTeX formatted formula")
    rule_id: Optional[str] = Field(None, description="Rule ID if rule-based step")
    rule_citation: Optional[str] = Field(None, description="Regulatory citation")
    confidence: Optional[float] = Field(None, ge=0, le=1, description="Step confidence")
    data_source: Optional[str] = Field(None, description="Source of input data")
    provenance_hash: Optional[str] = Field(None, description="Hash for audit trail")
    timestamp: datetime = Field(default_factory=datetime.now)

    @field_validator("step_type")
    @classmethod
    def validate_step_type(cls, v: str) -> str:
        valid_types = {"input", "validation", "lookup", "calculation",
                       "rule_evaluation", "aggregation", "output", "decision"}
        if v.lower() not in valid_types:
            raise ValueError(f"Step type must be one of: {valid_types}")
        return v.lower()


class DecisionTrace(BaseModel):
    """Complete trace of a decision-making process."""
    trace_id: str = Field(..., description="Unique trace identifier")
    decision_type: str = Field(..., description="Type of decision being traced")
    decision_result: str = Field(..., description="Final decision outcome")
    confidence: float = Field(..., ge=0, le=1, description="Overall confidence")
    confidence_level: ConfidenceLevel = Field(..., description="Categorical confidence")
    steps: List[ReasoningStep] = Field(default_factory=list, description="Reasoning steps")
    rules_evaluated: List[str] = Field(default_factory=list, description="Rules evaluated")
    rules_triggered: List[str] = Field(default_factory=list, description="Rules that fired")
    input_data_hash: str = Field(..., description="SHA-256 of input data")
    output_data_hash: str = Field(..., description="SHA-256 of output data")
    start_time: datetime = Field(..., description="When trace started")
    end_time: datetime = Field(default_factory=datetime.now, description="When trace ended")
    processing_time_ms: float = Field(..., ge=0, description="Total processing time")
    agent_id: str = Field(..., description="Agent that made decision")
    agent_version: str = Field(..., description="Version of agent")
    template_versions: List[TemplateVersion] = Field(default_factory=list)

    def calculate_provenance_hash(self) -> str:
        content = (
            f"{self.trace_id}|{self.decision_type}|{self.decision_result}|"
            f"{self.input_data_hash}|{self.output_data_hash}|"
            f"{self.start_time.isoformat()}|{len(self.steps)}"
        )
        return hashlib.sha256(content.encode()).hexdigest()

    def get_step_by_number(self, step_number: int) -> Optional[ReasoningStep]:
        for step in self.steps:
            if step.step_number == step_number:
                return step
        return None

    def get_steps_by_type(self, step_type: str) -> List[ReasoningStep]:
        return [s for s in self.steps if s.step_type == step_type.lower()]


class Explanation(BaseModel):
    """Core explanation model for any explainable output."""
    explanation_id: str = Field(..., description="Unique explanation identifier")
    explanation_type: ExplanationType = Field(..., description="Type of explanation")
    audience_level: AudienceLevel = Field(default=AudienceLevel.TECHNICAL)
    title: str = Field(..., description="Brief title for the explanation")
    summary: str = Field(..., description="Executive summary")
    detailed_explanation: str = Field(..., description="Full detailed explanation")
    key_findings: List[str] = Field(default_factory=list, description="Key takeaways")
    decision_trace: Optional[DecisionTrace] = Field(None, description="Full decision trace")
    feature_contributions: List[FeatureContribution] = Field(default_factory=list)
    regulatory_citations: List[str] = Field(default_factory=list)
    data_sources: List[str] = Field(default_factory=list)
    assumptions: List[str] = Field(default_factory=list)
    limitations: List[str] = Field(default_factory=list)
    confidence: float = Field(..., ge=0, le=1, description="Overall confidence")
    confidence_level: ConfidenceLevel = Field(..., description="Categorical confidence")
    template_version: TemplateVersion = Field(..., description="Template used")
    provenance_hash: str = Field(..., description="SHA-256 for audit trail")
    generated_at: datetime = Field(default_factory=datetime.now)
    generated_by: str = Field(..., description="System/agent that generated")

    def to_audience_format(self, audience: AudienceLevel) -> "Explanation":
        return Explanation(
            explanation_id=f"{self.explanation_id}_{audience.value}",
            explanation_type=self.explanation_type,
            audience_level=audience,
            title=self.title,
            summary=self.summary,
            detailed_explanation=self.detailed_explanation,
            key_findings=self.key_findings,
            decision_trace=self.decision_trace,
            feature_contributions=self.feature_contributions,
            regulatory_citations=self.regulatory_citations,
            data_sources=self.data_sources,
            assumptions=self.assumptions,
            limitations=self.limitations,
            confidence=self.confidence,
            confidence_level=self.confidence_level,
            template_version=self.template_version,
            provenance_hash=self.provenance_hash,
            generated_at=datetime.now(),
            generated_by=self.generated_by
        )


class NarrativeSummary(BaseModel):
    """Natural language narrative summary - deterministic templates only."""
    narrative_id: str = Field(..., description="Unique narrative identifier")
    narrative_type: str = Field(..., description="Type of narrative")
    audience_level: AudienceLevel = Field(default=AudienceLevel.EXECUTIVE)
    title: str = Field(..., description="Narrative title")
    executive_summary: str = Field(..., description="1-2 sentence summary")
    body: str = Field(..., description="Full narrative body")
    key_metrics: Dict[str, Any] = Field(default_factory=dict)
    trend_description: Optional[str] = Field(None)
    recommendations: List[str] = Field(default_factory=list)
    risk_factors: List[str] = Field(default_factory=list)
    template_id: str = Field(..., description="Template used for generation")
    template_version: TemplateVersion = Field(...)
    parameters_used: Dict[str, Any] = Field(default_factory=dict)
    word_count: int = Field(0, ge=0)
    reading_time_minutes: float = Field(0.0, ge=0)
    provenance_hash: str = Field(..., description="SHA-256 for audit")
    generated_at: datetime = Field(default_factory=datetime.now)

    def calculate_provenance_hash(self) -> str:
        content = (
            f"{self.narrative_id}|{self.template_id}|"
            f"{self.template_version.version}|"
            f"{self.body}|{self.generated_at.isoformat()}"
        )
        return hashlib.sha256(content.encode()).hexdigest()


class CalculationStep(BaseModel):
    """Detailed step in an emissions calculation."""
    step_number: int = Field(..., ge=1)
    step_name: str = Field(...)
    description: str = Field(...)
    formula: str = Field(...)
    formula_latex: Optional[str] = Field(None)
    inputs: Dict[str, Decimal] = Field(default_factory=dict)
    input_units: Dict[str, str] = Field(default_factory=dict)
    input_sources: Dict[str, str] = Field(default_factory=dict)
    output_value: Decimal = Field(...)
    output_unit: str = Field(...)
    epa_reference: Optional[str] = Field(None)
    epa_citation: Optional[str] = Field(None)
    uncertainty_value: Optional[Decimal] = Field(None)
    uncertainty_unit: Optional[str] = Field(None)
    uncertainty_basis: Optional[str] = Field(None)
    notes: List[str] = Field(default_factory=list)
    timestamp: datetime = Field(default_factory=datetime.now)


class UnitConversionExplanation(BaseModel):
    """Explanation of a unit conversion in calculations."""
    from_value: Decimal = Field(...)
    from_unit: str = Field(...)
    to_value: Decimal = Field(...)
    to_unit: str = Field(...)
    conversion_factor: Decimal = Field(...)
    conversion_formula: str = Field(...)
    conversion_source: str = Field(...)
    precision_loss: Optional[str] = Field(None)


class UncertaintyExplanation(BaseModel):
    """Explanation of uncertainty propagation in calculations."""
    calculation_id: str = Field(...)
    input_uncertainties: Dict[str, Dict[str, Any]] = Field(default_factory=dict)
    propagation_method: str = Field(...)
    coverage_factor: float = Field(2.0)
    confidence_interval: str = Field("95%")
    combined_uncertainty: Decimal = Field(...)
    expanded_uncertainty: Decimal = Field(...)
    dominant_contributors: List[str] = Field(default_factory=list)
    epa_reference: Optional[str] = Field(None)
    explanation_text: str = Field(...)


class ExplanationRequest(BaseModel):
    """Request for generating an explanation."""
    request_id: str = Field(...)
    explanation_type: ExplanationType = Field(...)
    target_id: str = Field(...)
    target_type: str = Field(...)
    audience_level: AudienceLevel = Field(default=AudienceLevel.TECHNICAL)
    include_trace: bool = Field(True)
    include_ml_details: bool = Field(True)
    include_citations: bool = Field(True)
    include_uncertainty: bool = Field(True)
    max_steps_to_show: Optional[int] = Field(None, ge=1)
    format: str = Field("json")
    requested_by: str = Field(...)
    requested_at: datetime = Field(default_factory=datetime.now)

    @field_validator("format")
    @classmethod
    def validate_format(cls, v: str) -> str:
        valid_formats = {"json", "markdown", "html", "pdf", "text"}
        if v.lower() not in valid_formats:
            raise ValueError(f"Format must be one of: {valid_formats}")
        return v.lower()


class ExplanationResponse(BaseModel):
    """Response containing a generated explanation."""
    request_id: str = Field(...)
    explanation: Explanation = Field(...)
    narrative: Optional[NarrativeSummary] = Field(None)
    calculation_steps: List[CalculationStep] = Field(default_factory=list)
    unit_conversions: List[UnitConversionExplanation] = Field(default_factory=list)
    uncertainty_analysis: Optional[UncertaintyExplanation] = Field(None)
    visualizations: List[Dict[str, Any]] = Field(default_factory=list)
    related_explanations: List[str] = Field(default_factory=list)
    processing_time_ms: float = Field(..., ge=0)
    template_versions_used: List[TemplateVersion] = Field(default_factory=list)
    provenance_hash: str = Field(...)
    generated_at: datetime = Field(default_factory=datetime.now)

    def calculate_provenance_hash(self) -> str:
        content = (
            f"{self.request_id}|{self.explanation.explanation_id}|"
            f"{len(self.calculation_steps)}|"
            f"{self.generated_at.isoformat()}"
        )
        return hashlib.sha256(content.encode()).hexdigest()


class SimilarCase(BaseModel):
    """Similar historical case for ML explanation context."""
    case_id: str = Field(...)
    similarity_score: float = Field(..., ge=0, le=1)
    outcome: str = Field(...)
    key_similarities: List[str] = Field(default_factory=list)
    key_differences: List[str] = Field(default_factory=list)
    timestamp: datetime = Field(...)
    decision_trace_id: Optional[str] = Field(None)


class MLExplanation(BaseModel):
    """Complete ML model explanation with SHAP/LIME."""
    explanation_id: str = Field(...)
    model_id: str = Field(...)
    model_version: str = Field(...)
    prediction_id: str = Field(...)
    prediction_value: Union[float, str, List[float]] = Field(...)
    prediction_probability: Optional[float] = Field(None, ge=0, le=1)
    feature_contributions: List[FeatureContribution] = Field(...)
    baseline_value: float = Field(...)
    shap_values: Optional[Dict[str, float]] = Field(None)
    lime_weights: Optional[Dict[str, float]] = Field(None)
    similar_cases: List[SimilarCase] = Field(default_factory=list)
    confidence: float = Field(..., ge=0, le=1)
    confidence_level: ConfidenceLevel = Field(...)
    explanation_method: str = Field(...)
    audience_level: AudienceLevel = Field(default=AudienceLevel.TECHNICAL)
    summary_text: str = Field(...)
    detailed_text: str = Field(...)
    provenance_hash: str = Field(...)
    generated_at: datetime = Field(default_factory=datetime.now)


class AuditTraceExplanation(BaseModel):
    """Explanation of audit trail and data lineage."""
    trace_id: str = Field(...)
    entity_id: str = Field(...)
    entity_type: str = Field(...)
    lineage_chain: List[Dict[str, Any]] = Field(...)
    change_history: List[Dict[str, Any]] = Field(default_factory=list)
    decision_points: List[DecisionTrace] = Field(default_factory=list)
    data_sources: List[str] = Field(default_factory=list)
    transformations_applied: List[str] = Field(default_factory=list)
    validation_results: List[Dict[str, Any]] = Field(default_factory=list)
    provenance_hashes: List[str] = Field(default_factory=list)
    chain_verified: bool = Field(...)
    verification_timestamp: datetime = Field(default_factory=datetime.now)
    summary_text: str = Field(...)
    regulatory_compliance_status: str = Field(...)
