# =============================================================================
# GL-002 FLAMEGUARD - Pytest Configuration
# =============================================================================
# Global AI Standards Compliance:
# - 85%+ code coverage enforcement (MANDATORY)
# - Test markers for unit, integration, golden, property, chaos tests
# - Timeout enforcement for test reliability
# - Strict marker validation
#
# Version: 2.0.0
# Target: 95+/100 on Global AI Standards
# =============================================================================

[pytest]
# =============================================================================
# Test Discovery
# =============================================================================
testpaths = .
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# =============================================================================
# Python Path
# =============================================================================
pythonpath = ..

# =============================================================================
# Minimum Version
# =============================================================================
minversion = 7.0

# =============================================================================
# Async Configuration
# =============================================================================
asyncio_mode = auto

# =============================================================================
# Test Markers
# =============================================================================
markers =
    # Core test categories (MANDATORY)
    unit: Unit tests - fast, isolated, no external dependencies
    integration: Integration tests - multiple components working together

    # Golden value tests (REQUIRED for Global AI Standards)
    golden: Golden value tests against NIST/IAPWS/ASME reference data

    # Property-based tests (RECOMMENDED)
    property: Property-based tests using Hypothesis
    hypothesis: Alias for property-based tests using Hypothesis

    # Chaos/Resilience tests (RECOMMENDED)
    chaos: Chaos engineering and fault injection tests
    resilience: Resilience and recovery tests

    # Performance and timing
    slow: Slow running tests (>10 seconds)
    performance: Performance benchmark tests

    # Special requirements
    requires_hardware: Tests requiring specific hardware
    requires_network: Tests requiring network access
    requires_database: Tests requiring database connection
    requires_shap: Tests requiring SHAP library
    requires_ml: Tests requiring ML libraries (sklearn, xgboost, etc.)

    # Compliance tests
    compliance: Regulatory compliance validation tests
    asme: ASME PTC 4.1 compliance tests
    nfpa: NFPA 85 compliance tests
    epa: EPA compliance tests

    # Explainability tests
    explainability: SHAP/LIME explainability tests
    shap: SHAP TreeExplainer specific tests

    # Safety tests
    safety: Safety-critical functionality tests
    circuit_breaker: Circuit breaker pattern tests
    interlock: Safety interlock tests

# =============================================================================
# Coverage Configuration (MANDATORY: 85%+)
# =============================================================================
# Coverage is enforced via pytest-cov plugin
# Run with: pytest --cov=.. --cov-fail-under=85

# =============================================================================
# Default Command Line Options
# =============================================================================
addopts =
    -v
    --tb=short
    --strict-markers
    -ra
    --durations=10
    -p no:cacheprovider

# =============================================================================
# Timeout Configuration
# =============================================================================
# Default timeout for all tests (seconds)
timeout = 300

# Method for timeout enforcement
timeout_method = thread

# =============================================================================
# Warning Filters
# =============================================================================
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:shap
    ignore::FutureWarning:sklearn
    ignore::RuntimeWarning:numpy

# =============================================================================
# Console Output
# =============================================================================
console_output_style = progress

# =============================================================================
# Logging Configuration
# =============================================================================
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests/test.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(name)s:%(lineno)d: %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# =============================================================================
# JUnit XML Output (for CI/CD)
# =============================================================================
junit_family = xunit2
junit_logging = all
junit_log_passing_tests = true

# =============================================================================
# Test Collection
# =============================================================================
# Ignore these directories during test collection
norecursedirs =
    .git
    .tox
    .venv
    venv
    __pycache__
    *.egg-info
    build
    dist
    deployment
    htmlcov
    .mypy_cache
    .pytest_cache

# =============================================================================
# Environment Variables
# =============================================================================
env =
    TESTING=1
    PYTHONDONTWRITEBYTECODE=1
    HYPOTHESIS_PROFILE=default

# =============================================================================
# Hypothesis Configuration
# =============================================================================
# Hypothesis profiles are configured in conftest.py
# Default profile settings:
#   - max_examples: 100
#   - deadline: 60000ms
#   - suppress_health_check: [too_slow]
