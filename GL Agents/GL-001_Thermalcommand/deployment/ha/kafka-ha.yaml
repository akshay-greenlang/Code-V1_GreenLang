# GL-001 ThermalCommand - Kafka High Availability Configuration
# 3-broker Kafka cluster with Zookeeper ensemble
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: gl-001-kafka-config
  namespace: greenlang
  labels:
    app: gl-001-kafka
data:
  server.properties: |
    # Broker Configuration
    broker.id=${BROKER_ID}
    listeners=PLAINTEXT://0.0.0.0:9092,SSL://0.0.0.0:9093
    advertised.listeners=PLAINTEXT://${POD_NAME}.gl-001-kafka-headless.greenlang.svc.cluster.local:9092,SSL://${POD_NAME}.gl-001-kafka-headless.greenlang.svc.cluster.local:9093
    listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL

    # Zookeeper
    zookeeper.connect=gl-001-zookeeper-0.gl-001-zookeeper-headless.greenlang.svc.cluster.local:2181,gl-001-zookeeper-1.gl-001-zookeeper-headless.greenlang.svc.cluster.local:2181,gl-001-zookeeper-2.gl-001-zookeeper-headless.greenlang.svc.cluster.local:2181/gl-001
    zookeeper.connection.timeout.ms=18000
    zookeeper.session.timeout.ms=18000

    # Log Directories
    log.dirs=/var/lib/kafka/data
    num.partitions=8
    default.replication.factor=3
    min.insync.replicas=2

    # Log Retention
    log.retention.hours=168
    log.retention.bytes=107374182400
    log.segment.bytes=1073741824
    log.retention.check.interval.ms=300000
    log.cleaner.enable=true

    # Network
    num.network.threads=8
    num.io.threads=16
    socket.send.buffer.bytes=102400
    socket.receive.buffer.bytes=102400
    socket.request.max.bytes=104857600
    max.connections.per.ip=1000
    connections.max.idle.ms=600000

    # Replication
    num.replica.fetchers=4
    replica.fetch.min.bytes=1
    replica.fetch.max.bytes=10485760
    replica.lag.time.max.ms=30000
    replica.socket.timeout.ms=30000
    replica.socket.receive.buffer.bytes=65536

    # Producer/Consumer
    message.max.bytes=10485760
    replica.fetch.max.bytes=10485760

    # Offsets
    offsets.topic.replication.factor=3
    offsets.topic.num.partitions=50
    offsets.retention.minutes=10080

    # Transaction
    transaction.state.log.replication.factor=3
    transaction.state.log.min.isr=2
    transaction.max.timeout.ms=900000

    # Group Coordinator
    group.initial.rebalance.delay.ms=3000

    # SSL (if enabled)
    ssl.keystore.location=/etc/kafka/secrets/kafka.keystore.jks
    ssl.keystore.password=${SSL_KEYSTORE_PASSWORD}
    ssl.key.password=${SSL_KEY_PASSWORD}
    ssl.truststore.location=/etc/kafka/secrets/kafka.truststore.jks
    ssl.truststore.password=${SSL_TRUSTSTORE_PASSWORD}

    # Metrics
    metric.reporters=io.prometheus.jmx.JmxExporter
    prometheus.jmx.exporter.port=9404

    # Auto Topic Creation (disabled for production)
    auto.create.topics.enable=false

    # Controlled Shutdown
    controlled.shutdown.enable=true
    controlled.shutdown.max.retries=3
    controlled.shutdown.retry.backoff.ms=5000

  log4j.properties: |
    log4j.rootLogger=INFO, stdout
    log4j.appender.stdout=org.apache.log4j.ConsoleAppender
    log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
    log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n
    log4j.logger.kafka=INFO
    log4j.logger.org.apache.kafka=INFO
    log4j.logger.org.apache.zookeeper=WARN
    log4j.logger.kafka.controller=TRACE
    log4j.logger.state.change.logger=TRACE
---
# Kafka Topics for GL-001
apiVersion: v1
kind: ConfigMap
metadata:
  name: gl-001-kafka-topics
  namespace: greenlang
  labels:
    app: gl-001-kafka
data:
  topics.sh: |
    #!/bin/bash
    BOOTSTRAP_SERVER="gl-001-kafka-0.gl-001-kafka-headless.greenlang.svc.cluster.local:9092"

    # Create topics
    kafka-topics.sh --create --if-not-exists --bootstrap-server $BOOTSTRAP_SERVER \
      --topic gl001.telemetry.normalized --partitions 8 --replication-factor 3 \
      --config min.insync.replicas=2 --config retention.ms=604800000

    kafka-topics.sh --create --if-not-exists --bootstrap-server $BOOTSTRAP_SERVER \
      --topic gl001.plan.dispatch --partitions 4 --replication-factor 3 \
      --config min.insync.replicas=2 --config retention.ms=604800000

    kafka-topics.sh --create --if-not-exists --bootstrap-server $BOOTSTRAP_SERVER \
      --topic gl001.actions.recommendations --partitions 4 --replication-factor 3 \
      --config min.insync.replicas=2 --config retention.ms=604800000

    kafka-topics.sh --create --if-not-exists --bootstrap-server $BOOTSTRAP_SERVER \
      --topic gl001.safety.events --partitions 4 --replication-factor 3 \
      --config min.insync.replicas=2 --config retention.ms=604800000

    kafka-topics.sh --create --if-not-exists --bootstrap-server $BOOTSTRAP_SERVER \
      --topic gl001.maintenance.triggers --partitions 4 --replication-factor 3 \
      --config min.insync.replicas=2 --config retention.ms=604800000

    kafka-topics.sh --create --if-not-exists --bootstrap-server $BOOTSTRAP_SERVER \
      --topic gl001.explainability.reports --partitions 4 --replication-factor 3 \
      --config min.insync.replicas=2 --config retention.ms=604800000

    kafka-topics.sh --create --if-not-exists --bootstrap-server $BOOTSTRAP_SERVER \
      --topic gl001.audit.log --partitions 8 --replication-factor 3 \
      --config min.insync.replicas=2 --config retention.ms=220752000000 \
      --config cleanup.policy=delete

    echo "Topics created successfully"
---
apiVersion: v1
kind: Secret
metadata:
  name: gl-001-kafka-credentials
  namespace: greenlang
  labels:
    app: gl-001-kafka
type: Opaque
stringData:
  brokers: "gl-001-kafka-0.gl-001-kafka-headless.greenlang.svc.cluster.local:9092,gl-001-kafka-1.gl-001-kafka-headless.greenlang.svc.cluster.local:9092,gl-001-kafka-2.gl-001-kafka-headless.greenlang.svc.cluster.local:9092"
  username: "gl-001-producer"
  password: "${KAFKA_PASSWORD}"
  ssl-keystore-password: "${SSL_KEYSTORE_PASSWORD}"
  ssl-key-password: "${SSL_KEY_PASSWORD}"
  ssl-truststore-password: "${SSL_TRUSTSTORE_PASSWORD}"
---
# Zookeeper StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: gl-001-zookeeper
  namespace: greenlang
  labels:
    app: gl-001-zookeeper
spec:
  serviceName: gl-001-zookeeper-headless
  replicas: 3
  selector:
    matchLabels:
      app: gl-001-zookeeper
  template:
    metadata:
      labels:
        app: gl-001-zookeeper
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9404"
    spec:
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
        runAsNonRoot: true
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app: gl-001-zookeeper
              topologyKey: topology.kubernetes.io/zone
      containers:
        - name: zookeeper
          image: confluentinc/cp-zookeeper:7.5.0
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 2181
              name: client
            - containerPort: 2888
              name: server
            - containerPort: 3888
              name: election
          env:
            - name: ZOOKEEPER_SERVER_ID
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: ZOOKEEPER_CLIENT_PORT
              value: "2181"
            - name: ZOOKEEPER_TICK_TIME
              value: "2000"
            - name: ZOOKEEPER_INIT_LIMIT
              value: "10"
            - name: ZOOKEEPER_SYNC_LIMIT
              value: "5"
            - name: ZOOKEEPER_SERVERS
              value: "gl-001-zookeeper-0.gl-001-zookeeper-headless.greenlang.svc.cluster.local:2888:3888;gl-001-zookeeper-1.gl-001-zookeeper-headless.greenlang.svc.cluster.local:2888:3888;gl-001-zookeeper-2.gl-001-zookeeper-headless.greenlang.svc.cluster.local:2888:3888"
            - name: ZOOKEEPER_4LW_COMMANDS_WHITELIST
              value: "ruok,stat,srvr,mntr"
          command:
            - bash
            - -c
            - |
              # Extract server ID from pod name
              HOSTNAME=$(hostname)
              SERVER_ID=${HOSTNAME##*-}
              export ZOOKEEPER_SERVER_ID=$((SERVER_ID + 1))
              exec /etc/confluent/docker/run
          resources:
            requests:
              cpu: 250m
              memory: 512Mi
            limits:
              cpu: 500m
              memory: 1Gi
          volumeMounts:
            - name: data
              mountPath: /var/lib/zookeeper/data
            - name: log
              mountPath: /var/lib/zookeeper/log
          livenessProbe:
            exec:
              command:
                - sh
                - -c
                - echo ruok | nc localhost 2181 | grep imok
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            exec:
              command:
                - sh
                - -c
                - echo ruok | nc localhost 2181 | grep imok
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 3
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL

  volumeClaimTemplates:
    - metadata:
        name: data
        labels:
          app: gl-001-zookeeper
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: gp3
        resources:
          requests:
            storage: 10Gi
    - metadata:
        name: log
        labels:
          app: gl-001-zookeeper
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: gp3
        resources:
          requests:
            storage: 10Gi
---
# Kafka StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: gl-001-kafka
  namespace: greenlang
  labels:
    app: gl-001-kafka
spec:
  serviceName: gl-001-kafka-headless
  replicas: 3
  selector:
    matchLabels:
      app: gl-001-kafka
  template:
    metadata:
      labels:
        app: gl-001-kafka
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9404"
    spec:
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
        runAsNonRoot: true
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app: gl-001-kafka
              topologyKey: topology.kubernetes.io/zone
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: gl-001-kafka
                topologyKey: kubernetes.io/hostname
      terminationGracePeriodSeconds: 120
      initContainers:
        - name: wait-for-zookeeper
          image: busybox:1.36
          command:
            - sh
            - -c
            - |
              until echo ruok | nc gl-001-zookeeper-0.gl-001-zookeeper-headless.greenlang.svc.cluster.local 2181 | grep imok; do
                echo "Waiting for Zookeeper..."
                sleep 2
              done
              echo "Zookeeper is ready"
      containers:
        - name: kafka
          image: confluentinc/cp-kafka:7.5.0
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 9092
              name: plaintext
            - containerPort: 9093
              name: ssl
            - containerPort: 9404
              name: jmx
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: KAFKA_HEAP_OPTS
              value: "-Xmx2g -Xms2g"
            - name: KAFKA_ZOOKEEPER_CONNECT
              value: "gl-001-zookeeper-0.gl-001-zookeeper-headless.greenlang.svc.cluster.local:2181,gl-001-zookeeper-1.gl-001-zookeeper-headless.greenlang.svc.cluster.local:2181,gl-001-zookeeper-2.gl-001-zookeeper-headless.greenlang.svc.cluster.local:2181/gl-001"
            - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
              value: "PLAINTEXT:PLAINTEXT,SSL:SSL"
            - name: KAFKA_INTER_BROKER_LISTENER_NAME
              value: "PLAINTEXT"
            - name: KAFKA_DEFAULT_REPLICATION_FACTOR
              value: "3"
            - name: KAFKA_MIN_INSYNC_REPLICAS
              value: "2"
            - name: KAFKA_NUM_PARTITIONS
              value: "8"
            - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: "3"
            - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
              value: "3"
            - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
              value: "2"
            - name: KAFKA_LOG_RETENTION_HOURS
              value: "168"
            - name: KAFKA_LOG_SEGMENT_BYTES
              value: "1073741824"
            - name: KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS
              value: "300000"
            - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
              value: "false"
            - name: KAFKA_CONTROLLED_SHUTDOWN_ENABLE
              value: "true"
            - name: KAFKA_JMX_PORT
              value: "9999"
            - name: KAFKA_JMX_HOSTNAME
              value: "localhost"
          command:
            - bash
            - -c
            - |
              HOSTNAME=$(hostname)
              BROKER_ID=${HOSTNAME##*-}
              export KAFKA_BROKER_ID=$BROKER_ID
              export KAFKA_ADVERTISED_LISTENERS="PLAINTEXT://${HOSTNAME}.gl-001-kafka-headless.greenlang.svc.cluster.local:9092"
              export KAFKA_LISTENERS="PLAINTEXT://0.0.0.0:9092"
              exec /etc/confluent/docker/run
          resources:
            requests:
              cpu: 500m
              memory: 2Gi
            limits:
              cpu: 2000m
              memory: 4Gi
          volumeMounts:
            - name: data
              mountPath: /var/lib/kafka/data
            - name: config
              mountPath: /etc/kafka/config
          livenessProbe:
            exec:
              command:
                - sh
                - -c
                - kafka-broker-api-versions --bootstrap-server localhost:9092 | grep ApiVersion
            initialDelaySeconds: 60
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3
          readinessProbe:
            exec:
              command:
                - sh
                - -c
                - kafka-broker-api-versions --bootstrap-server localhost:9092 | grep ApiVersion
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          lifecycle:
            preStop:
              exec:
                command:
                  - sh
                  - -c
                  - |
                    echo "Graceful shutdown initiated"
                    # Wait for in-flight messages
                    sleep 30
                    echo "Shutdown complete"

        - name: jmx-exporter
          image: bitnami/jmx-exporter:0.19.0
          ports:
            - containerPort: 9404
              name: metrics
          env:
            - name: JMX_PORT
              value: "9999"
          args:
            - "9404"
            - /etc/jmx-exporter/jmx-kafka.yaml
          volumeMounts:
            - name: jmx-config
              mountPath: /etc/jmx-exporter
          resources:
            requests:
              cpu: 50m
              memory: 64Mi
            limits:
              cpu: 100m
              memory: 128Mi
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            capabilities:
              drop:
                - ALL

      volumes:
        - name: config
          configMap:
            name: gl-001-kafka-config
        - name: jmx-config
          configMap:
            name: gl-001-kafka-jmx-config

  volumeClaimTemplates:
    - metadata:
        name: data
        labels:
          app: gl-001-kafka
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: gp3
        resources:
          requests:
            storage: 100Gi
---
# JMX Exporter Config
apiVersion: v1
kind: ConfigMap
metadata:
  name: gl-001-kafka-jmx-config
  namespace: greenlang
  labels:
    app: gl-001-kafka
data:
  jmx-kafka.yaml: |
    hostPort: localhost:9999
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    rules:
      - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
        name: kafka_server_$1_$2
        type: GAUGE
        labels:
          clientId: "$3"
          topic: "$4"
          partition: "$5"
      - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)><>Value
        name: kafka_server_$1_$2
        type: GAUGE
        labels:
          clientId: "$3"
          broker: "$4:$5"
      - pattern: kafka.server<type=(.+), name=(.+)><>Value
        name: kafka_server_$1_$2
        type: GAUGE
      - pattern: kafka.controller<type=(.+), name=(.+)><>Value
        name: kafka_controller_$1_$2
        type: GAUGE
      - pattern: kafka.network<type=(.+), name=(.+)><>Value
        name: kafka_network_$1_$2
        type: GAUGE
      - pattern: kafka.log<type=(.+), name=(.+)><>Value
        name: kafka_log_$1_$2
        type: GAUGE
---
# Zookeeper Headless Service
apiVersion: v1
kind: Service
metadata:
  name: gl-001-zookeeper-headless
  namespace: greenlang
  labels:
    app: gl-001-zookeeper
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 2181
      name: client
    - port: 2888
      name: server
    - port: 3888
      name: election
  selector:
    app: gl-001-zookeeper
---
# Zookeeper Service
apiVersion: v1
kind: Service
metadata:
  name: gl-001-zookeeper
  namespace: greenlang
  labels:
    app: gl-001-zookeeper
spec:
  type: ClusterIP
  ports:
    - port: 2181
      name: client
  selector:
    app: gl-001-zookeeper
---
# Kafka Headless Service
apiVersion: v1
kind: Service
metadata:
  name: gl-001-kafka-headless
  namespace: greenlang
  labels:
    app: gl-001-kafka
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 9092
      name: plaintext
    - port: 9093
      name: ssl
  selector:
    app: gl-001-kafka
---
# Kafka Bootstrap Service
apiVersion: v1
kind: Service
metadata:
  name: gl-001-kafka
  namespace: greenlang
  labels:
    app: gl-001-kafka
spec:
  type: ClusterIP
  ports:
    - port: 9092
      name: plaintext
    - port: 9404
      name: metrics
  selector:
    app: gl-001-kafka
---
# Zookeeper PodDisruptionBudget
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: gl-001-zookeeper-pdb
  namespace: greenlang
  labels:
    app: gl-001-zookeeper
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: gl-001-zookeeper
---
# Kafka PodDisruptionBudget
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: gl-001-kafka-pdb
  namespace: greenlang
  labels:
    app: gl-001-kafka
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: gl-001-kafka
---
# Topic Creation Job
apiVersion: batch/v1
kind: Job
metadata:
  name: gl-001-kafka-topic-init
  namespace: greenlang
  labels:
    app: gl-001-kafka
spec:
  ttlSecondsAfterFinished: 300
  template:
    spec:
      restartPolicy: OnFailure
      containers:
        - name: topic-init
          image: confluentinc/cp-kafka:7.5.0
          command:
            - sh
            - /scripts/topics.sh
          volumeMounts:
            - name: scripts
              mountPath: /scripts
      volumes:
        - name: scripts
          configMap:
            name: gl-001-kafka-topics
            defaultMode: 0755
