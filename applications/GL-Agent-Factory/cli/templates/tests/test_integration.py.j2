"""
Integration Tests for {{ cookiecutter.agent_name }}

Auto-generated by GreenLang Agent Factory
Tests agent behavior with external systems and end-to-end scenarios.
"""

import pytest
import asyncio
from typing import List
from datetime import datetime

from agent import {{ cookiecutter.agent_class_name }}, {{ cookiecutter.agent_class_name }}Input, {{ cookiecutter.agent_class_name }}Output


@pytest.mark.integration
class TestDatabaseIntegration:
    """Tests for database integration."""

    @pytest.mark.skip(reason="Database not configured in test environment")
    def test_emission_factor_lookup(self, agent):
        """Test emission factor lookup from database."""
        # This test requires database configuration
        pass

    @pytest.mark.skip(reason="Database not configured in test environment")
    def test_conversion_factor_retrieval(self, agent):
        """Test conversion factor retrieval from database."""
        pass


@pytest.mark.integration
class TestExternalAPIIntegration:
    """Tests for external API integration."""

    @pytest.mark.skip(reason="External API not available in test environment")
    async def test_erp_data_fetch(self, agent):
        """Test fetching data from ERP system."""
        pass


@pytest.mark.integration
class TestEndToEndScenarios:
    """End-to-end scenario tests."""

    def test_complete_processing_workflow(self, agent, sample_input):
        """Test complete workflow from input to output."""
        # Step 1: Validate input
        validation = agent._validate_input(sample_input)
        assert validation["is_valid"]

        # Step 2: Process
        result = agent.process(sample_input)
        assert result.validation_status == "PASS"

        # Step 3: Verify provenance
        assert len(result.provenance_hash) == 64

        # Step 4: Verify output is serializable
        json_output = result.json()
        assert len(json_output) > 0

    def test_batch_processing(self, agent, valid_inputs):
        """Test processing multiple inputs in sequence."""
        results = []
        for input_data in valid_inputs:
            result = agent.process(input_data)
            results.append(result)

        assert len(results) == len(valid_inputs)
        assert all(r.validation_status == "PASS" for r in results)

    def test_error_recovery(self, agent, sample_input, invalid_inputs):
        """Test that agent recovers after processing errors."""
        # First, trigger an error
        for input_dict, _ in invalid_inputs[:1]:
            try:
                bad_input = {{ cookiecutter.agent_class_name }}Input(**input_dict)
                agent.process(bad_input)
            except Exception:
                pass

        # Then process a valid input - should work
        result = agent.process(sample_input)
        assert result.validation_status == "PASS"


@pytest.mark.integration
class TestConcurrency:
    """Tests for concurrent processing."""

    def test_thread_safety(self, agent, sample_input):
        """Test agent is thread-safe."""
        import concurrent.futures

        def process_input(i):
            return agent.process(sample_input)

        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(process_input, i) for i in range(10)]
            results = [f.result() for f in concurrent.futures.as_completed(futures)]

        # All results should be valid
        assert len(results) == 10
        assert all(r.validation_status == "PASS" for r in results)

        # All provenance hashes should be identical (determinism)
        first_hash = results[0].provenance_hash
        assert all(r.provenance_hash == first_hash for r in results)


@pytest.mark.integration
class TestDataPipeline:
    """Tests for data pipeline integration."""

    def test_input_from_csv(self, agent, tmp_path):
        """Test processing input from CSV file."""
        import csv

        # Create test CSV
        csv_file = tmp_path / "test_input.csv"
        with open(csv_file, "w", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=["field1", "field2"])
            writer.writeheader()
            writer.writerow({"field1": "value1", "field2": "value2"})

        # Read and process
        with open(csv_file) as f:
            reader = csv.DictReader(f)
            for row in reader:
                # Convert CSV row to input model
                # input_data = {{ cookiecutter.agent_class_name }}Input(**row)
                # result = agent.process(input_data)
                pass

    def test_output_to_json(self, agent, sample_input, tmp_path):
        """Test writing output to JSON file."""
        import json

        result = agent.process(sample_input)

        output_file = tmp_path / "test_output.json"
        with open(output_file, "w") as f:
            f.write(result.json())

        # Verify file was written correctly
        with open(output_file) as f:
            loaded = json.load(f)

        assert loaded["provenance_hash"] == result.provenance_hash


@pytest.mark.integration
class TestAuditTrail:
    """Tests for audit trail functionality."""

    def test_provenance_chain(self, agent, valid_inputs):
        """Test that processing creates traceable provenance chain."""
        if len(valid_inputs) < 2:
            pytest.skip("Need at least 2 valid inputs")

        results = [agent.process(inp) for inp in valid_inputs]

        # Each result should have unique provenance
        hashes = [r.provenance_hash for r in results]
        assert len(set(hashes)) == len(hashes), "All provenance hashes should be unique"

    def test_audit_data_completeness(self, agent, sample_input):
        """Test that output contains all required audit data."""
        result = agent.process(sample_input)

        # Required audit fields
        assert hasattr(result, "provenance_hash")
        assert hasattr(result, "processing_time_ms")
        assert hasattr(result, "validation_status")

        # Values should be populated
        assert result.provenance_hash is not None
        assert result.processing_time_ms > 0
        assert result.validation_status in ["PASS", "FAIL"]
