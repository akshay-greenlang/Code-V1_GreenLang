"""
GL-007 FurnacePulse - SHAP TreeExplainer for RUL Predictions

Implements SHAP TreeExplainer for Remaining Useful Life (RUL) prediction
feature attribution, explaining which sensor readings, operating conditions,
and maintenance history drive RUL estimates for furnace components.

Features:
    - TreeExplainer implementation for deterministic SHAP values
    - Waterfall plots for individual prediction breakdown
    - Force plots for interactive feature contribution visualization
    - Feature importance extraction with engineering interpretations
    - Provenance tracking with SHA-256 hashing
    - Batch explanation support for fleet analysis

Reference:
    - Lundberg & Lee, "A Unified Approach to Interpreting Model Predictions", NeurIPS 2017
    - NFPA 86 Standard for Ovens and Furnaces
    - ASME PTC 4.1 for fired steam generators
    - API 530 Calculation of Heater-Tube Thickness
    - API 560 Fired Heaters for General Refinery Service

Zero-Hallucination: All SHAP values are computed deterministically using
TreeExplainer on trained Weibull-based surrogate models, never generated by LLMs.

Example:
    >>> explainer = SHAPRULExplainer(model_version="1.0.0")
    >>> result = explainer.explain_rul_prediction(
    ...     rul_output, sensor_features, maintenance_history
    ... )
    >>> print(f"Top driver: {result.top_drivers[0].feature_name}")
    >>> print(f"Impact: {result.top_drivers[0].engineering_interpretation}")
    >>> # Generate visualizations
    >>> waterfall_path = explainer.generate_waterfall_plot(result)
    >>> force_plot_html = explainer.generate_force_plot(result)
"""

from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Tuple, Union
from enum import Enum
import hashlib
import json
import logging
import math

import numpy as np
import io
import base64
from pathlib import Path
import uuid

try:
    import shap
    HAS_SHAP = True
except ImportError:
    HAS_SHAP = False

try:
    from sklearn.ensemble import (
        RandomForestRegressor,
        GradientBoostingRegressor,
        ExtraTreesRegressor,
    )
    from sklearn.preprocessing import StandardScaler
    HAS_SKLEARN = True
except ImportError:
    HAS_SKLEARN = False

try:
    import matplotlib
    matplotlib.use('Agg')  # Non-interactive backend for server environments
    import matplotlib.pyplot as plt
    HAS_MATPLOTLIB = True
except ImportError:
    HAS_MATPLOTLIB = False

from pydantic import BaseModel, Field

logger = logging.getLogger(__name__)


# =============================================================================
# ENUMS AND DATA CLASSES
# =============================================================================

class RULOutputType(Enum):
    """Type of RUL prediction output being explained."""

    RUL_HOURS = "rul_hours"
    FAILURE_PROBABILITY = "failure_probability"
    HAZARD_RATE = "hazard_rate"
    HEALTH_INDEX = "health_index"
    RISK_CATEGORY = "risk_category"
    NEXT_INSPECTION = "next_inspection"


class RULFeatureCategory(Enum):
    """Category of RUL prediction features."""

    OPERATING_TIME = "operating_time"
    TEMPERATURE = "temperature"
    PRESSURE = "pressure"
    VIBRATION = "vibration"
    CORROSION = "corrosion"
    MAINTENANCE = "maintenance"
    THERMAL_CYCLING = "thermal_cycling"
    WEIBULL_PARAM = "weibull_parameter"
    DERIVED = "derived"


@dataclass
class RULDriverInfo:
    """
    Information about a top driver of RUL predictions.

    Attributes:
        feature_name: Name of the driving feature
        shap_value: SHAP value contribution to RUL prediction
        feature_value: Actual value of the feature
        direction: "increases" or "decreases" RUL
        category: Feature category for grouping
        rank: Importance ranking (1 = most important)
        contribution_percent: Percentage of total explanation
        unit: Engineering unit of the feature
        engineering_interpretation: Domain-specific explanation
        nfpa_reference: Relevant NFPA 86 section (if applicable)
        sensitivity: Sensitivity coefficient (hours RUL per unit feature change)
    """

    feature_name: str
    shap_value: float
    feature_value: float
    direction: str
    category: RULFeatureCategory
    rank: int
    contribution_percent: float
    unit: str = ""
    engineering_interpretation: str = ""
    nfpa_reference: Optional[str] = None
    sensitivity: float = 0.0


@dataclass
class SHAPRULResult:
    """
    Result from SHAP analysis of RUL prediction.

    Attributes:
        component_id: ID of component being analyzed
        component_type: Type of furnace component
        output_type: Type of RUL output explained
        prediction_id: Reference to original prediction
        feature_names: Ordered list of feature names
        shap_values: SHAP values for each feature
        base_value: Expected RUL (model baseline)
        feature_values: Input feature values
        predicted_rul_hours: Predicted RUL in hours
        predicted_risk_category: Predicted risk category
        feature_importance: Aggregated feature importance
        top_drivers: Ranked list of top drivers
        interaction_effects: Pairwise interaction effects
        category_contributions: Contributions by feature category
        degradation_factors: Factors driving degradation
        protective_factors: Factors extending life
        timestamp: Analysis timestamp
        computation_hash: SHA-256 hash for provenance
        model_version: Version of explainer model
    """

    component_id: str
    component_type: str
    output_type: RULOutputType
    prediction_id: str
    feature_names: List[str]
    shap_values: np.ndarray
    base_value: float
    feature_values: np.ndarray
    predicted_rul_hours: float
    predicted_risk_category: str
    feature_importance: Dict[str, float]
    top_drivers: List[RULDriverInfo]
    interaction_effects: Dict[str, Dict[str, float]]
    category_contributions: Dict[str, float]
    degradation_factors: List[RULDriverInfo]
    protective_factors: List[RULDriverInfo]
    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    computation_hash: str = ""
    model_version: str = ""


@dataclass
class GlobalRULExplanation:
    """
    Global explanation aggregated across multiple RUL predictions.

    Attributes:
        component_type: Type of component
        model_version: Version of explainer model
        num_predictions: Number of predictions included
        mean_abs_shap: Mean absolute SHAP by feature
        feature_ranking: Features ranked by importance
        direction_consistency: How consistent is feature direction (0-1)
        critical_features: Features that commonly indicate critical risk
        maintenance_predictors: Features that predict maintenance needs
        typical_ranges: Typical value ranges for key features
        sensitivity_matrix: Sensitivity of RUL to each input
        timestamp: Summary timestamp
        computation_hash: SHA-256 hash for provenance
    """

    component_type: str
    model_version: str
    num_predictions: int
    mean_abs_shap: Dict[str, float]
    feature_ranking: List[str]
    direction_consistency: Dict[str, float]
    critical_features: List[str]
    maintenance_predictors: List[str]
    typical_ranges: Dict[str, Tuple[float, float]]
    sensitivity_matrix: Dict[str, float]
    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    computation_hash: str = ""


# =============================================================================
# SHAP RUL EXPLAINER
# =============================================================================

class SHAPRULExplainer:
    """
    SHAP-based explainer for Remaining Useful Life (RUL) predictions.

    Uses TreeExplainer on Weibull-based surrogate models to attribute
    RUL predictions to input features including operating conditions,
    sensor readings, and maintenance history.

    Key Features:
        - Local explanations for individual RUL predictions
        - Global summaries across component fleet
        - Degradation vs. protective factor identification
        - NFPA 86 compliance context
        - Engineering-relevant interpretations

    Reference:
        NFPA 86 Standard for Ovens and Furnaces
        API 530 Calculation of Heater-Tube Thickness
        API 560 Fired Heaters for General Refinery Service

    Example:
        >>> explainer = SHAPRULExplainer(model_version="1.0.0")
        >>> result = explainer.explain_rul_prediction(
        ...     rul_output, operating_hours=45000, tmt_max=875.0
        ... )
        >>> for driver in result.top_drivers[:5]:
        ...     print(f"{driver.feature_name}: {driver.contribution_percent:.1f}%")
    """

    VERSION = "1.0.0"

    # Engineering interpretations for RUL-relevant features
    ENGINEERING_INTERPRETATIONS = {
        "operating_hours": "Total operating time is primary RUL predictor per Weibull model",
        "tmt_max": "Maximum tube metal temperature affects creep life (API 530)",
        "tmt_avg": "Average TMT indicates sustained thermal stress levels",
        "thermal_cycles": "Thermal cycling causes fatigue damage accumulation",
        "temp_gradient": "Temperature gradients create thermal stress",
        "wall_thickness": "Wall thickness margin determines pressure containment life",
        "corrosion_rate": "Corrosion rate limits remaining wall thickness life",
        "vibration_rms": "Vibration indicates mechanical stress and wear",
        "maintenance_score": "Maintenance quality affects component longevity",
        "weibull_beta": "Weibull shape parameter indicates failure rate behavior",
        "weibull_eta": "Weibull scale parameter represents characteristic life",
    }

    # Feature category mappings
    FEATURE_CATEGORIES = {
        "operating": RULFeatureCategory.OPERATING_TIME,
        "hours": RULFeatureCategory.OPERATING_TIME,
        "age": RULFeatureCategory.OPERATING_TIME,
        "tmt": RULFeatureCategory.TEMPERATURE,
        "temp": RULFeatureCategory.TEMPERATURE,
        "thermal": RULFeatureCategory.TEMPERATURE,
        "t_": RULFeatureCategory.TEMPERATURE,
        "press": RULFeatureCategory.PRESSURE,
        "p_": RULFeatureCategory.PRESSURE,
        "vib": RULFeatureCategory.VIBRATION,
        "corr": RULFeatureCategory.CORROSION,
        "wall": RULFeatureCategory.CORROSION,
        "thickness": RULFeatureCategory.CORROSION,
        "maint": RULFeatureCategory.MAINTENANCE,
        "repair": RULFeatureCategory.MAINTENANCE,
        "cycle": RULFeatureCategory.THERMAL_CYCLING,
        "weibull": RULFeatureCategory.WEIBULL_PARAM,
        "beta": RULFeatureCategory.WEIBULL_PARAM,
        "eta": RULFeatureCategory.WEIBULL_PARAM,
    }

    # Feature units
    FEATURE_UNITS = {
        "operating_hours": "hours",
        "tmt_max": "C",
        "tmt_avg": "C",
        "thermal_cycles": "cycles",
        "temp_gradient": "C/m",
        "wall_thickness": "mm",
        "corrosion_rate": "mm/yr",
        "vibration_rms": "mm/s",
        "maintenance_score": "score",
        "weibull_beta": "-",
        "weibull_eta": "hours",
    }

    # NFPA 86 references for key features
    NFPA_REFERENCES = {
        "tmt_max": "NFPA 86 7.3.2 - Temperature monitoring",
        "flame": "NFPA 86 8.6.3 - Flame supervision",
        "safety": "NFPA 86 8.7 - Safety shutoff systems",
        "purge": "NFPA 86 8.3 - Purge systems",
    }

    def __init__(
        self,
        model_version: str = "1.0.0",
        n_estimators: int = 100,
        max_depth: int = 10,
        use_tree_explainer: bool = True,
        n_background_samples: int = 100,
        random_state: int = 42,
    ) -> None:
        """
        Initialize SHAP RUL Explainer.

        Args:
            model_version: Version identifier for the explainer
            n_estimators: Number of trees in surrogate forest
            max_depth: Maximum tree depth for surrogate model
            use_tree_explainer: Use TreeExplainer (exact, fast for trees)
            n_background_samples: Background samples for KernelSHAP fallback
            random_state: Random seed for reproducibility
        """
        self.model_version = model_version
        self.n_estimators = n_estimators
        self.max_depth = max_depth
        self.use_tree_explainer = use_tree_explainer
        self.n_background_samples = n_background_samples
        self.random_state = random_state

        # Surrogate models by component type
        self._surrogate_models: Dict[str, Any] = {}
        self._scalers: Dict[str, Any] = {}
        self._feature_names: List[str] = []

        # Historical results for global summaries
        self._historical_results: Dict[str, List[SHAPRULResult]] = {}

        # SHAP explainer cache
        self._explainers: Dict[str, Any] = {}

        logger.info(f"Initialized SHAPRULExplainer v{self.VERSION}")

    def explain_rul_prediction(
        self,
        component_id: str,
        component_type: str,
        operating_hours: float,
        weibull_beta: float,
        weibull_eta: float,
        predicted_rul_hours: float,
        predicted_risk_category: str,
        tmt_max_C: Optional[float] = None,
        tmt_avg_C: Optional[float] = None,
        thermal_cycles: Optional[int] = None,
        temp_gradient_C_m: Optional[float] = None,
        wall_thickness_mm: Optional[float] = None,
        corrosion_rate_mm_yr: Optional[float] = None,
        vibration_rms_mm_s: Optional[float] = None,
        maintenance_score: Optional[float] = None,
        additional_features: Optional[Dict[str, float]] = None,
    ) -> SHAPRULResult:
        """
        Explain an RUL prediction using SHAP values.

        Args:
            component_id: Unique component identifier
            component_type: Type of furnace component
            operating_hours: Current operating hours
            weibull_beta: Weibull shape parameter
            weibull_eta: Weibull scale parameter (hours)
            predicted_rul_hours: Predicted remaining useful life
            predicted_risk_category: Predicted risk category
            tmt_max_C: Maximum tube metal temperature (optional)
            tmt_avg_C: Average tube metal temperature (optional)
            thermal_cycles: Number of thermal cycles (optional)
            temp_gradient_C_m: Temperature gradient (optional)
            wall_thickness_mm: Wall thickness (optional)
            corrosion_rate_mm_yr: Corrosion rate (optional)
            vibration_rms_mm_s: Vibration RMS (optional)
            maintenance_score: Maintenance quality score (optional)
            additional_features: Additional features (optional)

        Returns:
            SHAPRULResult with feature attributions
        """
        prediction_id = self._generate_id()

        # Extract features
        features, feature_names = self._extract_features(
            operating_hours=operating_hours,
            weibull_beta=weibull_beta,
            weibull_eta=weibull_eta,
            tmt_max_C=tmt_max_C,
            tmt_avg_C=tmt_avg_C,
            thermal_cycles=thermal_cycles,
            temp_gradient_C_m=temp_gradient_C_m,
            wall_thickness_mm=wall_thickness_mm,
            corrosion_rate_mm_yr=corrosion_rate_mm_yr,
            vibration_rms_mm_s=vibration_rms_mm_s,
            maintenance_score=maintenance_score,
            additional_features=additional_features,
        )
        self._feature_names = feature_names

        # Build or retrieve surrogate model
        if component_type not in self._surrogate_models:
            self._build_surrogate_model(
                features, predicted_rul_hours, component_type
            )

        # Calculate SHAP values
        shap_values, base_value = self._calculate_shap_values(
            features, component_type
        )

        # Calculate feature importance
        feature_importance = self._calculate_feature_importance(
            shap_values, feature_names
        )

        # Identify top drivers
        top_drivers = self._identify_top_drivers(
            shap_values, features, feature_names, predicted_rul_hours, k=10
        )

        # Calculate interaction effects
        interaction_effects = self._calculate_interactions(
            features, feature_names, shap_values
        )

        # Calculate category contributions
        category_contributions = self._calculate_category_contributions(
            shap_values, feature_names
        )

        # Identify degradation vs protective factors
        degradation_factors = [d for d in top_drivers if d.direction == "decreases"]
        protective_factors = [d for d in top_drivers if d.direction == "increases"]

        # Compute provenance hash
        computation_hash = self._compute_hash(
            features, shap_values, feature_importance, predicted_rul_hours
        )

        result = SHAPRULResult(
            component_id=component_id,
            component_type=component_type,
            output_type=RULOutputType.RUL_HOURS,
            prediction_id=prediction_id,
            feature_names=feature_names,
            shap_values=shap_values,
            base_value=base_value,
            feature_values=features,
            predicted_rul_hours=predicted_rul_hours,
            predicted_risk_category=predicted_risk_category,
            feature_importance=feature_importance,
            top_drivers=top_drivers,
            interaction_effects=interaction_effects,
            category_contributions=category_contributions,
            degradation_factors=degradation_factors,
            protective_factors=protective_factors,
            computation_hash=computation_hash,
            model_version=self.model_version,
        )

        # Store for global analysis
        if component_type not in self._historical_results:
            self._historical_results[component_type] = []
        self._historical_results[component_type].append(result)

        logger.info(
            f"Explained RUL prediction for {component_id} "
            f"({component_type}): {predicted_rul_hours:.0f}h"
        )

        return result

    def explain_batch(
        self,
        predictions: List[Dict[str, Any]],
    ) -> List[SHAPRULResult]:
        """
        Explain a batch of RUL predictions.

        Args:
            predictions: List of prediction dictionaries with required fields

        Returns:
            List of SHAP RUL results
        """
        results = []

        for pred in predictions:
            try:
                result = self.explain_rul_prediction(**pred)
                results.append(result)
            except Exception as e:
                logger.error(f"Failed to explain prediction: {e}")

        return results

    def generate_global_explanation(
        self,
        component_type: str,
        results: Optional[List[SHAPRULResult]] = None,
    ) -> GlobalRULExplanation:
        """
        Generate global explanation across multiple predictions.

        Args:
            component_type: Type of component to summarize
            results: List of SHAP results (uses historical if None)

        Returns:
            GlobalRULExplanation with aggregated insights
        """
        if results is None:
            results = self._historical_results.get(component_type, [])

        if not results:
            logger.warning(f"No results available for {component_type}")
            return self._create_empty_global_explanation(component_type)

        # Aggregate SHAP values
        all_shap_values = np.array([r.shap_values for r in results])
        all_feature_values = np.array([r.feature_values for r in results])
        feature_names = results[0].feature_names

        # Mean absolute SHAP
        mean_abs_shap = {}
        for i, name in enumerate(feature_names):
            mean_abs_shap[name] = round(
                float(np.mean(np.abs(all_shap_values[:, i]))), 2
            )

        # Feature ranking
        feature_ranking = sorted(
            mean_abs_shap.keys(),
            key=lambda x: mean_abs_shap[x],
            reverse=True
        )

        # Direction consistency
        direction_consistency = {}
        for i, name in enumerate(feature_names):
            values = all_shap_values[:, i]
            positive_ratio = np.mean(values > 0)
            consistency = max(positive_ratio, 1 - positive_ratio)
            direction_consistency[name] = round(float(consistency), 4)

        # Critical features (high importance + decreases RUL consistently)
        critical_features = []
        for i, name in enumerate(feature_names):
            if mean_abs_shap[name] > np.percentile(list(mean_abs_shap.values()), 75):
                negative_ratio = np.mean(all_shap_values[:, i] < 0)
                if negative_ratio > 0.7:  # Consistently decreases RUL
                    critical_features.append(name)

        # Maintenance predictors (features that indicate maintenance needs)
        maintenance_predictors = []
        for i, name in enumerate(feature_names):
            if any(kw in name.lower() for kw in ["maint", "condition", "health", "wear"]):
                maintenance_predictors.append(name)

        # Typical ranges
        typical_ranges = {}
        for i, name in enumerate(feature_names):
            values = all_feature_values[:, i]
            typical_ranges[name] = (
                round(float(np.percentile(values, 10)), 2),
                round(float(np.percentile(values, 90)), 2)
            )

        # Sensitivity matrix (hours RUL per unit feature)
        sensitivity_matrix = self._calculate_global_sensitivity(results)

        # Compute hash
        computation_hash = self._compute_global_hash(
            mean_abs_shap, feature_ranking, len(results)
        )

        return GlobalRULExplanation(
            component_type=component_type,
            model_version=self.model_version,
            num_predictions=len(results),
            mean_abs_shap=mean_abs_shap,
            feature_ranking=feature_ranking,
            direction_consistency=direction_consistency,
            critical_features=critical_features,
            maintenance_predictors=maintenance_predictors,
            typical_ranges=typical_ranges,
            sensitivity_matrix=sensitivity_matrix,
            computation_hash=computation_hash,
        )

    def get_maintenance_insights(
        self,
        result: SHAPRULResult,
    ) -> Dict[str, Any]:
        """
        Extract actionable maintenance insights from SHAP analysis.

        Args:
            result: SHAP RUL result

        Returns:
            Dictionary with maintenance recommendations
        """
        insights = {
            "component_id": result.component_id,
            "predicted_rul_hours": result.predicted_rul_hours,
            "risk_category": result.predicted_risk_category,
            "primary_concerns": [],
            "recommended_actions": [],
            "monitoring_priorities": [],
            "nfpa_compliance_notes": [],
        }

        # Analyze degradation factors
        for factor in result.degradation_factors[:3]:
            concern = {
                "feature": factor.feature_name,
                "current_value": factor.feature_value,
                "unit": factor.unit,
                "impact": f"Reduces RUL by {abs(factor.shap_value):.0f} hours",
                "interpretation": factor.engineering_interpretation,
            }
            insights["primary_concerns"].append(concern)

            # Generate recommended action
            if "temp" in factor.feature_name.lower() or "tmt" in factor.feature_name.lower():
                insights["recommended_actions"].append(
                    "Review firing rate and burner distribution to reduce hot spots"
                )
            elif "corr" in factor.feature_name.lower():
                insights["recommended_actions"].append(
                    "Schedule ultrasonic thickness measurement"
                )
            elif "vib" in factor.feature_name.lower():
                insights["recommended_actions"].append(
                    "Investigate vibration source - check fan balance and tube supports"
                )

            # NFPA references
            if factor.nfpa_reference:
                insights["nfpa_compliance_notes"].append(factor.nfpa_reference)

        # Monitoring priorities
        for driver in result.top_drivers[:5]:
            priority = {
                "feature": driver.feature_name,
                "importance_rank": driver.rank,
                "sensitivity": driver.sensitivity,
                "recommended_interval": self._suggest_monitoring_interval(driver),
            }
            insights["monitoring_priorities"].append(priority)

        return insights

    def _extract_features(
        self,
        operating_hours: float,
        weibull_beta: float,
        weibull_eta: float,
        tmt_max_C: Optional[float],
        tmt_avg_C: Optional[float],
        thermal_cycles: Optional[int],
        temp_gradient_C_m: Optional[float],
        wall_thickness_mm: Optional[float],
        corrosion_rate_mm_yr: Optional[float],
        vibration_rms_mm_s: Optional[float],
        maintenance_score: Optional[float],
        additional_features: Optional[Dict[str, float]],
    ) -> Tuple[np.ndarray, List[str]]:
        """Extract numerical feature array from inputs."""
        features = []
        names = []

        # Core Weibull features (always included)
        features.extend([
            operating_hours,
            weibull_beta,
            weibull_eta,
            operating_hours / weibull_eta,  # Normalized age
        ])
        names.extend([
            "operating_hours",
            "weibull_beta",
            "weibull_eta",
            "normalized_age",
        ])

        # Optional temperature features
        if tmt_max_C is not None:
            features.append(tmt_max_C)
            names.append("tmt_max_C")
        if tmt_avg_C is not None:
            features.append(tmt_avg_C)
            names.append("tmt_avg_C")
        if temp_gradient_C_m is not None:
            features.append(temp_gradient_C_m)
            names.append("temp_gradient_C_m")

        # Thermal cycling
        if thermal_cycles is not None:
            features.append(float(thermal_cycles))
            names.append("thermal_cycles")

        # Corrosion features
        if wall_thickness_mm is not None:
            features.append(wall_thickness_mm)
            names.append("wall_thickness_mm")
        if corrosion_rate_mm_yr is not None:
            features.append(corrosion_rate_mm_yr)
            names.append("corrosion_rate_mm_yr")

        # Mechanical features
        if vibration_rms_mm_s is not None:
            features.append(vibration_rms_mm_s)
            names.append("vibration_rms_mm_s")

        # Maintenance features
        if maintenance_score is not None:
            features.append(maintenance_score)
            names.append("maintenance_score")

        # Additional features
        if additional_features:
            for name, value in sorted(additional_features.items()):
                features.append(value)
                names.append(name)

        return np.array(features), names

    def _build_surrogate_model(
        self,
        features: np.ndarray,
        predicted_rul: float,
        component_type: str,
    ) -> None:
        """Build Weibull-based surrogate model for SHAP analysis."""
        if not HAS_SKLEARN:
            logger.warning("sklearn not available, using simplified model")
            self._surrogate_models[component_type] = None
            return

        n_samples = 300
        n_features = len(features)

        # Generate synthetic training data with physics-informed variations
        np.random.seed(self.random_state)
        X_train = np.zeros((n_samples, n_features))
        y_train = np.zeros(n_samples)

        for i in range(n_samples):
            # Perturb features around current values
            perturbation = np.random.randn(n_features) * 0.2
            X_train[i] = features * (1 + perturbation)
            X_train[i] = np.maximum(X_train[i], 0.01)

            # Generate physics-based RUL target using Weibull model
            # Find indices for key features
            operating_idx = self._feature_names.index("operating_hours") if "operating_hours" in self._feature_names else 0
            eta_idx = self._feature_names.index("weibull_eta") if "weibull_eta" in self._feature_names else 2
            beta_idx = self._feature_names.index("weibull_beta") if "weibull_beta" in self._feature_names else 1

            t = X_train[i, operating_idx]
            eta = X_train[i, eta_idx]
            beta = X_train[i, beta_idx]

            # Weibull-based RUL estimate
            # RUL is time until failure probability reaches threshold
            threshold = 0.1
            if eta > 0 and beta > 0:
                t_fail = eta * ((-math.log(1 - threshold)) ** (1.0 / beta))
                base_rul = max(t_fail - t, 0)
            else:
                base_rul = 10000

            # Apply adjustments for other features
            adjustment = 1.0

            # Temperature adjustment
            if "tmt_max_C" in self._feature_names:
                tmt_idx = self._feature_names.index("tmt_max_C")
                tmt = X_train[i, tmt_idx]
                if tmt > 900:  # High TMT reduces RUL
                    adjustment *= max(0.5, 1.0 - (tmt - 900) / 200)

            # Corrosion adjustment
            if "corrosion_rate_mm_yr" in self._feature_names:
                corr_idx = self._feature_names.index("corrosion_rate_mm_yr")
                corr_rate = X_train[i, corr_idx]
                if corr_rate > 0.1:  # High corrosion reduces RUL
                    adjustment *= max(0.3, 1.0 - corr_rate * 2)

            # Thermal cycling adjustment
            if "thermal_cycles" in self._feature_names:
                cycle_idx = self._feature_names.index("thermal_cycles")
                cycles = X_train[i, cycle_idx]
                if cycles > 1000:  # Many cycles reduces RUL
                    adjustment *= max(0.7, 1.0 - (cycles - 1000) / 10000)

            # Maintenance adjustment
            if "maintenance_score" in self._feature_names:
                maint_idx = self._feature_names.index("maintenance_score")
                maint = X_train[i, maint_idx]
                if maint > 70:  # Good maintenance extends RUL
                    adjustment *= 1.0 + (maint - 70) / 200

            y_train[i] = base_rul * adjustment + np.random.randn() * 100

        # Scale features
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_train)
        self._scalers[component_type] = scaler

        # Train surrogate model (Gradient Boosting for good SHAP support)
        model = GradientBoostingRegressor(
            n_estimators=self.n_estimators,
            max_depth=self.max_depth,
            random_state=self.random_state,
            learning_rate=0.1,
        )
        model.fit(X_scaled, y_train)
        self._surrogate_models[component_type] = model

        logger.info(f"Built surrogate model for {component_type}")

    def _calculate_shap_values(
        self,
        features: np.ndarray,
        component_type: str,
    ) -> Tuple[np.ndarray, float]:
        """Calculate SHAP values using TreeExplainer."""
        model = self._surrogate_models.get(component_type)
        scaler = self._scalers.get(component_type)

        if model is None:
            return np.zeros(len(features)), 0.0

        # Scale features
        features_scaled = scaler.transform(features.reshape(1, -1))
        base_pred = float(model.predict(features_scaled)[0])

        try:
            if HAS_SHAP and self.use_tree_explainer:
                # Use cached explainer or create new one
                if component_type not in self._explainers:
                    self._explainers[component_type] = shap.TreeExplainer(model)

                explainer = self._explainers[component_type]
                shap_values = explainer(features_scaled)

                return shap_values.values[0], float(shap_values.base_values[0])
            else:
                # Fallback to permutation importance
                return self._calculate_permutation_importance(
                    features_scaled[0], model, base_pred
                )
        except Exception as e:
            logger.error(f"SHAP calculation failed: {e}")
            return self._calculate_permutation_importance(
                features_scaled[0], model, base_pred
            )

    def _calculate_permutation_importance(
        self,
        features: np.ndarray,
        model: Any,
        base_pred: float,
    ) -> Tuple[np.ndarray, float]:
        """Fallback permutation-based importance calculation."""
        importance = np.zeros(len(features))

        for i in range(len(features)):
            perturbed = features.copy()
            perturbed[i] *= 0.9  # 10% perturbation
            new_pred = model.predict(perturbed.reshape(1, -1))[0]
            importance[i] = base_pred - new_pred

        return importance, base_pred

    def _calculate_feature_importance(
        self,
        shap_values: np.ndarray,
        feature_names: List[str],
    ) -> Dict[str, float]:
        """Calculate aggregated feature importance."""
        importance = {}
        for i, name in enumerate(feature_names):
            importance[name] = round(float(np.abs(shap_values[i])), 2)

        return dict(sorted(
            importance.items(),
            key=lambda x: x[1],
            reverse=True
        ))

    def _identify_top_drivers(
        self,
        shap_values: np.ndarray,
        features: np.ndarray,
        feature_names: List[str],
        predicted_rul: float,
        k: int = 10,
    ) -> List[RULDriverInfo]:
        """Identify top drivers with engineering interpretations."""
        top_drivers = []
        total_abs_shap = np.sum(np.abs(shap_values))

        # Sort by absolute SHAP value
        indices = np.argsort(np.abs(shap_values))[::-1]

        for rank, idx in enumerate(indices[:k], 1):
            name = feature_names[idx]
            shap_val = float(shap_values[idx])
            feat_val = float(features[idx])

            # Determine category
            category = self._categorize_feature(name)

            # Direction (positive SHAP = increases RUL)
            direction = "increases" if shap_val > 0 else "decreases"

            # Contribution percentage
            contribution_pct = (
                abs(shap_val) / total_abs_shap * 100
                if total_abs_shap > 0 else 0.0
            )

            # Get unit
            unit = self.FEATURE_UNITS.get(name, "")

            # Engineering interpretation
            interpretation = self._get_engineering_interpretation(
                name, shap_val, feat_val, category
            )

            # NFPA reference
            nfpa_ref = self._get_nfpa_reference(name)

            # Sensitivity (hours RUL per unit feature change)
            sensitivity = shap_val / (feat_val + 1e-10) if feat_val != 0 else 0.0

            top_drivers.append(RULDriverInfo(
                feature_name=name,
                shap_value=round(shap_val, 2),
                feature_value=round(feat_val, 4),
                direction=direction,
                category=category,
                rank=rank,
                contribution_percent=round(contribution_pct, 2),
                unit=unit,
                engineering_interpretation=interpretation,
                nfpa_reference=nfpa_ref,
                sensitivity=round(sensitivity, 4),
            ))

        return top_drivers

    def _calculate_interactions(
        self,
        features: np.ndarray,
        feature_names: List[str],
        shap_values: np.ndarray,
    ) -> Dict[str, Dict[str, float]]:
        """Calculate pairwise feature interactions."""
        interactions: Dict[str, Dict[str, float]] = {}

        # Get top features
        top_indices = np.argsort(np.abs(shap_values))[-6:]

        for i in top_indices:
            name_i = feature_names[i]
            interactions[name_i] = {}

            for j in top_indices:
                if i != j:
                    name_j = feature_names[j]
                    # Approximate interaction
                    interaction = (
                        shap_values[i] * shap_values[j] /
                        (abs(shap_values[i]) + abs(shap_values[j]) + 1e-10)
                    )
                    interactions[name_i][name_j] = round(float(interaction), 2)

        return interactions

    def _calculate_category_contributions(
        self,
        shap_values: np.ndarray,
        feature_names: List[str],
    ) -> Dict[str, float]:
        """Calculate total SHAP contribution by category."""
        contributions: Dict[str, float] = {}

        for i, name in enumerate(feature_names):
            category = self._categorize_feature(name)
            cat_name = category.value

            if cat_name not in contributions:
                contributions[cat_name] = 0.0
            contributions[cat_name] += abs(float(shap_values[i]))

        # Round values
        return {k: round(v, 2) for k, v in contributions.items()}

    def _calculate_global_sensitivity(
        self,
        results: List[SHAPRULResult],
    ) -> Dict[str, float]:
        """Calculate global sensitivity from historical results."""
        sensitivity: Dict[str, List[float]] = {}

        for result in results:
            for driver in result.top_drivers:
                if driver.feature_name not in sensitivity:
                    sensitivity[driver.feature_name] = []
                sensitivity[driver.feature_name].append(driver.sensitivity)

        # Average sensitivities
        return {
            name: round(float(np.mean(values)), 4)
            for name, values in sensitivity.items()
        }

    def _categorize_feature(self, name: str) -> RULFeatureCategory:
        """Categorize feature by name pattern."""
        name_lower = name.lower()

        for pattern, category in self.FEATURE_CATEGORIES.items():
            if pattern in name_lower:
                return category

        return RULFeatureCategory.DERIVED

    def _get_engineering_interpretation(
        self,
        name: str,
        shap_value: float,
        feature_value: float,
        category: RULFeatureCategory,
    ) -> str:
        """Generate engineering interpretation for feature contribution."""
        direction = "extends" if shap_value > 0 else "reduces"

        # Look for specific interpretations
        for pattern, interpretation in self.ENGINEERING_INTERPRETATIONS.items():
            if pattern in name.lower():
                return (
                    f"{interpretation}; current value ({feature_value:.2f}) "
                    f"{direction} RUL by {abs(shap_value):.0f} hours"
                )

        # Category-based interpretations
        category_interpretations = {
            RULFeatureCategory.OPERATING_TIME: f"Operating time {direction} remaining component life",
            RULFeatureCategory.TEMPERATURE: f"Temperature condition {direction} material integrity",
            RULFeatureCategory.PRESSURE: f"Pressure stress {direction} mechanical life",
            RULFeatureCategory.VIBRATION: f"Vibration level {direction} fatigue life",
            RULFeatureCategory.CORROSION: f"Corrosion state {direction} wall thickness life",
            RULFeatureCategory.MAINTENANCE: f"Maintenance quality {direction} component longevity",
            RULFeatureCategory.THERMAL_CYCLING: f"Thermal cycling {direction} fatigue resistance",
            RULFeatureCategory.WEIBULL_PARAM: f"Statistical parameter {direction} failure prediction",
            RULFeatureCategory.DERIVED: f"Derived feature {direction} RUL estimate",
        }

        return category_interpretations.get(
            category,
            f"Feature {direction} RUL prediction"
        )

    def _get_nfpa_reference(self, name: str) -> Optional[str]:
        """Get NFPA 86 reference for feature if applicable."""
        name_lower = name.lower()

        for pattern, reference in self.NFPA_REFERENCES.items():
            if pattern in name_lower:
                return reference

        return None

    def _suggest_monitoring_interval(self, driver: RULDriverInfo) -> str:
        """Suggest monitoring interval based on driver characteristics."""
        if driver.rank <= 2:
            # Top 2 drivers - frequent monitoring
            return "Daily"
        elif driver.rank <= 5:
            # Top 5 - weekly
            return "Weekly"
        elif abs(driver.sensitivity) > 10:
            # High sensitivity - weekly
            return "Weekly"
        else:
            # Others - monthly
            return "Monthly"

    def _create_empty_global_explanation(
        self,
        component_type: str,
    ) -> GlobalRULExplanation:
        """Create empty global explanation when no data available."""
        return GlobalRULExplanation(
            component_type=component_type,
            model_version=self.model_version,
            num_predictions=0,
            mean_abs_shap={},
            feature_ranking=[],
            direction_consistency={},
            critical_features=[],
            maintenance_predictors=[],
            typical_ranges={},
            sensitivity_matrix={},
            computation_hash="",
        )

    def _generate_id(self) -> str:
        """Generate unique prediction ID."""
        timestamp = datetime.now(timezone.utc).isoformat()
        return hashlib.md5(timestamp.encode()).hexdigest()[:12]

    def _compute_hash(
        self,
        features: np.ndarray,
        shap_values: np.ndarray,
        importance: Dict[str, float],
        predicted_rul: float,
    ) -> str:
        """Compute SHA-256 hash for provenance."""
        data = {
            "features": features.tolist(),
            "shap_values": shap_values.tolist(),
            "importance": importance,
            "predicted_rul": predicted_rul,
            "model_version": self.model_version,
            "explainer_version": self.VERSION,
        }
        data_str = json.dumps(data, sort_keys=True)
        return hashlib.sha256(data_str.encode()).hexdigest()

    def _compute_global_hash(
        self,
        mean_abs_shap: Dict[str, float],
        feature_ranking: List[str],
        num_predictions: int,
    ) -> str:
        """Compute SHA-256 hash for global summary."""
        data = {
            "mean_abs_shap": mean_abs_shap,
            "feature_ranking": feature_ranking,
            "num_predictions": num_predictions,
            "model_version": self.model_version,
            "explainer_version": self.VERSION,
        }
        data_str = json.dumps(data, sort_keys=True)
        return hashlib.sha256(data_str.encode()).hexdigest()

    # =========================================================================
    # VISUALIZATION METHODS
    # =========================================================================

    def generate_waterfall_plot(
        self,
        result: SHAPRULResult,
        max_display: int = 10,
        output_path: Optional[str] = None,
        show_values: bool = True,
        title: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Generate a waterfall plot showing feature contribution breakdown.

        The waterfall plot visualizes how each feature contributes to pushing
        the RUL prediction from the base value (expected RUL) to the final
        predicted RUL value.

        Args:
            result: SHAPRULResult from explain_rul_prediction
            max_display: Maximum number of features to display
            output_path: Path to save the plot (optional)
            show_values: Whether to display SHAP values on the plot
            title: Custom title for the plot

        Returns:
            Dictionary containing:
                - image_base64: Base64-encoded PNG image
                - image_path: Path where image was saved (if output_path provided)
                - provenance_hash: SHA-256 hash for audit trail
                - metadata: Plot metadata

        Example:
            >>> result = explainer.explain_rul_prediction(...)
            >>> waterfall = explainer.generate_waterfall_plot(result)
            >>> with open("waterfall.png", "wb") as f:
            ...     f.write(base64.b64decode(waterfall["image_base64"]))
        """
        if not HAS_MATPLOTLIB:
            logger.error("matplotlib not available for waterfall plot generation")
            return self._create_empty_plot_result("matplotlib not installed")

        if not HAS_SHAP:
            logger.error("SHAP not available for waterfall plot generation")
            return self._create_empty_plot_result("SHAP not installed")

        try:
            # Create SHAP Explanation object for waterfall plot
            shap_explanation = shap.Explanation(
                values=result.shap_values,
                base_values=result.base_value,
                data=result.feature_values,
                feature_names=result.feature_names
            )

            # Create figure
            plt.figure(figsize=(12, 8))

            # Generate waterfall plot
            shap.plots.waterfall(
                shap_explanation,
                max_display=max_display,
                show=False
            )

            # Customize title
            if title is None:
                title = (
                    f"RUL Prediction Breakdown - {result.component_id}\n"
                    f"Predicted RUL: {result.predicted_rul_hours:,.0f} hours | "
                    f"Risk: {result.predicted_risk_category}"
                )
            plt.title(title, fontsize=12, fontweight='bold')

            # Add annotation for base value
            plt.annotate(
                f"Base (expected) RUL: {result.base_value:,.0f} hours",
                xy=(0.02, 0.02),
                xycoords='axes fraction',
                fontsize=9,
                color='gray',
                style='italic'
            )

            plt.tight_layout()

            # Save to buffer
            buffer = io.BytesIO()
            plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
            buffer.seek(0)
            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            buffer.close()

            # Save to file if path provided
            image_path = None
            if output_path:
                image_path = Path(output_path)
                image_path.parent.mkdir(parents=True, exist_ok=True)
                plt.savefig(str(image_path), dpi=150, bbox_inches='tight')

            plt.close()

            # Compute provenance hash
            provenance_hash = self._compute_plot_hash(
                "waterfall", result.computation_hash, image_base64[:100]
            )

            logger.info(
                f"Generated waterfall plot for {result.component_id} "
                f"(hash: {provenance_hash[:8]}...)"
            )

            return {
                "image_base64": image_base64,
                "image_path": str(image_path) if image_path else None,
                "format": "png",
                "provenance_hash": provenance_hash,
                "metadata": {
                    "component_id": result.component_id,
                    "prediction_id": result.prediction_id,
                    "predicted_rul_hours": result.predicted_rul_hours,
                    "base_value": result.base_value,
                    "features_displayed": min(max_display, len(result.feature_names)),
                    "generated_at": datetime.now(timezone.utc).isoformat(),
                    "model_version": self.model_version,
                }
            }

        except Exception as e:
            logger.error(f"Failed to generate waterfall plot: {e}", exc_info=True)
            return self._create_empty_plot_result(str(e))

    def generate_force_plot(
        self,
        result: SHAPRULResult,
        output_path: Optional[str] = None,
        matplotlib_output: bool = False,
        link: str = "identity",
    ) -> Dict[str, Any]:
        """
        Generate a force plot showing feature contributions interactively.

        Force plots show how features push the prediction from the base value
        (expected RUL) to the final predicted value. Red features push the
        prediction higher (increasing RUL), blue features push it lower
        (decreasing RUL).

        Args:
            result: SHAPRULResult from explain_rul_prediction
            output_path: Path to save the HTML file (optional)
            matplotlib_output: If True, generate matplotlib figure instead of HTML
            link: Transform to apply ("identity" or "logit")

        Returns:
            Dictionary containing:
                - html: Interactive HTML force plot (if matplotlib_output=False)
                - image_base64: Base64-encoded PNG (if matplotlib_output=True)
                - image_path: Path where saved (if output_path provided)
                - provenance_hash: SHA-256 hash for audit trail
                - metadata: Plot metadata

        Example:
            >>> result = explainer.explain_rul_prediction(...)
            >>> force = explainer.generate_force_plot(result)
            >>> with open("force_plot.html", "w") as f:
            ...     f.write(force["html"])
        """
        if not HAS_SHAP:
            logger.error("SHAP not available for force plot generation")
            return self._create_empty_plot_result("SHAP not installed")

        try:
            # Create SHAP Explanation object
            shap_explanation = shap.Explanation(
                values=result.shap_values,
                base_values=result.base_value,
                data=result.feature_values,
                feature_names=result.feature_names
            )

            if matplotlib_output:
                if not HAS_MATPLOTLIB:
                    return self._create_empty_plot_result("matplotlib not installed")

                # Generate matplotlib force plot
                plt.figure(figsize=(16, 4))
                shap.plots.force(
                    shap_explanation,
                    matplotlib=True,
                    show=False,
                    link=link
                )

                # Customize
                plt.title(
                    f"Force Plot - {result.component_id} | "
                    f"RUL: {result.predicted_rul_hours:,.0f} hours",
                    fontsize=11,
                    fontweight='bold'
                )
                plt.tight_layout()

                # Save to buffer
                buffer = io.BytesIO()
                plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
                buffer.seek(0)
                image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
                buffer.close()

                # Save to file if path provided
                image_path = None
                if output_path:
                    image_path = Path(output_path)
                    image_path.parent.mkdir(parents=True, exist_ok=True)
                    plt.savefig(str(image_path), dpi=150, bbox_inches='tight')

                plt.close()

                provenance_hash = self._compute_plot_hash(
                    "force_matplotlib", result.computation_hash, image_base64[:100]
                )

                return {
                    "image_base64": image_base64,
                    "image_path": str(image_path) if image_path else None,
                    "format": "png",
                    "html": None,
                    "provenance_hash": provenance_hash,
                    "metadata": self._create_plot_metadata(result, "force_plot")
                }
            else:
                # Generate interactive HTML force plot
                force_plot = shap.plots.force(
                    shap_explanation,
                    matplotlib=False,
                    show=False,
                    link=link
                )

                # Get HTML representation
                html_content = shap.getjs() + force_plot.html()

                # Wrap in full HTML document
                full_html = self._wrap_force_plot_html(
                    html_content, result
                )

                # Save to file if path provided
                html_path = None
                if output_path:
                    html_path = Path(output_path)
                    html_path.parent.mkdir(parents=True, exist_ok=True)
                    html_path.write_text(full_html, encoding='utf-8')

                provenance_hash = self._compute_plot_hash(
                    "force_html", result.computation_hash, html_content[:100]
                )

                logger.info(
                    f"Generated force plot for {result.component_id} "
                    f"(hash: {provenance_hash[:8]}...)"
                )

                return {
                    "html": full_html,
                    "html_path": str(html_path) if html_path else None,
                    "image_base64": None,
                    "format": "html",
                    "provenance_hash": provenance_hash,
                    "metadata": self._create_plot_metadata(result, "force_plot")
                }

        except Exception as e:
            logger.error(f"Failed to generate force plot: {e}", exc_info=True)
            return self._create_empty_plot_result(str(e))

    def generate_summary_plot(
        self,
        results: List[SHAPRULResult],
        plot_type: str = "bar",
        max_display: int = 15,
        output_path: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Generate a summary plot showing global feature importance.

        Args:
            results: List of SHAPRULResults from multiple predictions
            plot_type: Type of plot ("bar", "dot", "violin")
            max_display: Maximum number of features to display
            output_path: Path to save the plot (optional)

        Returns:
            Dictionary with plot data and provenance

        Example:
            >>> results = [explainer.explain_rul_prediction(...) for _ in range(100)]
            >>> summary = explainer.generate_summary_plot(results)
        """
        if not HAS_MATPLOTLIB or not HAS_SHAP:
            return self._create_empty_plot_result("SHAP or matplotlib not installed")

        if not results:
            return self._create_empty_plot_result("No results provided")

        try:
            # Aggregate SHAP values and features
            all_shap = np.array([r.shap_values for r in results])
            all_features = np.array([r.feature_values for r in results])
            feature_names = results[0].feature_names

            # Create figure
            plt.figure(figsize=(12, 8))

            if plot_type == "bar":
                # Bar plot showing mean absolute SHAP values
                mean_abs_shap = np.mean(np.abs(all_shap), axis=0)
                sorted_idx = np.argsort(mean_abs_shap)[::-1][:max_display]

                plt.barh(
                    range(len(sorted_idx)),
                    mean_abs_shap[sorted_idx],
                    color='#1e88e5',
                    alpha=0.8
                )
                plt.yticks(
                    range(len(sorted_idx)),
                    [feature_names[i] for i in sorted_idx]
                )
                plt.xlabel("Mean |SHAP value| (hours)")
                plt.title(
                    f"Global Feature Importance - RUL Prediction\n"
                    f"Aggregated from {len(results)} predictions",
                    fontweight='bold'
                )
                plt.gca().invert_yaxis()

            elif plot_type in ("dot", "violin"):
                # Use SHAP's built-in summary plot
                shap.summary_plot(
                    all_shap,
                    all_features,
                    feature_names=feature_names,
                    max_display=max_display,
                    plot_type="dot" if plot_type == "dot" else "violin",
                    show=False
                )
                plt.title(
                    f"SHAP Summary - {len(results)} RUL Predictions",
                    fontweight='bold'
                )

            plt.tight_layout()

            # Save to buffer
            buffer = io.BytesIO()
            plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
            buffer.seek(0)
            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            buffer.close()

            # Save to file
            image_path = None
            if output_path:
                image_path = Path(output_path)
                image_path.parent.mkdir(parents=True, exist_ok=True)
                plt.savefig(str(image_path), dpi=150, bbox_inches='tight')

            plt.close()

            provenance_hash = hashlib.sha256(
                f"summary_{plot_type}_{len(results)}_{image_base64[:100]}".encode()
            ).hexdigest()

            return {
                "image_base64": image_base64,
                "image_path": str(image_path) if image_path else None,
                "format": "png",
                "plot_type": plot_type,
                "provenance_hash": provenance_hash,
                "metadata": {
                    "num_predictions": len(results),
                    "features_displayed": min(max_display, len(feature_names)),
                    "generated_at": datetime.now(timezone.utc).isoformat(),
                }
            }

        except Exception as e:
            logger.error(f"Failed to generate summary plot: {e}", exc_info=True)
            return self._create_empty_plot_result(str(e))

    def generate_dependence_plot(
        self,
        results: List[SHAPRULResult],
        feature_name: str,
        interaction_feature: Optional[str] = None,
        output_path: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Generate a dependence plot showing feature effect on RUL.

        Dependence plots show how a feature affects RUL predictions across
        different values of that feature.

        Args:
            results: List of SHAPRULResults
            feature_name: Feature to analyze
            interaction_feature: Feature to color by (auto-detected if None)
            output_path: Path to save the plot

        Returns:
            Dictionary with plot data and provenance
        """
        if not HAS_MATPLOTLIB or not HAS_SHAP:
            return self._create_empty_plot_result("SHAP or matplotlib not installed")

        if not results:
            return self._create_empty_plot_result("No results provided")

        feature_names = results[0].feature_names
        if feature_name not in feature_names:
            return self._create_empty_plot_result(f"Feature {feature_name} not found")

        try:
            # Aggregate data
            all_shap = np.array([r.shap_values for r in results])
            all_features = np.array([r.feature_values for r in results])
            feature_idx = feature_names.index(feature_name)

            plt.figure(figsize=(10, 7))

            if interaction_feature and interaction_feature in feature_names:
                interaction_idx = feature_names.index(interaction_feature)
                shap.dependence_plot(
                    feature_idx,
                    all_shap,
                    all_features,
                    feature_names=feature_names,
                    interaction_index=interaction_idx,
                    show=False
                )
            else:
                shap.dependence_plot(
                    feature_idx,
                    all_shap,
                    all_features,
                    feature_names=feature_names,
                    show=False
                )

            # Get unit for feature
            unit = self.FEATURE_UNITS.get(feature_name, "")
            unit_str = f" ({unit})" if unit else ""

            plt.xlabel(f"{feature_name}{unit_str}")
            plt.ylabel(f"SHAP value for {feature_name} (hours)")
            plt.title(
                f"Dependence Plot: {feature_name} Effect on RUL\n"
                f"Based on {len(results)} predictions",
                fontweight='bold'
            )
            plt.tight_layout()

            # Save to buffer
            buffer = io.BytesIO()
            plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
            buffer.seek(0)
            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            buffer.close()

            # Save to file
            image_path = None
            if output_path:
                image_path = Path(output_path)
                image_path.parent.mkdir(parents=True, exist_ok=True)
                plt.savefig(str(image_path), dpi=150, bbox_inches='tight')

            plt.close()

            provenance_hash = hashlib.sha256(
                f"dependence_{feature_name}_{len(results)}_{image_base64[:100]}".encode()
            ).hexdigest()

            return {
                "image_base64": image_base64,
                "image_path": str(image_path) if image_path else None,
                "format": "png",
                "feature": feature_name,
                "provenance_hash": provenance_hash,
                "metadata": {
                    "num_predictions": len(results),
                    "feature_analyzed": feature_name,
                    "interaction_feature": interaction_feature,
                    "generated_at": datetime.now(timezone.utc).isoformat(),
                }
            }

        except Exception as e:
            logger.error(f"Failed to generate dependence plot: {e}", exc_info=True)
            return self._create_empty_plot_result(str(e))

    def get_feature_importance(
        self,
        result: SHAPRULResult,
        normalize: bool = True,
    ) -> Dict[str, float]:
        """
        Extract feature importance rankings from SHAP analysis.

        Args:
            result: SHAPRULResult from explain_rul_prediction
            normalize: If True, normalize to percentages summing to 100

        Returns:
            Dictionary of feature names to importance scores

        Example:
            >>> result = explainer.explain_rul_prediction(...)
            >>> importance = explainer.get_feature_importance(result)
            >>> print(f"Most important: {list(importance.keys())[0]}")
        """
        importance = {}
        abs_values = np.abs(result.shap_values)
        total = np.sum(abs_values)

        for i, name in enumerate(result.feature_names):
            if normalize and total > 0:
                importance[name] = round(float(abs_values[i] / total * 100), 2)
            else:
                importance[name] = round(float(abs_values[i]), 2)

        # Sort by importance descending
        return dict(sorted(
            importance.items(),
            key=lambda x: x[1],
            reverse=True
        ))

    def export_explanation(
        self,
        result: SHAPRULResult,
        format: str = "json",
        include_plots: bool = True,
        output_dir: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Export complete explanation package with all artifacts.

        Creates a comprehensive export including SHAP values, visualizations,
        and provenance information suitable for regulatory audits.

        Args:
            result: SHAPRULResult to export
            format: Export format ("json", "html", "pdf")
            include_plots: Include generated plots
            output_dir: Directory to save exports

        Returns:
            Dictionary containing all export paths and data

        Example:
            >>> result = explainer.explain_rul_prediction(...)
            >>> export = explainer.export_explanation(result, output_dir="./exports")
        """
        export_data: Dict[str, Any] = {
            "component_id": result.component_id,
            "component_type": result.component_type,
            "prediction_id": result.prediction_id,
            "predicted_rul_hours": result.predicted_rul_hours,
            "predicted_risk_category": result.predicted_risk_category,
            "base_value": result.base_value,
            "timestamp": result.timestamp.isoformat(),
            "computation_hash": result.computation_hash,
            "model_version": result.model_version,
            "feature_importance": self.get_feature_importance(result),
            "top_drivers": [
                {
                    "feature": d.feature_name,
                    "shap_value": d.shap_value,
                    "value": d.feature_value,
                    "direction": d.direction,
                    "contribution_pct": d.contribution_percent,
                    "interpretation": d.engineering_interpretation,
                }
                for d in result.top_drivers[:10]
            ],
            "category_contributions": result.category_contributions,
            "degradation_factors": [d.feature_name for d in result.degradation_factors],
            "protective_factors": [d.feature_name for d in result.protective_factors],
        }

        export_result: Dict[str, Any] = {
            "data": export_data,
            "format": format,
            "files": [],
            "provenance_hash": None,
        }

        # Generate output paths
        if output_dir:
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            base_name = f"rul_explanation_{result.component_id}_{result.prediction_id}"

            # Save JSON
            json_path = output_path / f"{base_name}.json"
            json_path.write_text(
                json.dumps(export_data, indent=2, default=str),
                encoding='utf-8'
            )
            export_result["files"].append(str(json_path))

            # Generate plots if requested
            if include_plots:
                waterfall_path = output_path / f"{base_name}_waterfall.png"
                waterfall = self.generate_waterfall_plot(
                    result, output_path=str(waterfall_path)
                )
                if waterfall.get("image_path"):
                    export_result["files"].append(waterfall["image_path"])
                    export_result["waterfall_plot"] = waterfall

                force_path = output_path / f"{base_name}_force.html"
                force = self.generate_force_plot(
                    result, output_path=str(force_path)
                )
                if force.get("html_path"):
                    export_result["files"].append(force["html_path"])
                    export_result["force_plot"] = force

        # Compute final provenance hash
        export_result["provenance_hash"] = hashlib.sha256(
            json.dumps(export_data, sort_keys=True, default=str).encode()
        ).hexdigest()

        logger.info(
            f"Exported explanation for {result.component_id} "
            f"({len(export_result['files'])} files)"
        )

        return export_result

    # =========================================================================
    # HELPER METHODS FOR VISUALIZATION
    # =========================================================================

    def _wrap_force_plot_html(
        self,
        html_content: str,
        result: SHAPRULResult,
    ) -> str:
        """Wrap force plot HTML in a complete document."""
        return f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RUL Prediction Explanation - {result.component_id}</title>
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            margin: 20px;
            background-color: #fafafa;
        }}
        .header {{
            background: linear-gradient(135deg, #1e3a5f 0%, #2e5a8f 100%);
            color: white;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 20px;
        }}
        .header h1 {{ margin: 0 0 10px 0; font-size: 24px; }}
        .header p {{ margin: 5px 0; opacity: 0.9; }}
        .metrics {{
            display: flex;
            gap: 20px;
            margin-top: 15px;
        }}
        .metric {{
            background: rgba(255,255,255,0.1);
            padding: 10px 20px;
            border-radius: 4px;
        }}
        .metric-value {{ font-size: 28px; font-weight: bold; }}
        .metric-label {{ font-size: 12px; opacity: 0.8; }}
        .plot-container {{
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        .footer {{
            margin-top: 20px;
            font-size: 12px;
            color: #666;
            text-align: center;
        }}
    </style>
</head>
<body>
    <div class="header">
        <h1>RUL Prediction Explanation</h1>
        <p><strong>Component:</strong> {result.component_id} ({result.component_type})</p>
        <p><strong>Prediction ID:</strong> {result.prediction_id}</p>
        <div class="metrics">
            <div class="metric">
                <div class="metric-value">{result.predicted_rul_hours:,.0f}</div>
                <div class="metric-label">Predicted RUL (hours)</div>
            </div>
            <div class="metric">
                <div class="metric-value">{result.predicted_risk_category}</div>
                <div class="metric-label">Risk Category</div>
            </div>
            <div class="metric">
                <div class="metric-value">{result.base_value:,.0f}</div>
                <div class="metric-label">Base RUL (hours)</div>
            </div>
        </div>
    </div>
    <div class="plot-container">
        <h2>Feature Contributions</h2>
        <p>Red features <strong>increase</strong> RUL, blue features <strong>decrease</strong> RUL.</p>
        {html_content}
    </div>
    <div class="footer">
        <p>Generated by GL-007 FurnacePulse SHAP Explainer v{self.VERSION}</p>
        <p>Computation Hash: {result.computation_hash[:16]}...</p>
        <p>Generated: {result.timestamp.isoformat()}</p>
    </div>
</body>
</html>
"""

    def _create_empty_plot_result(self, error: str) -> Dict[str, Any]:
        """Create empty plot result for error cases."""
        return {
            "image_base64": None,
            "image_path": None,
            "html": None,
            "format": None,
            "error": error,
            "provenance_hash": hashlib.sha256(
                f"error_{error}_{datetime.now().isoformat()}".encode()
            ).hexdigest(),
            "metadata": {
                "error": error,
                "generated_at": datetime.now(timezone.utc).isoformat(),
            }
        }

    def _compute_plot_hash(
        self,
        plot_type: str,
        source_hash: str,
        content_sample: str,
    ) -> str:
        """Compute provenance hash for a generated plot."""
        data = {
            "plot_type": plot_type,
            "source_hash": source_hash,
            "content_sample": content_sample,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "model_version": self.model_version,
        }
        return hashlib.sha256(
            json.dumps(data, sort_keys=True).encode()
        ).hexdigest()

    def _create_plot_metadata(
        self,
        result: SHAPRULResult,
        plot_type: str,
    ) -> Dict[str, Any]:
        """Create standard metadata for plots."""
        return {
            "component_id": result.component_id,
            "prediction_id": result.prediction_id,
            "predicted_rul_hours": result.predicted_rul_hours,
            "base_value": result.base_value,
            "plot_type": plot_type,
            "generated_at": datetime.now(timezone.utc).isoformat(),
            "model_version": self.model_version,
            "explainer_version": self.VERSION,
        }
