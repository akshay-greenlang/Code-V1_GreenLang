# GL-007 FurnacePulse - pytest Configuration
#
# Enforces 85% minimum test coverage and configures test execution
# for the Furnace Performance Monitoring Agent.
#
# Reference: NFPA 86 Standard for Ovens and Furnaces quality assurance
#
# Usage:
#   pytest                           # Run all tests
#   pytest tests/test_unit/          # Run unit tests only
#   pytest tests/test_compliance/    # Run NFPA 86 compliance tests
#   pytest --cov                     # Run with coverage
#   pytest -x                        # Stop on first failure
#   pytest -v                        # Verbose output
#   pytest --lf                      # Run last failed tests
#   pytest -m "nfpa"                 # Run NFPA 86 specific tests

[pytest]
# Test discovery
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Minimum coverage threshold (enforced)
minversion = 7.0

# Default options
addopts =
    --strict-markers
    --strict-config
    -ra
    -q
    --tb=short
    --cov=.
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --cov-fail-under=85
    --cov-branch
    -W ignore::DeprecationWarning
    -W ignore::PendingDeprecationWarning

# Coverage configuration
[coverage:run]
source = .
branch = True
omit =
    tests/*
    */__pycache__/*
    */migrations/*
    setup.py
    conftest.py
    *_pb2.py
    *_pb2_grpc.py

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
    @abstractmethod
    @abc.abstractmethod

fail_under = 85
show_missing = True
precision = 2

[coverage:html]
directory = htmlcov
title = GL-007 FurnacePulse Coverage Report

# Test markers
markers =
    unit: Unit tests (fast, isolated)
    integration: Integration tests (require external services)
    slow: Slow tests (>5 seconds)
    smoke: Smoke tests for quick validation
    e2e: End-to-end tests
    nfpa: NFPA 86 compliance tests
    safety: Safety-critical tests
    rul: Remaining Useful Life tests
    hotspot: Hotspot detection tests
    efficiency: Efficiency calculation tests
    shap: SHAP explainability tests
    evidence: Evidence sealing tests
    merkle: Merkle tree tests
    telemetry: Telemetry processing tests
    cmms: CMMS integration tests
    weibull: Weibull distribution tests
    api: API endpoint tests
    kafka: Kafka integration tests
    influxdb: InfluxDB integration tests
    benchmark: Performance benchmark tests
    golden: Golden test with known expected results

# Timeout for individual tests
timeout = 300
timeout_method = thread

# Asyncio mode
asyncio_mode = auto

# Fixtures
filterwarnings =
    error
    ignore::UserWarning
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning

# Console output
console_output_style = progress

# Logging
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests/test.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Environment variables for tests
env =
    GL_AGENT_ID=GL-007
    GL_AGENT_NAME=FurnacePulse
    GL_ENV=test
    GL_LOG_LEVEL=DEBUG
    PYTHONDONTWRITEBYTECODE=1

# Parallel execution
# Use: pytest -n auto for parallel execution
[pytest:ini_options]
norecursedirs =
    .git
    .tox
    .env
    dist
    build
    htmlcov
    *.egg-info
    __pycache__
    node_modules

# Required plugins
required_plugins =
    pytest-cov>=4.0.0
    pytest-asyncio>=0.21.0
    pytest-timeout>=2.2.0
