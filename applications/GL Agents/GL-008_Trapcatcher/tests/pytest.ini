# -*- ini -*-
# ==============================================================================
# GL-008 TRAPCATCHER - pytest Configuration
# ==============================================================================
# Production-grade pytest configuration with 85% coverage enforcement
# for GreenLang Global AI Standards v2.0 compliance.
#
# Coverage Requirements:
#   - Minimum 85% overall coverage (enforced)
#   - Critical paths require 95%+ coverage
#   - Core modules require 90%+ coverage
#
# Test Organization:
#   tests/
#     unit/          - Unit tests for individual components
#     test_unit/     - Alternative unit test location
#     integration/   - Integration tests for API and database
#     test_integration/ - Alternative integration test location
#     golden/        - Determinism tests with golden values
#     performance/   - Performance benchmarks
#
# Standards Compliance:
#   - ASME PTC 39: Steam Traps - Performance Test Codes
#   - ISO 7841: Automatic steam traps - Steam loss determination
#   - GreenLang Global AI Standards v2.0
#
# Usage:
#   pytest                          # Run all tests
#   pytest -m unit                  # Run unit tests only
#   pytest -m golden                # Run golden value tests
#   pytest -m "not slow"            # Skip slow tests
#   pytest --cov --cov-fail-under=85  # With coverage enforcement
#
# Author: GL-BackendDeveloper
# Version: 2.0.0
# Date: December 2025
# ==============================================================================

[pytest]
# =============================================================================
# GENERAL CONFIGURATION
# =============================================================================

# Minimum pytest version required
minversion = 7.0

# Test discovery paths (supports multiple directory structures)
testpaths =
    tests
    unit
    test_unit
    integration
    test_integration
    golden
    test_golden

# Test file patterns
python_files = test_*.py *_test.py tests.py
python_classes = Test* *Test *Tests
python_functions = test_*

# Directories to ignore
norecursedirs =
    .git
    .tox
    .env
    venv
    __pycache__
    *.egg-info
    .pytest_cache
    .mypy_cache
    .hypothesis
    node_modules
    build
    dist
    htmlcov

# =============================================================================
# MARKERS
# =============================================================================
markers =
    # Test type markers
    unit: Unit tests for individual components (deselect with '-m "not unit"')
    integration: Integration tests requiring external services
    golden: Golden value tests for determinism verification (ASME/ISO)
    e2e: End-to-end tests for complete workflows
    performance: Performance benchmark tests

    # Speed markers
    slow: Tests that take >5 seconds to run
    fast: Tests that complete in <1 second
    smoke: Quick smoke tests for deployment verification

    # Standards compliance markers
    asme: ASME PTC 39 compliance tests
    iso: ISO 7841 compliance tests
    determinism: Tests verifying calculation reproducibility

    # Feature markers
    acoustic: Acoustic diagnostic tests
    thermal: Thermal diagnostic tests
    multimodal: Multimodal classification tests

    # Calculator markers
    energy_loss: Energy loss calculation tests
    steam_loss: Steam loss calculation tests
    carbon: Carbon emission calculation tests
    roi: ROI calculation tests

    # Component markers
    bounds_validator: Bounds validation tests
    classifier: Trap state classifier tests
    explainability: SHAP and feature importance tests
    metrics: Prometheus metrics tests
    api: API endpoint tests

    # Infrastructure markers
    security: Security-related tests
    requires_db: Tests requiring database connection
    requires_redis: Tests requiring Redis connection
    requires_docker: Tests requiring Docker

    # Quality markers
    regression: Regression tests
    flaky: Potentially flaky tests (use with caution)

# =============================================================================
# EXECUTION OPTIONS
# =============================================================================
addopts =
    --strict-markers
    --strict-config
    -ra
    --tb=short
    --color=yes
    --code-highlight=yes
    --durations=20
    --durations-min=0.1
    -v
    -x

# Console output style
console_output_style = progress

# XFail strict mode - unexpected passes are failures
xfail_strict = true

# =============================================================================
# TIMEOUT CONFIGURATION
# =============================================================================
timeout = 60
timeout_method = thread

# =============================================================================
# ASYNC SUPPORT (pytest-asyncio)
# =============================================================================
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function

# =============================================================================
# LOGGING
# =============================================================================
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = logs/pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s (%(filename)s:%(lineno)s)
log_file_date_format = %Y-%m-%d %H:%M:%S

# =============================================================================
# WARNINGS
# =============================================================================
filterwarnings =
    # Treat warnings as errors by default for strict quality
    error

    # Ignore specific deprecation warnings from dependencies
    ignore::DeprecationWarning:prometheus_client.*
    ignore::PendingDeprecationWarning:prometheus_client.*
    ignore::DeprecationWarning:pydantic.*
    ignore::DeprecationWarning:pkg_resources.*
    ignore::DeprecationWarning:distutils.*

    # Ignore asyncio warnings
    ignore::RuntimeWarning:asyncio.*

    # Ignore hypothesis warnings about slow tests
    ignore::hypothesis.errors.HypothesisWarning

# =============================================================================
# COVERAGE CONFIGURATION - 85% MINIMUM ENFORCED
# =============================================================================
[coverage:run]
# Source directories to measure
source =
    calculators
    core
    classifiers
    explainability
    integration
    monitoring
    api

# Enable branch coverage
branch = true

# Enable parallel coverage for multiprocessing
parallel = true

# Dynamic context for better reporting
dynamic_context = test_function

# Paths to omit from coverage
omit =
    tests/*
    test_*/*
    */__pycache__/*
    */migrations/*
    setup.py
    conftest.py
    */test_*.py
    *_test.py
    .venv/*
    venv/*

[coverage:paths]
source =
    .
    */site-packages/

[coverage:report]
# Decimal precision
precision = 2

# Show line numbers of missing coverage
show_missing = true

# Don't skip covered files
skip_covered = false

# Sort by coverage percentage
sort = Cover

# ENFORCE 85% MINIMUM COVERAGE - GreenLang Global AI Standards
fail_under = 85

# Exclude patterns from coverage calculation
exclude_lines =
    # Standard pragmas
    pragma: no cover
    pragma: no branch

    # Defensive assertions
    raise AssertionError
    raise NotImplementedError

    # Main block
    if __name__ == .__main__.:

    # Type checking imports
    if TYPE_CHECKING:
    if typing.TYPE_CHECKING:

    # Abstract methods
    @abstractmethod
    @abc.abstractmethod

    # Protocol definitions
    class .*\bProtocol\):

    # Overload decorators
    @overload
    @typing.overload

    # Debug/repr methods
    def __repr__
    def __str__

    # Logging
    logger\.debug

    # Platform-specific code
    if sys.platform

    # Deprecated code
    @deprecated

# Partial branch patterns
partial_branches =
    pragma: no branch
    if 0:
    if False:

[coverage:html]
# HTML report output directory
directory = htmlcov

# Report title
title = GL-008 TRAPCATCHER Coverage Report (85% Required)

# Show contexts in HTML report
show_contexts = true

# Skip files with 100% coverage in report
skip_covered = false

[coverage:xml]
# XML report output
output = coverage.xml

[coverage:json]
# JSON report output
output = coverage.json

# =============================================================================
# MODULE-SPECIFIC COVERAGE REQUIREMENTS
# =============================================================================
# These are verified in CI pipeline and enforced programmatically:
#
# CRITICAL (95%+ required):
#   - calculators/steam_trap_energy_loss_calculator.py
#   - core/trap_state_classifier.py
#   - core/bounds_validator.py
#
# HIGH (90%+ required):
#   - explainability/*.py
#   - classifiers/*.py
#   - monitoring/metrics_exporter.py
#
# STANDARD (85%+ required):
#   - api/routes.py
#   - integration/*.py
#
# =============================================================================
# PERFORMANCE THRESHOLDS
# =============================================================================
# These are verified in performance tests:
#
# Classification: <50ms per trap
# Energy calculation: <100ms per trap
# Bounds validation: <5ms per validation
# Fleet analysis: <5s for 1000 traps
# SHAP explanation: <200ms per prediction
# API response: <100ms for single trap
#
# =============================================================================
# HYPOTHESIS CONFIGURATION (Property-Based Testing)
# =============================================================================
[hypothesis]
# Default hypothesis settings for property-based testing
# These provide deterministic test execution in CI

# Profile name
profile = default

# Maximum examples per test
max_examples = 100

# Deadline per example in milliseconds
deadline = 500

# Database for example storage
database = .hypothesis/examples

# Verbosity level
verbosity = normal

# Derandomize for CI reproducibility
derandomize = false

# Suppress health checks (optional)
suppress_health_check =

# Print statistics on completion
print_statistics = true
