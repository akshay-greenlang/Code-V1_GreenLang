# -*- coding: utf-8 -*-
"""
Prometheus Metrics - AGENT-DATA-009: Spend Data Categorizer

12 Prometheus metrics for spend data categorizer service monitoring with
graceful fallback when prometheus_client is not installed.

Metrics:
    1.  gl_spend_cat_records_ingested_total (Counter, labels: source)
    2.  gl_spend_cat_records_classified_total (Counter, labels: taxonomy)
    3.  gl_spend_cat_scope3_mapped_total (Counter, labels: category)
    4.  gl_spend_cat_emissions_calculated_total (Counter, labels: source)
    5.  gl_spend_cat_rules_evaluated_total (Counter, labels: result)
    6.  gl_spend_cat_reports_generated_total (Counter, labels: format)
    7.  gl_spend_cat_classification_confidence (Histogram, buckets: 0.1-1.0)
    8.  gl_spend_cat_processing_duration_seconds (Histogram, labels: operation)
    9.  gl_spend_cat_active_batches (Gauge)
    10. gl_spend_cat_total_spend_usd (Gauge)
    11. gl_spend_cat_processing_errors_total (Counter, labels: error_type)
    12. gl_spend_cat_emission_factor_lookups_total (Counter, labels: source)

Author: GreenLang Platform Team
Date: February 2026
PRD: AGENT-DATA-009 Spend Data Categorizer (GL-DATA-SUP-002)
Status: Production Ready
"""

from __future__ import annotations

import logging

logger = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# Graceful prometheus_client import
# ---------------------------------------------------------------------------

try:
    from prometheus_client import Counter, Gauge, Histogram
    PROMETHEUS_AVAILABLE = True
except ImportError:
    PROMETHEUS_AVAILABLE = False
    logger.info(
        "prometheus_client not installed; spend categorizer metrics disabled"
    )


# ---------------------------------------------------------------------------
# Metric definitions
# ---------------------------------------------------------------------------

if PROMETHEUS_AVAILABLE:
    # 1. Spend records ingested by source
    spend_cat_records_ingested_total = Counter(
        "gl_spend_cat_records_ingested_total",
        "Total spend records ingested",
        labelnames=["source"],
    )

    # 2. Records classified by taxonomy system
    spend_cat_records_classified_total = Counter(
        "gl_spend_cat_records_classified_total",
        "Total spend records classified",
        labelnames=["taxonomy"],
    )

    # 3. Scope 3 category mappings by GHG Protocol category
    spend_cat_scope3_mapped_total = Counter(
        "gl_spend_cat_scope3_mapped_total",
        "Total spend records mapped to Scope 3 categories",
        labelnames=["category"],
    )

    # 4. Emission calculations completed by factor source
    spend_cat_emissions_calculated_total = Counter(
        "gl_spend_cat_emissions_calculated_total",
        "Total emission calculations completed",
        labelnames=["source"],
    )

    # 5. Classification rules evaluated by result
    spend_cat_rules_evaluated_total = Counter(
        "gl_spend_cat_rules_evaluated_total",
        "Total classification rules evaluated",
        labelnames=["result"],
    )

    # 6. Reports generated by format
    spend_cat_reports_generated_total = Counter(
        "gl_spend_cat_reports_generated_total",
        "Total reports generated",
        labelnames=["format"],
    )

    # 7. Classification confidence score distribution
    spend_cat_classification_confidence = Histogram(
        "gl_spend_cat_classification_confidence",
        "Classification confidence score distribution",
        buckets=(
            0.1, 0.2, 0.3, 0.4, 0.5,
            0.6, 0.7, 0.8, 0.9, 1.0,
        ),
    )

    # 8. Processing duration histogram by operation type
    spend_cat_processing_duration_seconds = Histogram(
        "gl_spend_cat_processing_duration_seconds",
        "Spend categorizer processing duration in seconds",
        labelnames=["operation"],
        buckets=(
            0.05, 0.1, 0.25, 0.5, 1.0, 2.5,
            5.0, 10.0, 30.0, 60.0, 120.0, 300.0,
        ),
    )

    # 9. Currently active batches gauge
    spend_cat_active_batches = Gauge(
        "gl_spend_cat_active_batches",
        "Number of currently active processing batches",
    )

    # 10. Total spend amount in USD gauge
    spend_cat_total_spend_usd = Gauge(
        "gl_spend_cat_total_spend_usd",
        "Total cumulative spend amount in USD",
    )

    # 11. Processing errors by error type
    spend_cat_processing_errors_total = Counter(
        "gl_spend_cat_processing_errors_total",
        "Total processing errors encountered",
        labelnames=["error_type"],
    )

    # 12. Emission factor lookups by source
    spend_cat_emission_factor_lookups_total = Counter(
        "gl_spend_cat_emission_factor_lookups_total",
        "Total emission factor lookups performed",
        labelnames=["source"],
    )

else:
    # No-op placeholders
    spend_cat_records_ingested_total = None  # type: ignore[assignment]
    spend_cat_records_classified_total = None  # type: ignore[assignment]
    spend_cat_scope3_mapped_total = None  # type: ignore[assignment]
    spend_cat_emissions_calculated_total = None  # type: ignore[assignment]
    spend_cat_rules_evaluated_total = None  # type: ignore[assignment]
    spend_cat_reports_generated_total = None  # type: ignore[assignment]
    spend_cat_classification_confidence = None  # type: ignore[assignment]
    spend_cat_processing_duration_seconds = None  # type: ignore[assignment]
    spend_cat_active_batches = None  # type: ignore[assignment]
    spend_cat_total_spend_usd = None  # type: ignore[assignment]
    spend_cat_processing_errors_total = None  # type: ignore[assignment]
    spend_cat_emission_factor_lookups_total = None  # type: ignore[assignment]


# ---------------------------------------------------------------------------
# Helper functions (safe to call even without prometheus_client)
# ---------------------------------------------------------------------------


def record_ingestion(source: str) -> None:
    """Record a spend record ingestion event.

    Args:
        source: Ingestion source (csv, excel, api, erp, manual).
    """
    if not PROMETHEUS_AVAILABLE:
        return
    spend_cat_records_ingested_total.labels(
        source=source,
    ).inc()


def record_classification(taxonomy: str) -> None:
    """Record a spend record classification event.

    Args:
        taxonomy: Taxonomy system used (unspsc, naics, nace, custom).
    """
    if not PROMETHEUS_AVAILABLE:
        return
    spend_cat_records_classified_total.labels(
        taxonomy=taxonomy,
    ).inc()


def record_scope3_mapping(category: str) -> None:
    """Record a Scope 3 category mapping event.

    Args:
        category: GHG Protocol Scope 3 category (cat1..cat15).
    """
    if not PROMETHEUS_AVAILABLE:
        return
    spend_cat_scope3_mapped_total.labels(
        category=category,
    ).inc()


def record_emission_calculation(source: str) -> None:
    """Record an emission calculation completion event.

    Args:
        source: Emission factor source (eeio, exiobase, defra, ecoinvent).
    """
    if not PROMETHEUS_AVAILABLE:
        return
    spend_cat_emissions_calculated_total.labels(
        source=source,
    ).inc()


def record_rule_evaluation(result: str) -> None:
    """Record a classification rule evaluation event.

    Args:
        result: Evaluation result (match, no_match).
    """
    if not PROMETHEUS_AVAILABLE:
        return
    spend_cat_rules_evaluated_total.labels(
        result=result,
    ).inc()


def record_report_generation(report_format: str) -> None:
    """Record a report generation event.

    Args:
        report_format: Report format (json, csv, excel, pdf).
    """
    if not PROMETHEUS_AVAILABLE:
        return
    spend_cat_reports_generated_total.labels(
        format=report_format,
    ).inc()


def record_classification_confidence(confidence: float) -> None:
    """Record a classification confidence score observation.

    Args:
        confidence: Confidence score (0.0 - 1.0).
    """
    if not PROMETHEUS_AVAILABLE:
        return
    spend_cat_classification_confidence.observe(confidence)


def record_processing_duration(operation: str, duration: float) -> None:
    """Record processing duration for an operation.

    Args:
        operation: Operation type (ingest, classify, map_scope3, calculate, etc.).
        duration: Duration in seconds.
    """
    if not PROMETHEUS_AVAILABLE:
        return
    spend_cat_processing_duration_seconds.labels(
        operation=operation,
    ).observe(duration)


def update_active_batches(delta: int) -> None:
    """Update the active batches gauge.

    Args:
        delta: Positive to increment, negative to decrement.
    """
    if not PROMETHEUS_AVAILABLE:
        return
    if delta > 0:
        spend_cat_active_batches.inc(delta)
    elif delta < 0:
        spend_cat_active_batches.dec(abs(delta))


def update_total_spend(amount: float) -> None:
    """Update the total spend USD gauge.

    Args:
        amount: Amount to add to the total spend (may be negative for corrections).
    """
    if not PROMETHEUS_AVAILABLE:
        return
    spend_cat_total_spend_usd.inc(amount)


def record_processing_error(error_type: str) -> None:
    """Record a processing error event.

    Args:
        error_type: Error classification (validation, timeout, data, integration, unknown).
    """
    if not PROMETHEUS_AVAILABLE:
        return
    spend_cat_processing_errors_total.labels(
        error_type=error_type,
    ).inc()


def record_factor_lookup(source: str) -> None:
    """Record an emission factor lookup event.

    Args:
        source: Factor database source (eeio, exiobase, defra, ecoinvent).
    """
    if not PROMETHEUS_AVAILABLE:
        return
    spend_cat_emission_factor_lookups_total.labels(
        source=source,
    ).inc()


__all__ = [
    "PROMETHEUS_AVAILABLE",
    # Metric objects
    "spend_cat_records_ingested_total",
    "spend_cat_records_classified_total",
    "spend_cat_scope3_mapped_total",
    "spend_cat_emissions_calculated_total",
    "spend_cat_rules_evaluated_total",
    "spend_cat_reports_generated_total",
    "spend_cat_classification_confidence",
    "spend_cat_processing_duration_seconds",
    "spend_cat_active_batches",
    "spend_cat_total_spend_usd",
    "spend_cat_processing_errors_total",
    "spend_cat_emission_factor_lookups_total",
    # Helper functions
    "record_ingestion",
    "record_classification",
    "record_scope3_mapping",
    "record_emission_calculation",
    "record_rule_evaluation",
    "record_report_generation",
    "record_classification_confidence",
    "record_processing_duration",
    "update_active_batches",
    "update_total_spend",
    "record_processing_error",
    "record_factor_lookup",
]
