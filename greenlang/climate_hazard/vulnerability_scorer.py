# -*- coding: utf-8 -*-
"""
Vulnerability Scorer Engine - AGENT-DATA-020 (Engine 5 of 7)

Scores entity vulnerability to climate hazards using the IPCC AR5/AR6
vulnerability assessment framework.  Vulnerability is computed as a
weighted combination of exposure, sensitivity, and adaptive capacity:

    vulnerability = (w_exp * exposure + w_sens * sensitivity
                     - w_adapt * adaptive_capacity) * 100
    # Clamped to [0, 100]

Default weights (configurable via ClimateHazardConfig):
    - Exposure:          0.40
    - Sensitivity:       0.35
    - Adaptive capacity: 0.25

Vulnerability Levels (5-tier):
    NEGLIGIBLE   0 - 20
    LOW         20 - 40
    MODERATE    40 - 60
    HIGH        60 - 80
    CRITICAL    80 - 100

Provides sector-specific sensitivity factor libraries, adaptive capacity
indicator libraries, sensitivity and adaptive-capacity profile management,
residual risk calculation (post-adaptation), and entity ranking by
vulnerability score.

Zero-Hallucination: All calculations use deterministic Python arithmetic
(weighted averages, clamping, percentage calculations). No LLM calls for
numeric computations. No external numerical libraries required.

Example:
    >>> from greenlang.climate_hazard.vulnerability_scorer import VulnerabilityScorerEngine
    >>> engine = VulnerabilityScorerEngine()
    >>> result = engine.score_vulnerability(
    ...     entity_id="entity-001",
    ...     hazard_type="flood",
    ...     exposure_score=65.0,
    ...     sensitivity_factors={"crop_diversity": 0.3, "irrigation_coverage": 0.7},
    ...     adaptive_capacity_indicators={"financial_reserves": 0.6, "insurance_coverage": 0.8},
    ... )
    >>> assert 0.0 <= result["vulnerability_score"] <= 100.0

Author: GreenLang Platform Team
Date: February 2026
PRD: AGENT-DATA-020 Climate Hazard Connector (GL-DATA-GEO-002)
Status: Production Ready
"""

from __future__ import annotations

import hashlib
import json
import logging
import math
import threading
import time
import uuid
from collections import defaultdict
from dataclasses import dataclass, field as dc_field
from datetime import datetime, timezone
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)


# ---------------------------------------------------------------------------
# Module-level exports
# ---------------------------------------------------------------------------

__all__ = ["VulnerabilityScorerEngine"]


# ---------------------------------------------------------------------------
# Graceful imports -- provenance.py
# ---------------------------------------------------------------------------

try:
    from greenlang.climate_hazard.provenance import ProvenanceTracker
except Exception:  # pragma: no cover -- fallback when module unavailable

    class ProvenanceTracker:  # type: ignore[no-redef]
        """Minimal fallback ProvenanceTracker when module unavailable."""

        GENESIS_HASH = hashlib.sha256(
            b"greenlang-climate-hazard-connector-genesis"
        ).hexdigest()

        def __init__(
            self, genesis_hash: str = "greenlang-climate-hazard-connector-genesis"
        ) -> None:
            self._lock = threading.Lock()
            self._chain: List[Dict[str, Any]] = []
            self._last: str = self.GENESIS_HASH

        def hash_record(self, data: Dict[str, Any]) -> str:
            s = json.dumps(data, sort_keys=True, default=str)
            return hashlib.sha256(s.encode("utf-8")).hexdigest()

        def build_hash(self, data: Any) -> str:
            s = json.dumps(data, sort_keys=True, default=str)
            return hashlib.sha256(s.encode("utf-8")).hexdigest()

        def record(
            self,
            entity_type: str,
            action: str,
            entity_id: str,
            data: Any = None,
            metadata: Optional[Dict[str, Any]] = None,
        ) -> Any:
            ts = datetime.now(timezone.utc).isoformat()
            data_hash = self.build_hash(data)
            combined = json.dumps(
                {
                    "previous": self._last,
                    "input": data_hash,
                    "output": data_hash,
                    "operation": action,
                    "timestamp": ts,
                },
                sort_keys=True,
            )
            chain_hash = hashlib.sha256(combined.encode("utf-8")).hexdigest()
            with self._lock:
                self._chain.append(
                    {
                        "entity_type": entity_type,
                        "entity_id": entity_id,
                        "action": action,
                        "data_hash": data_hash,
                        "timestamp": ts,
                        "chain_hash": chain_hash,
                    }
                )
                self._last = chain_hash

            class _Entry:
                def __init__(self, hv: str) -> None:
                    self.hash_value = hv

            return _Entry(chain_hash)

        def reset(self) -> None:
            with self._lock:
                self._chain.clear()
                self._last = self.GENESIS_HASH

        @property
        def entry_count(self) -> int:
            with self._lock:
                return len(self._chain)


# ---------------------------------------------------------------------------
# Graceful imports -- metrics.py
# ---------------------------------------------------------------------------

try:
    from greenlang.climate_hazard.metrics import (
        record_vulnerability as _record_vulnerability_metric,
        observe_pipeline_duration as _observe_pipeline_duration,
    )
except Exception:  # pragma: no cover

    def _record_vulnerability_metric(sector: str, hazard_type: str) -> None:  # type: ignore[misc]
        """No-op metric stub."""

    def _observe_pipeline_duration(pipeline_stage: str, seconds: float) -> None:  # type: ignore[misc]
        """No-op metric stub."""


# ---------------------------------------------------------------------------
# Graceful imports -- config.py
# ---------------------------------------------------------------------------

try:
    from greenlang.climate_hazard.config import get_config as _get_config
except Exception:  # pragma: no cover

    def _get_config() -> Any:  # type: ignore[misc]
        """Return a minimal config-like object with vulnerability weights."""

        class _MinimalConfig:
            vuln_weight_exposure: float = 0.40
            vuln_weight_sensitivity: float = 0.35
            vuln_weight_adaptive: float = 0.25
            default_scenario: str = "SSP2-4.5"
            default_time_horizon: str = "MID_TERM"
            enable_provenance: bool = True
            enable_metrics: bool = True

        return _MinimalConfig()


# ---------------------------------------------------------------------------
# Enumerations
# ---------------------------------------------------------------------------


class VulnerabilityLevel(str, Enum):
    """Five-tier vulnerability classification (IPCC AR5/AR6 aligned).

    Thresholds:
        NEGLIGIBLE:  0 <= score < 20
        LOW:        20 <= score < 40
        MODERATE:   40 <= score < 60
        HIGH:       60 <= score < 80
        CRITICAL:   80 <= score <= 100
    """

    NEGLIGIBLE = "negligible"
    LOW = "low"
    MODERATE = "moderate"
    HIGH = "high"
    CRITICAL = "critical"


class AdaptationEffectivenessLevel(str, Enum):
    """Effectiveness classification for adaptation measures."""

    VERY_HIGH = "very_high"
    HIGH = "high"
    MODERATE = "moderate"
    LOW = "low"
    NEGLIGIBLE = "negligible"


# ---------------------------------------------------------------------------
# Data Models
# ---------------------------------------------------------------------------


@dataclass
class VulnerabilityScore:
    """Result of a single vulnerability assessment.

    Attributes:
        score_id: Unique identifier (VS-<uuid_hex[:12]>).
        entity_id: Identifier of the assessed entity.
        hazard_type: Climate hazard type assessed against.
        exposure_score: Exposure score (0-100 scale).
        sensitivity_score: Computed sensitivity (0-1, mean of factors).
        adaptive_capacity_score: Computed adaptive capacity (0-1, mean of indicators).
        vulnerability_score: Final vulnerability score (0-100 scale).
        vulnerability_level: Categorical vulnerability level.
        scenario: Climate scenario used (e.g. SSP2-4.5).
        time_horizon: Time horizon of assessment.
        factor_contributions: Breakdown of each component's contribution.
        scored_at: ISO 8601 UTC timestamp.
        provenance_hash: SHA-256 provenance hash for audit trail.
    """

    score_id: str = ""
    entity_id: str = ""
    hazard_type: str = ""
    exposure_score: float = 0.0
    sensitivity_score: float = 0.0
    adaptive_capacity_score: float = 0.0
    vulnerability_score: float = 0.0
    vulnerability_level: str = VulnerabilityLevel.NEGLIGIBLE.value
    scenario: str = ""
    time_horizon: str = ""
    factor_contributions: Dict[str, Any] = dc_field(default_factory=dict)
    scored_at: str = ""
    provenance_hash: str = ""

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization.

        Returns:
            Dictionary representation of the vulnerability score.
        """
        return {
            "score_id": self.score_id,
            "entity_id": self.entity_id,
            "hazard_type": self.hazard_type,
            "exposure_score": self.exposure_score,
            "sensitivity_score": self.sensitivity_score,
            "adaptive_capacity_score": self.adaptive_capacity_score,
            "vulnerability_score": self.vulnerability_score,
            "vulnerability_level": self.vulnerability_level,
            "scenario": self.scenario,
            "time_horizon": self.time_horizon,
            "factor_contributions": self.factor_contributions,
            "scored_at": self.scored_at,
            "provenance_hash": self.provenance_hash,
        }


@dataclass
class SensitivityProfile:
    """Stored sensitivity profile for an entity in a specific sector.

    Attributes:
        profile_id: Unique identifier (SP-<uuid_hex[:12]>).
        entity_id: Identifier of the entity this profile belongs to.
        sector: Economic sector for this profile.
        factors: Mapping of factor_name -> value (0.0 to 1.0).
        overall_sensitivity: Mean of all factor values.
        created_at: ISO 8601 UTC timestamp.
        updated_at: ISO 8601 UTC timestamp of last update.
        provenance_hash: SHA-256 provenance hash for audit trail.
    """

    profile_id: str = ""
    entity_id: str = ""
    sector: str = ""
    factors: Dict[str, float] = dc_field(default_factory=dict)
    overall_sensitivity: float = 0.0
    created_at: str = ""
    updated_at: str = ""
    provenance_hash: str = ""

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization.

        Returns:
            Dictionary representation of the sensitivity profile.
        """
        return {
            "profile_id": self.profile_id,
            "entity_id": self.entity_id,
            "sector": self.sector,
            "factors": dict(self.factors),
            "overall_sensitivity": self.overall_sensitivity,
            "created_at": self.created_at,
            "updated_at": self.updated_at,
            "provenance_hash": self.provenance_hash,
        }


@dataclass
class AdaptiveCapacityProfile:
    """Stored adaptive capacity profile for an entity.

    Attributes:
        profile_id: Unique identifier (ACP-<uuid_hex[:12]>).
        entity_id: Identifier of the entity this profile belongs to.
        indicators: Mapping of indicator_name -> value (0.0 to 1.0).
        overall_capacity: Mean of all indicator values.
        created_at: ISO 8601 UTC timestamp.
        updated_at: ISO 8601 UTC timestamp of last update.
        provenance_hash: SHA-256 provenance hash for audit trail.
    """

    profile_id: str = ""
    entity_id: str = ""
    indicators: Dict[str, float] = dc_field(default_factory=dict)
    overall_capacity: float = 0.0
    created_at: str = ""
    updated_at: str = ""
    provenance_hash: str = ""

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization.

        Returns:
            Dictionary representation of the adaptive capacity profile.
        """
        return {
            "profile_id": self.profile_id,
            "entity_id": self.entity_id,
            "indicators": dict(self.indicators),
            "overall_capacity": self.overall_capacity,
            "created_at": self.created_at,
            "updated_at": self.updated_at,
            "provenance_hash": self.provenance_hash,
        }


@dataclass
class ResidualRiskResult:
    """Result of a residual risk calculation (post-adaptation).

    Attributes:
        result_id: Unique identifier (RR-<uuid_hex[:12]>).
        entity_id: Identifier of the entity assessed.
        original_score: Original vulnerability score before adaptation.
        residual_score: Residual vulnerability score after adaptation.
        risk_reduction_pct: Percentage reduction in vulnerability.
        measures_applied: List of adaptation measures that were applied.
        effectiveness_level: Overall effectiveness classification.
        calculated_at: ISO 8601 UTC timestamp.
        provenance_hash: SHA-256 provenance hash for audit trail.
    """

    result_id: str = ""
    entity_id: str = ""
    original_score: float = 0.0
    residual_score: float = 0.0
    risk_reduction_pct: float = 0.0
    measures_applied: List[Dict[str, Any]] = dc_field(default_factory=list)
    effectiveness_level: str = ""
    calculated_at: str = ""
    provenance_hash: str = ""

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization.

        Returns:
            Dictionary representation of the residual risk result.
        """
        return {
            "result_id": self.result_id,
            "entity_id": self.entity_id,
            "original_score": self.original_score,
            "residual_score": self.residual_score,
            "risk_reduction_pct": self.risk_reduction_pct,
            "measures_applied": list(self.measures_applied),
            "effectiveness_level": self.effectiveness_level,
            "calculated_at": self.calculated_at,
            "provenance_hash": self.provenance_hash,
        }


@dataclass
class EntityRanking:
    """Ranked entity entry for comparative vulnerability analysis.

    Attributes:
        rank: 1-based ranking position (1 = most vulnerable).
        entity_id: Identifier of the ranked entity.
        vulnerability_score: Vulnerability score for ranking.
        vulnerability_level: Categorical vulnerability level.
        percentile: Percentile position (0-100, 100 = most vulnerable).
    """

    rank: int = 0
    entity_id: str = ""
    vulnerability_score: float = 0.0
    vulnerability_level: str = VulnerabilityLevel.NEGLIGIBLE.value
    percentile: float = 0.0

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization.

        Returns:
            Dictionary representation of the entity ranking.
        """
        return {
            "rank": self.rank,
            "entity_id": self.entity_id,
            "vulnerability_score": self.vulnerability_score,
            "vulnerability_level": self.vulnerability_level,
            "percentile": self.percentile,
        }


# ---------------------------------------------------------------------------
# Helper functions
# ---------------------------------------------------------------------------


def _utcnow() -> datetime:
    """Return current UTC datetime."""
    return datetime.now(timezone.utc)


def _utcnow_iso() -> str:
    """Return current UTC datetime as ISO 8601 string."""
    return _utcnow().replace(microsecond=0).isoformat()


def _generate_id(prefix: str) -> str:
    """Generate a unique identifier with the given prefix.

    Args:
        prefix: Short string prefix (e.g. 'VS', 'SP', 'ACP', 'RR').

    Returns:
        String in the format ``<prefix>-<uuid4_hex[:12]>``.
    """
    return f"{prefix}-{uuid.uuid4().hex[:12]}"


def _safe_mean(values: List[float]) -> float:
    """Compute arithmetic mean, returning 0.0 for empty lists.

    Args:
        values: List of numeric values.

    Returns:
        Arithmetic mean, or 0.0 if the list is empty.
    """
    if not values:
        return 0.0
    return sum(values) / len(values)


def _clamp(value: float, lo: float = 0.0, hi: float = 100.0) -> float:
    """Clamp a numeric value to [lo, hi].

    Args:
        value: The value to clamp.
        lo: Lower bound (default 0.0).
        hi: Upper bound (default 100.0).

    Returns:
        Clamped value.
    """
    return max(lo, min(hi, value))


def _classify_vulnerability(score: float) -> VulnerabilityLevel:
    """Classify a vulnerability score into one of five levels.

    Thresholds (IPCC-aligned):
        >= 80: CRITICAL
        >= 60: HIGH
        >= 40: MODERATE
        >= 20: LOW
        <  20: NEGLIGIBLE

    Args:
        score: Vulnerability score in [0, 100].

    Returns:
        VulnerabilityLevel enum value.
    """
    if score >= 80.0:
        return VulnerabilityLevel.CRITICAL
    if score >= 60.0:
        return VulnerabilityLevel.HIGH
    if score >= 40.0:
        return VulnerabilityLevel.MODERATE
    if score >= 20.0:
        return VulnerabilityLevel.LOW
    return VulnerabilityLevel.NEGLIGIBLE


def _classify_effectiveness(reduction_pct: float) -> AdaptationEffectivenessLevel:
    """Classify adaptation effectiveness based on risk reduction percentage.

    Thresholds:
        >= 80%: VERY_HIGH
        >= 60%: HIGH
        >= 40%: MODERATE
        >= 20%: LOW
        <  20%: NEGLIGIBLE

    Args:
        reduction_pct: Percentage reduction in vulnerability (0-100).

    Returns:
        AdaptationEffectivenessLevel enum value.
    """
    if reduction_pct >= 80.0:
        return AdaptationEffectivenessLevel.VERY_HIGH
    if reduction_pct >= 60.0:
        return AdaptationEffectivenessLevel.HIGH
    if reduction_pct >= 40.0:
        return AdaptationEffectivenessLevel.MODERATE
    if reduction_pct >= 20.0:
        return AdaptationEffectivenessLevel.LOW
    return AdaptationEffectivenessLevel.NEGLIGIBLE


def _build_provenance_hash(data: Any) -> str:
    """Build a SHA-256 hash for arbitrary data for provenance tracking.

    Args:
        data: Any JSON-serializable object.

    Returns:
        Hex-encoded SHA-256 hash string.
    """
    serialized = json.dumps(data, sort_keys=True, default=str)
    return hashlib.sha256(serialized.encode("utf-8")).hexdigest()


# ---------------------------------------------------------------------------
# Sector-Specific Sensitivity Factor Defaults
# ---------------------------------------------------------------------------

# Each sector has five named sensitivity factors, all defaulting to 0.5
# when used by score_sector_vulnerability.  These represent the canonical
# IPCC AR5/AR6 sector sensitivity dimensions for climate hazard assessment.

SECTOR_SENSITIVITY_FACTORS: Dict[str, Dict[str, float]] = {
    "agriculture": {
        "crop_diversity": 0.5,
        "irrigation_coverage": 0.5,
        "soil_quality": 0.5,
        "growing_season_stability": 0.5,
        "pest_resistance": 0.5,
    },
    "real_estate": {
        "building_age_factor": 0.5,
        "construction_quality": 0.5,
        "flood_proofing": 0.5,
        "insulation_rating": 0.5,
        "structural_resilience": 0.5,
    },
    "infrastructure": {
        "design_standard": 0.5,
        "maintenance_level": 0.5,
        "redundancy": 0.5,
        "material_durability": 0.5,
        "age_factor": 0.5,
    },
    "supply_chain": {
        "supplier_diversity": 0.5,
        "inventory_buffer": 0.5,
        "lead_time_flexibility": 0.5,
        "geographic_spread": 0.5,
        "contractual_protection": 0.5,
    },
    "natural_assets": {
        "ecosystem_health": 0.5,
        "biodiversity_index": 0.5,
        "connectivity": 0.5,
        "regeneration_capacity": 0.5,
        "protection_status": 0.5,
    },
    "energy": {
        "grid_resilience": 0.5,
        "fuel_diversity": 0.5,
        "storage_capacity": 0.5,
        "demand_flexibility": 0.5,
        "infrastructure_age": 0.5,
    },
    "financial": {
        "capital_reserves": 0.5,
        "insurance_coverage": 0.5,
        "portfolio_diversity": 0.5,
        "liquidity_ratio": 0.5,
        "stress_test_score": 0.5,
    },
    "manufacturing": {
        "process_flexibility": 0.5,
        "water_dependency": 0.5,
        "energy_intensity": 0.5,
        "raw_material_diversity": 0.5,
        "automation_level": 0.5,
    },
}

# ---------------------------------------------------------------------------
# Adaptive Capacity Indicator Defaults
# ---------------------------------------------------------------------------

# 10 adaptive capacity indicators, each defaulting to 0.5.  These represent
# the generic adaptive capacity dimensions applicable across all sectors.

DEFAULT_ADAPTIVE_CAPACITY_INDICATORS: Dict[str, float] = {
    "financial_reserves": 0.5,
    "insurance_coverage": 0.5,
    "early_warning_systems": 0.5,
    "emergency_preparedness": 0.5,
    "infrastructure_redundancy": 0.5,
    "backup_systems": 0.5,
    "workforce_flexibility": 0.5,
    "governance_quality": 0.5,
    "regulatory_environment": 0.5,
    "technology_adoption": 0.5,
}

# ---------------------------------------------------------------------------
# Valid hazard types (accepted by the scorer)
# ---------------------------------------------------------------------------

VALID_HAZARD_TYPES: frozenset = frozenset(
    {
        "flood",
        "drought",
        "wildfire",
        "heat_wave",
        "cold_wave",
        "storm",
        "sea_level_rise",
        "tropical_cyclone",
        "landslide",
        "water_stress",
        "precipitation_change",
        "temperature_change",
        "compound",
    }
)

# ---------------------------------------------------------------------------
# Valid sectors
# ---------------------------------------------------------------------------

VALID_SECTORS: frozenset = frozenset(SECTOR_SENSITIVITY_FACTORS.keys())

# ---------------------------------------------------------------------------
# Hazard-sector sensitivity multipliers
# ---------------------------------------------------------------------------

# Certain hazard-sector combinations have elevated baseline sensitivity.
# These multipliers are applied to the raw sensitivity score before the
# final vulnerability calculation to reflect domain knowledge about which
# sectors are inherently more sensitive to specific hazard types.  A
# multiplier of 1.0 means no adjustment; > 1.0 increases sensitivity.

HAZARD_SECTOR_MULTIPLIERS: Dict[str, Dict[str, float]] = {
    "flood": {
        "agriculture": 1.25,
        "real_estate": 1.20,
        "infrastructure": 1.15,
        "supply_chain": 1.10,
        "natural_assets": 1.05,
        "energy": 1.00,
        "financial": 1.00,
        "manufacturing": 1.10,
    },
    "drought": {
        "agriculture": 1.35,
        "real_estate": 1.00,
        "infrastructure": 1.05,
        "supply_chain": 1.10,
        "natural_assets": 1.25,
        "energy": 1.15,
        "financial": 1.00,
        "manufacturing": 1.10,
    },
    "wildfire": {
        "agriculture": 1.20,
        "real_estate": 1.25,
        "infrastructure": 1.20,
        "supply_chain": 1.10,
        "natural_assets": 1.30,
        "energy": 1.15,
        "financial": 1.00,
        "manufacturing": 1.05,
    },
    "heat_wave": {
        "agriculture": 1.30,
        "real_estate": 1.10,
        "infrastructure": 1.15,
        "supply_chain": 1.05,
        "natural_assets": 1.20,
        "energy": 1.25,
        "financial": 1.00,
        "manufacturing": 1.15,
    },
    "cold_wave": {
        "agriculture": 1.20,
        "real_estate": 1.10,
        "infrastructure": 1.20,
        "supply_chain": 1.15,
        "natural_assets": 1.10,
        "energy": 1.25,
        "financial": 1.00,
        "manufacturing": 1.10,
    },
    "storm": {
        "agriculture": 1.15,
        "real_estate": 1.20,
        "infrastructure": 1.25,
        "supply_chain": 1.20,
        "natural_assets": 1.10,
        "energy": 1.20,
        "financial": 1.00,
        "manufacturing": 1.10,
    },
    "sea_level_rise": {
        "agriculture": 1.15,
        "real_estate": 1.30,
        "infrastructure": 1.25,
        "supply_chain": 1.15,
        "natural_assets": 1.25,
        "energy": 1.10,
        "financial": 1.05,
        "manufacturing": 1.10,
    },
    "tropical_cyclone": {
        "agriculture": 1.25,
        "real_estate": 1.25,
        "infrastructure": 1.30,
        "supply_chain": 1.20,
        "natural_assets": 1.15,
        "energy": 1.20,
        "financial": 1.05,
        "manufacturing": 1.15,
    },
    "landslide": {
        "agriculture": 1.15,
        "real_estate": 1.25,
        "infrastructure": 1.30,
        "supply_chain": 1.10,
        "natural_assets": 1.15,
        "energy": 1.10,
        "financial": 1.00,
        "manufacturing": 1.05,
    },
    "water_stress": {
        "agriculture": 1.35,
        "real_estate": 1.05,
        "infrastructure": 1.10,
        "supply_chain": 1.10,
        "natural_assets": 1.30,
        "energy": 1.20,
        "financial": 1.00,
        "manufacturing": 1.25,
    },
    "precipitation_change": {
        "agriculture": 1.30,
        "real_estate": 1.05,
        "infrastructure": 1.10,
        "supply_chain": 1.05,
        "natural_assets": 1.20,
        "energy": 1.10,
        "financial": 1.00,
        "manufacturing": 1.10,
    },
    "temperature_change": {
        "agriculture": 1.25,
        "real_estate": 1.10,
        "infrastructure": 1.10,
        "supply_chain": 1.05,
        "natural_assets": 1.20,
        "energy": 1.20,
        "financial": 1.00,
        "manufacturing": 1.15,
    },
    "compound": {
        "agriculture": 1.30,
        "real_estate": 1.20,
        "infrastructure": 1.25,
        "supply_chain": 1.20,
        "natural_assets": 1.25,
        "energy": 1.20,
        "financial": 1.10,
        "manufacturing": 1.20,
    },
}

# ---------------------------------------------------------------------------
# Scenario severity multipliers
# ---------------------------------------------------------------------------

# Higher-emission scenarios amplify vulnerability.  These multipliers
# adjust the raw vulnerability score to reflect the severity of the
# climate scenario under assessment.

SCENARIO_MULTIPLIERS: Dict[str, float] = {
    "SSP1-1.9": 0.85,
    "SSP1-2.6": 0.90,
    "SSP2-4.5": 1.00,
    "SSP3-7.0": 1.10,
    "SSP5-8.5": 1.20,
    "RCP2.6": 0.90,
    "RCP4.5": 1.00,
    "RCP6.0": 1.05,
    "RCP8.5": 1.20,
}

# ---------------------------------------------------------------------------
# Time horizon multipliers
# ---------------------------------------------------------------------------

# Longer time horizons generally increase vulnerability due to
# compounding climate effects and infrastructure aging.

TIME_HORIZON_MULTIPLIERS: Dict[str, float] = {
    "SHORT_TERM": 0.90,
    "MID_TERM": 1.00,
    "LONG_TERM": 1.15,
}


# ---------------------------------------------------------------------------
# VulnerabilityScorerEngine
# ---------------------------------------------------------------------------


class VulnerabilityScorerEngine:
    """IPCC AR5/AR6 vulnerability scoring engine for climate hazard assessment.

    Computes entity vulnerability as a weighted function of exposure,
    sensitivity, and adaptive capacity, following the IPCC AR5/AR6
    vulnerability framework:

        vulnerability = (w_exp * exposure + w_sens * sensitivity
                         - w_adapt * adaptive_capacity) * 100

    The result is clamped to [0, 100] and classified into one of five
    vulnerability levels: NEGLIGIBLE, LOW, MODERATE, HIGH, CRITICAL.

    Supports:
        - Full vulnerability scoring with custom sensitivity factors
          and adaptive capacity indicators
        - Sector-level scoring using built-in defaults
        - Sensitivity profile management (create/get)
        - Adaptive capacity profile management (create/get)
        - Residual risk calculation with adaptation measures
        - Entity ranking by vulnerability score
        - Score retrieval and filtered listing
        - Engine statistics and state management

    Thread Safety:
        All mutable state is protected by ``threading.Lock``.

    Zero-Hallucination:
        All numeric computations are deterministic Python arithmetic.
        No LLM calls for scoring, classification, or ranking.

    Attributes:
        _exposure_engine: Optional reference to ExposureAssessorEngine.
        _provenance: ProvenanceTracker for SHA-256 audit trails.
        _config: ClimateHazardConfig for vulnerability weights.
        _lock: Threading lock for thread-safe state access.
        _scores: In-memory store of vulnerability scores keyed by score_id.
        _sensitivity_profiles: Store of sensitivity profiles keyed by profile_id.
        _adaptive_profiles: Store of adaptive capacity profiles keyed by profile_id.
        _residual_results: Store of residual risk results keyed by result_id.
        _entity_score_index: Index mapping entity_id to list of score_ids.
        _hazard_score_index: Index mapping hazard_type to list of score_ids.
        _level_score_index: Index mapping vulnerability_level to list of score_ids.
        _entity_sensitivity_index: Index mapping entity_id to list of profile_ids.
        _entity_adaptive_index: Index mapping entity_id to list of profile_ids.
        _total_scored: Running count of total vulnerability scores computed.
        _total_profiles_created: Running count of profiles created.
        _total_residual_calcs: Running count of residual risk calculations.
        _total_rankings: Running count of ranking operations.
        _total_errors: Running count of processing errors.

    Example:
        >>> engine = VulnerabilityScorerEngine()
        >>> result = engine.score_vulnerability(
        ...     entity_id="farm-001",
        ...     hazard_type="drought",
        ...     exposure_score=70.0,
        ...     sensitivity_factors={"crop_diversity": 0.3, "soil_quality": 0.6},
        ...     adaptive_capacity_indicators={"financial_reserves": 0.7},
        ... )
        >>> print(result["vulnerability_level"])
    """

    # ------------------------------------------------------------------
    # Initialization
    # ------------------------------------------------------------------

    def __init__(
        self,
        exposure_engine: Optional[Any] = None,
        provenance: Optional[ProvenanceTracker] = None,
        genesis_hash: Optional[str] = None,
    ) -> None:
        """Initialize VulnerabilityScorerEngine.

        Args:
            exposure_engine: Optional ExposureAssessorEngine for
                integrated exposure lookups. When provided, enables
                automatic exposure score retrieval.
            provenance: Optional ProvenanceTracker instance. When None,
                a new tracker is created with the given genesis_hash.
            genesis_hash: Optional genesis hash for provenance chain
                initialization. Ignored when provenance is provided.
        """
        self._exposure_engine = exposure_engine

        # Provenance tracker
        if provenance is not None:
            self._provenance = provenance
        elif genesis_hash is not None:
            self._provenance = ProvenanceTracker(genesis_hash=genesis_hash)
        else:
            self._provenance = ProvenanceTracker()

        # Configuration
        try:
            self._config = _get_config()
        except Exception:
            self._config = None

        # Threading lock
        self._lock = threading.Lock()

        # In-memory stores
        self._scores: Dict[str, VulnerabilityScore] = {}
        self._sensitivity_profiles: Dict[str, SensitivityProfile] = {}
        self._adaptive_profiles: Dict[str, AdaptiveCapacityProfile] = {}
        self._residual_results: Dict[str, ResidualRiskResult] = {}

        # Indexes for fast lookups
        self._entity_score_index: Dict[str, List[str]] = defaultdict(list)
        self._hazard_score_index: Dict[str, List[str]] = defaultdict(list)
        self._level_score_index: Dict[str, List[str]] = defaultdict(list)
        self._entity_sensitivity_index: Dict[str, List[str]] = defaultdict(list)
        self._entity_adaptive_index: Dict[str, List[str]] = defaultdict(list)

        # Counters
        self._total_scored: int = 0
        self._total_profiles_created: int = 0
        self._total_residual_calcs: int = 0
        self._total_rankings: int = 0
        self._total_errors: int = 0

        logger.info(
            "VulnerabilityScorerEngine initialized: "
            "exposure_engine=%s, provenance_entries=%d",
            "attached" if exposure_engine is not None else "none",
            self._provenance.entry_count,
        )

    # ------------------------------------------------------------------
    # Configuration access helpers
    # ------------------------------------------------------------------

    def _get_weight_exposure(self) -> float:
        """Return the exposure weight from config (default 0.40).

        Returns:
            Exposure weight as a float in [0.0, 1.0].
        """
        if self._config is not None:
            return getattr(self._config, "vuln_weight_exposure", 0.40)
        return 0.40

    def _get_weight_sensitivity(self) -> float:
        """Return the sensitivity weight from config (default 0.35).

        Returns:
            Sensitivity weight as a float in [0.0, 1.0].
        """
        if self._config is not None:
            return getattr(self._config, "vuln_weight_sensitivity", 0.35)
        return 0.35

    def _get_weight_adaptive(self) -> float:
        """Return the adaptive capacity weight from config (default 0.25).

        Returns:
            Adaptive capacity weight as a float in [0.0, 1.0].
        """
        if self._config is not None:
            return getattr(self._config, "vuln_weight_adaptive", 0.25)
        return 0.25

    def _get_default_scenario(self) -> str:
        """Return the default scenario from config (default SSP2-4.5).

        Returns:
            Default scenario string.
        """
        if self._config is not None:
            return getattr(self._config, "default_scenario", "SSP2-4.5")
        return "SSP2-4.5"

    def _get_default_time_horizon(self) -> str:
        """Return the default time horizon from config (default MID_TERM).

        Returns:
            Default time horizon string.
        """
        if self._config is not None:
            return getattr(self._config, "default_time_horizon", "MID_TERM")
        return "MID_TERM"

    def _is_provenance_enabled(self) -> bool:
        """Return whether provenance tracking is enabled.

        Returns:
            True if provenance tracking is enabled.
        """
        if self._config is not None:
            return getattr(self._config, "enable_provenance", True)
        return True

    def _is_metrics_enabled(self) -> bool:
        """Return whether metrics export is enabled.

        Returns:
            True if metrics export is enabled.
        """
        if self._config is not None:
            return getattr(self._config, "enable_metrics", True)
        return True

    # ------------------------------------------------------------------
    # Core vulnerability calculation (IPCC AR5/AR6)
    # ------------------------------------------------------------------

    def _compute_vulnerability(
        self,
        exposure_normalised: float,
        sensitivity: float,
        adaptive_capacity: float,
    ) -> float:
        """Compute raw vulnerability score using IPCC AR5/AR6 formula.

        Formula:
            vulnerability = (w_exp * exposure + w_sens * sensitivity
                             - w_adapt * adaptive_capacity) * 100

        The result is clamped to [0, 100].

        Args:
            exposure_normalised: Exposure on 0-1 scale (exposure_score / 100).
            sensitivity: Sensitivity on 0-1 scale (mean of factors).
            adaptive_capacity: Adaptive capacity on 0-1 scale (mean of indicators).

        Returns:
            Vulnerability score in [0.0, 100.0].
        """
        w_exp = self._get_weight_exposure()
        w_sens = self._get_weight_sensitivity()
        w_adapt = self._get_weight_adaptive()

        raw = (
            w_exp * exposure_normalised
            + w_sens * sensitivity
            - w_adapt * adaptive_capacity
        ) * 100.0

        return _clamp(raw, 0.0, 100.0)

    def _apply_scenario_multiplier(
        self,
        score: float,
        scenario: Optional[str],
    ) -> float:
        """Apply scenario severity multiplier to the vulnerability score.

        Args:
            score: Raw vulnerability score in [0, 100].
            scenario: Climate scenario string (e.g. SSP2-4.5).

        Returns:
            Adjusted score, clamped to [0, 100].
        """
        if scenario is None:
            return score
        multiplier = SCENARIO_MULTIPLIERS.get(scenario, 1.0)
        return _clamp(score * multiplier, 0.0, 100.0)

    def _apply_time_horizon_multiplier(
        self,
        score: float,
        time_horizon: Optional[str],
    ) -> float:
        """Apply time horizon multiplier to the vulnerability score.

        Args:
            score: Vulnerability score in [0, 100].
            time_horizon: Time horizon string (SHORT_TERM, MID_TERM, LONG_TERM).

        Returns:
            Adjusted score, clamped to [0, 100].
        """
        if time_horizon is None:
            return score
        multiplier = TIME_HORIZON_MULTIPLIERS.get(time_horizon, 1.0)
        return _clamp(score * multiplier, 0.0, 100.0)

    def _apply_hazard_sector_multiplier(
        self,
        sensitivity: float,
        hazard_type: str,
        sector: Optional[str],
    ) -> float:
        """Apply hazard-sector sensitivity multiplier.

        Args:
            sensitivity: Base sensitivity score on 0-1 scale.
            hazard_type: Climate hazard type.
            sector: Economic sector (optional).

        Returns:
            Adjusted sensitivity, clamped to [0, 1].
        """
        if sector is None:
            return sensitivity
        hazard_multipliers = HAZARD_SECTOR_MULTIPLIERS.get(hazard_type, {})
        multiplier = hazard_multipliers.get(sector, 1.0)
        return _clamp(sensitivity * multiplier, 0.0, 1.0)

    def _compute_factor_contributions(
        self,
        exposure_normalised: float,
        sensitivity: float,
        adaptive_capacity: float,
        vulnerability_score: float,
        sensitivity_factors: Dict[str, float],
        adaptive_capacity_indicators: Dict[str, float],
    ) -> Dict[str, Any]:
        """Compute detailed factor contribution breakdown.

        Args:
            exposure_normalised: Exposure on 0-1 scale.
            sensitivity: Overall sensitivity on 0-1 scale.
            adaptive_capacity: Overall adaptive capacity on 0-1 scale.
            vulnerability_score: Final vulnerability score.
            sensitivity_factors: Individual sensitivity factor values.
            adaptive_capacity_indicators: Individual adaptive capacity values.

        Returns:
            Dictionary with weighted contributions and factor-level details.
        """
        w_exp = self._get_weight_exposure()
        w_sens = self._get_weight_sensitivity()
        w_adapt = self._get_weight_adaptive()

        exposure_contribution = w_exp * exposure_normalised * 100.0
        sensitivity_contribution = w_sens * sensitivity * 100.0
        adaptive_contribution = w_adapt * adaptive_capacity * 100.0

        # Compute individual factor contributions as fraction of total
        # sensitivity contribution
        factor_details: Dict[str, Dict[str, float]] = {}
        n_factors = len(sensitivity_factors) if sensitivity_factors else 1
        for fname, fval in sensitivity_factors.items():
            factor_details[fname] = {
                "value": round(fval, 6),
                "weight": round(1.0 / n_factors, 6),
                "contribution": round(fval / n_factors, 6),
            }

        indicator_details: Dict[str, Dict[str, float]] = {}
        n_indicators = len(adaptive_capacity_indicators) if adaptive_capacity_indicators else 1
        for iname, ival in adaptive_capacity_indicators.items():
            indicator_details[iname] = {
                "value": round(ival, 6),
                "weight": round(1.0 / n_indicators, 6),
                "contribution": round(ival / n_indicators, 6),
            }

        return {
            "weights": {
                "exposure": round(w_exp, 4),
                "sensitivity": round(w_sens, 4),
                "adaptive_capacity": round(w_adapt, 4),
            },
            "component_scores": {
                "exposure_normalised": round(exposure_normalised, 6),
                "sensitivity": round(sensitivity, 6),
                "adaptive_capacity": round(adaptive_capacity, 6),
            },
            "component_contributions": {
                "exposure": round(exposure_contribution, 4),
                "sensitivity": round(sensitivity_contribution, 4),
                "adaptive_capacity": round(adaptive_contribution, 4),
            },
            "sensitivity_factors": factor_details,
            "adaptive_capacity_indicators": indicator_details,
            "formula": (
                f"({w_exp} * {round(exposure_normalised, 4)} "
                f"+ {w_sens} * {round(sensitivity, 4)} "
                f"- {w_adapt} * {round(adaptive_capacity, 4)}) * 100 "
                f"= {round(vulnerability_score, 4)}"
            ),
        }

    # ------------------------------------------------------------------
    # Provenance helper
    # ------------------------------------------------------------------

    def _record_provenance(
        self,
        entity_id: str,
        action: str,
        data: Any,
    ) -> str:
        """Record a provenance entry and return the hash.

        Args:
            entity_id: Entity identifier for provenance.
            action: Action label (e.g. score_vulnerability).
            data: Data payload to hash.

        Returns:
            SHA-256 provenance hash string.
        """
        if not self._is_provenance_enabled():
            return _build_provenance_hash(data)

        try:
            entry = self._provenance.record(
                entity_type="vulnerability",
                action=action,
                entity_id=entity_id,
                data=data,
            )
            return getattr(entry, "hash_value", _build_provenance_hash(data))
        except Exception as exc:
            logger.warning(
                "Provenance recording failed for %s/%s: %s",
                entity_id,
                action,
                exc,
            )
            return _build_provenance_hash(data)

    # ------------------------------------------------------------------
    # Input validation helpers
    # ------------------------------------------------------------------

    def _validate_entity_id(self, entity_id: str) -> None:
        """Validate entity_id is a non-empty string.

        Args:
            entity_id: Entity identifier to validate.

        Raises:
            ValueError: If entity_id is empty or not a string.
        """
        if not entity_id or not isinstance(entity_id, str):
            raise ValueError(
                f"entity_id must be a non-empty string, got {entity_id!r}"
            )

    def _validate_hazard_type(self, hazard_type: str) -> None:
        """Validate hazard_type is a recognized climate hazard.

        Args:
            hazard_type: Hazard type string to validate.

        Raises:
            ValueError: If hazard_type is empty or not recognized.
        """
        if not hazard_type or not isinstance(hazard_type, str):
            raise ValueError(
                f"hazard_type must be a non-empty string, got {hazard_type!r}"
            )
        if hazard_type not in VALID_HAZARD_TYPES:
            logger.warning(
                "Unrecognized hazard_type '%s'; "
                "scoring will proceed but no sector multiplier applied. "
                "Valid types: %s",
                hazard_type,
                sorted(VALID_HAZARD_TYPES),
            )

    def _validate_exposure_score(self, exposure_score: float) -> float:
        """Validate and normalise exposure_score to [0, 100].

        Args:
            exposure_score: Exposure score input (should be 0-100).

        Returns:
            Clamped exposure score in [0, 100].

        Raises:
            TypeError: If exposure_score is not numeric.
        """
        if not isinstance(exposure_score, (int, float)):
            raise TypeError(
                f"exposure_score must be numeric, got {type(exposure_score).__name__}"
            )
        if exposure_score < 0.0 or exposure_score > 100.0:
            logger.warning(
                "exposure_score %.4f outside [0, 100]; clamping", exposure_score
            )
        return _clamp(float(exposure_score), 0.0, 100.0)

    def _validate_factor_values(
        self,
        factors: Dict[str, float],
        label: str,
    ) -> Dict[str, float]:
        """Validate that all factor/indicator values are in [0, 1].

        Values outside [0, 1] are clamped and a warning is logged.

        Args:
            factors: Mapping of name -> value.
            label: Descriptive label for log messages (e.g. 'sensitivity').

        Returns:
            Validated dictionary with values clamped to [0, 1].

        Raises:
            TypeError: If factors is not a dict.
            ValueError: If factors is empty.
        """
        if not isinstance(factors, dict):
            raise TypeError(
                f"{label} must be a dict, got {type(factors).__name__}"
            )
        if not factors:
            raise ValueError(f"{label} must not be empty")

        validated: Dict[str, float] = {}
        for name, value in factors.items():
            if not isinstance(value, (int, float)):
                logger.warning(
                    "%s factor '%s' is not numeric (%s); defaulting to 0.5",
                    label,
                    name,
                    type(value).__name__,
                )
                validated[name] = 0.5
                continue

            fval = float(value)
            if fval < 0.0 or fval > 1.0:
                logger.warning(
                    "%s factor '%s' value %.4f outside [0, 1]; clamping",
                    label,
                    name,
                    fval,
                )
                fval = _clamp(fval, 0.0, 1.0)
            validated[name] = fval

        return validated

    def _validate_sector(self, sector: str) -> None:
        """Validate sector is a recognized sector name.

        Args:
            sector: Sector name to validate.

        Raises:
            ValueError: If sector is empty or not a string.
        """
        if not sector or not isinstance(sector, str):
            raise ValueError(
                f"sector must be a non-empty string, got {sector!r}"
            )
        if sector not in VALID_SECTORS:
            logger.warning(
                "Unrecognized sector '%s'; "
                "scoring will use generic defaults. "
                "Valid sectors: %s",
                sector,
                sorted(VALID_SECTORS),
            )

    # ------------------------------------------------------------------
    # Public Method 1: score_vulnerability
    # ------------------------------------------------------------------

    def score_vulnerability(
        self,
        entity_id: str,
        hazard_type: str,
        exposure_score: float,
        sensitivity_factors: Dict[str, float],
        adaptive_capacity_indicators: Dict[str, float],
        scenario: Optional[str] = None,
        time_horizon: Optional[str] = None,
    ) -> Dict[str, Any]:
        """Score entity vulnerability using IPCC AR5/AR6 framework.

        Computes vulnerability as a weighted combination of exposure,
        sensitivity (mean of factors), and adaptive capacity (mean of
        indicators), then applies optional scenario and time horizon
        multipliers.

        Formula:
            vulnerability = (w_exp * (exposure/100) + w_sens * sensitivity
                             - w_adapt * adaptive_capacity) * 100

        Args:
            entity_id: Unique identifier for the entity being assessed.
            hazard_type: Climate hazard type (flood, drought, wildfire,
                heat_wave, cold_wave, storm, sea_level_rise,
                tropical_cyclone, landslide, water_stress,
                precipitation_change, temperature_change, compound).
            exposure_score: Exposure score on 0-100 scale.
            sensitivity_factors: Dictionary of sensitivity factor names
                to values (0.0 to 1.0 each). The overall sensitivity
                score is the arithmetic mean of all values.
            adaptive_capacity_indicators: Dictionary of adaptive capacity
                indicator names to values (0.0 to 1.0 each). The overall
                adaptive capacity score is the arithmetic mean of all values.
            scenario: Optional climate scenario (SSP1-1.9, SSP1-2.6,
                SSP2-4.5, SSP3-7.0, SSP5-8.5, RCP2.6, RCP4.5, RCP6.0,
                RCP8.5). Defaults to config value (SSP2-4.5).
            time_horizon: Optional time horizon (SHORT_TERM, MID_TERM,
                LONG_TERM). Defaults to config value (MID_TERM).

        Returns:
            Dictionary containing:
                - score_id: Unique score identifier.
                - entity_id: Entity assessed.
                - hazard_type: Hazard assessed.
                - exposure_score: Validated exposure score (0-100).
                - sensitivity_score: Mean of sensitivity factors (0-1).
                - adaptive_capacity_score: Mean of adaptive indicators (0-1).
                - vulnerability_score: Final vulnerability score (0-100).
                - vulnerability_level: Categorical level.
                - scenario: Climate scenario used.
                - time_horizon: Time horizon used.
                - factor_contributions: Detailed breakdown.
                - scored_at: ISO 8601 UTC timestamp.
                - provenance_hash: SHA-256 audit trail hash.

        Raises:
            ValueError: If entity_id or hazard_type is empty.
            TypeError: If exposure_score is not numeric or factors
                are not dicts.
        """
        start_time = time.time()

        try:
            # Validate inputs
            self._validate_entity_id(entity_id)
            self._validate_hazard_type(hazard_type)
            validated_exposure = self._validate_exposure_score(exposure_score)
            validated_sensitivity = self._validate_factor_values(
                sensitivity_factors, "sensitivity_factors"
            )
            validated_adaptive = self._validate_factor_values(
                adaptive_capacity_indicators, "adaptive_capacity_indicators"
            )

            # Apply defaults from config
            effective_scenario = scenario or self._get_default_scenario()
            effective_horizon = time_horizon or self._get_default_time_horizon()

            # Compute component scores
            exposure_normalised = validated_exposure / 100.0
            sensitivity_score = _safe_mean(list(validated_sensitivity.values()))
            adaptive_capacity_score = _safe_mean(list(validated_adaptive.values()))

            # Compute raw vulnerability
            raw_vuln = self._compute_vulnerability(
                exposure_normalised=exposure_normalised,
                sensitivity=sensitivity_score,
                adaptive_capacity=adaptive_capacity_score,
            )

            # Apply scenario and time horizon multipliers
            adjusted_vuln = self._apply_scenario_multiplier(
                raw_vuln, effective_scenario
            )
            final_vuln = self._apply_time_horizon_multiplier(
                adjusted_vuln, effective_horizon
            )
            final_vuln = round(final_vuln, 4)

            # Classify
            vuln_level = _classify_vulnerability(final_vuln)

            # Factor contributions
            contributions = self._compute_factor_contributions(
                exposure_normalised=exposure_normalised,
                sensitivity=sensitivity_score,
                adaptive_capacity=adaptive_capacity_score,
                vulnerability_score=final_vuln,
                sensitivity_factors=validated_sensitivity,
                adaptive_capacity_indicators=validated_adaptive,
            )

            # Build result
            score_id = _generate_id("VS")
            scored_at = _utcnow_iso()

            # Provenance
            provenance_data = {
                "score_id": score_id,
                "entity_id": entity_id,
                "hazard_type": hazard_type,
                "exposure_score": validated_exposure,
                "sensitivity_score": round(sensitivity_score, 6),
                "adaptive_capacity_score": round(adaptive_capacity_score, 6),
                "vulnerability_score": final_vuln,
                "scenario": effective_scenario,
                "time_horizon": effective_horizon,
                "scored_at": scored_at,
            }
            provenance_hash = self._record_provenance(
                entity_id=entity_id,
                action="score_vulnerability",
                data=provenance_data,
            )

            # Build score object
            score_obj = VulnerabilityScore(
                score_id=score_id,
                entity_id=entity_id,
                hazard_type=hazard_type,
                exposure_score=round(validated_exposure, 4),
                sensitivity_score=round(sensitivity_score, 6),
                adaptive_capacity_score=round(adaptive_capacity_score, 6),
                vulnerability_score=final_vuln,
                vulnerability_level=vuln_level.value,
                scenario=effective_scenario,
                time_horizon=effective_horizon,
                factor_contributions=contributions,
                scored_at=scored_at,
                provenance_hash=provenance_hash,
            )

            # Store and index
            with self._lock:
                self._scores[score_id] = score_obj
                self._entity_score_index[entity_id].append(score_id)
                self._hazard_score_index[hazard_type].append(score_id)
                self._level_score_index[vuln_level.value].append(score_id)
                self._total_scored += 1

            # Metrics
            if self._is_metrics_enabled():
                try:
                    _record_vulnerability_metric("general", hazard_type)
                except Exception:
                    pass

            elapsed = time.time() - start_time
            if self._is_metrics_enabled():
                try:
                    _observe_pipeline_duration("vulnerability_scoring", elapsed)
                except Exception:
                    pass

            logger.info(
                "Scored vulnerability: entity=%s hazard=%s "
                "exposure=%.2f sensitivity=%.4f adaptive=%.4f "
                "vulnerability=%.2f level=%s scenario=%s horizon=%s "
                "score_id=%s elapsed=%.3fs",
                entity_id,
                hazard_type,
                validated_exposure,
                sensitivity_score,
                adaptive_capacity_score,
                final_vuln,
                vuln_level.value,
                effective_scenario,
                effective_horizon,
                score_id,
                elapsed,
            )

            return score_obj.to_dict()

        except (ValueError, TypeError):
            with self._lock:
                self._total_errors += 1
            raise
        except Exception as exc:
            with self._lock:
                self._total_errors += 1
            logger.error(
                "Unexpected error scoring vulnerability for entity=%s: %s",
                entity_id,
                exc,
                exc_info=True,
            )
            raise

    # ------------------------------------------------------------------
    # Public Method 2: score_sector_vulnerability
    # ------------------------------------------------------------------

    def score_sector_vulnerability(
        self,
        sector: str,
        location: str,
        hazard_type: str,
        exposure_score: float,
        scenario: Optional[str] = None,
        time_horizon: Optional[str] = None,
    ) -> Dict[str, Any]:
        """Score sector-level vulnerability using built-in defaults.

        Uses the built-in sector sensitivity factors (all defaulting to
        0.5) and the default adaptive capacity indicators (all 0.5) for
        the specified sector.  Applies the hazard-sector sensitivity
        multiplier when available.

        Args:
            sector: Economic sector (agriculture, real_estate,
                infrastructure, supply_chain, natural_assets, energy,
                financial, manufacturing).
            location: Location identifier for the assessment.
            hazard_type: Climate hazard type.
            exposure_score: Exposure score on 0-100 scale.
            scenario: Optional climate scenario. Defaults to config.
            time_horizon: Optional time horizon. Defaults to config.

        Returns:
            Dictionary with same structure as score_vulnerability, plus
            additional sector-specific metadata.

        Raises:
            ValueError: If sector, location, or hazard_type is empty.
            TypeError: If exposure_score is not numeric.
        """
        start_time = time.time()

        try:
            # Validate
            self._validate_sector(sector)
            if not location or not isinstance(location, str):
                raise ValueError(
                    f"location must be a non-empty string, got {location!r}"
                )
            self._validate_hazard_type(hazard_type)
            validated_exposure = self._validate_exposure_score(exposure_score)

            effective_scenario = scenario or self._get_default_scenario()
            effective_horizon = time_horizon or self._get_default_time_horizon()

            # Get sector-specific defaults or generic fallback
            sector_factors = SECTOR_SENSITIVITY_FACTORS.get(
                sector,
                {
                    "general_sensitivity_1": 0.5,
                    "general_sensitivity_2": 0.5,
                    "general_sensitivity_3": 0.5,
                    "general_sensitivity_4": 0.5,
                    "general_sensitivity_5": 0.5,
                },
            )
            adaptive_indicators = dict(DEFAULT_ADAPTIVE_CAPACITY_INDICATORS)

            # Compute component scores
            exposure_normalised = validated_exposure / 100.0
            raw_sensitivity = _safe_mean(list(sector_factors.values()))

            # Apply hazard-sector sensitivity multiplier
            adjusted_sensitivity = self._apply_hazard_sector_multiplier(
                raw_sensitivity, hazard_type, sector
            )
            adaptive_capacity_score = _safe_mean(list(adaptive_indicators.values()))

            # Compute vulnerability
            raw_vuln = self._compute_vulnerability(
                exposure_normalised=exposure_normalised,
                sensitivity=adjusted_sensitivity,
                adaptive_capacity=adaptive_capacity_score,
            )
            adjusted_vuln = self._apply_scenario_multiplier(
                raw_vuln, effective_scenario
            )
            final_vuln = self._apply_time_horizon_multiplier(
                adjusted_vuln, effective_horizon
            )
            final_vuln = round(final_vuln, 4)

            vuln_level = _classify_vulnerability(final_vuln)

            # Factor contributions
            contributions = self._compute_factor_contributions(
                exposure_normalised=exposure_normalised,
                sensitivity=adjusted_sensitivity,
                adaptive_capacity=adaptive_capacity_score,
                vulnerability_score=final_vuln,
                sensitivity_factors=sector_factors,
                adaptive_capacity_indicators=adaptive_indicators,
            )
            contributions["sector"] = sector
            contributions["location"] = location
            contributions["hazard_sector_multiplier"] = HAZARD_SECTOR_MULTIPLIERS.get(
                hazard_type, {}
            ).get(sector, 1.0)
            contributions["raw_sensitivity"] = round(raw_sensitivity, 6)
            contributions["adjusted_sensitivity"] = round(adjusted_sensitivity, 6)

            # Build result
            entity_id = f"sector:{sector}:{location}"
            score_id = _generate_id("VS")
            scored_at = _utcnow_iso()

            provenance_data = {
                "score_id": score_id,
                "entity_id": entity_id,
                "sector": sector,
                "location": location,
                "hazard_type": hazard_type,
                "exposure_score": validated_exposure,
                "sensitivity_score": round(adjusted_sensitivity, 6),
                "adaptive_capacity_score": round(adaptive_capacity_score, 6),
                "vulnerability_score": final_vuln,
                "scenario": effective_scenario,
                "time_horizon": effective_horizon,
                "scored_at": scored_at,
            }
            provenance_hash = self._record_provenance(
                entity_id=entity_id,
                action="score_sector",
                data=provenance_data,
            )

            score_obj = VulnerabilityScore(
                score_id=score_id,
                entity_id=entity_id,
                hazard_type=hazard_type,
                exposure_score=round(validated_exposure, 4),
                sensitivity_score=round(adjusted_sensitivity, 6),
                adaptive_capacity_score=round(adaptive_capacity_score, 6),
                vulnerability_score=final_vuln,
                vulnerability_level=vuln_level.value,
                scenario=effective_scenario,
                time_horizon=effective_horizon,
                factor_contributions=contributions,
                scored_at=scored_at,
                provenance_hash=provenance_hash,
            )

            # Store and index
            with self._lock:
                self._scores[score_id] = score_obj
                self._entity_score_index[entity_id].append(score_id)
                self._hazard_score_index[hazard_type].append(score_id)
                self._level_score_index[vuln_level.value].append(score_id)
                self._total_scored += 1

            # Metrics
            if self._is_metrics_enabled():
                try:
                    _record_vulnerability_metric(sector, hazard_type)
                except Exception:
                    pass

            elapsed = time.time() - start_time
            if self._is_metrics_enabled():
                try:
                    _observe_pipeline_duration("vulnerability_scoring", elapsed)
                except Exception:
                    pass

            logger.info(
                "Scored sector vulnerability: sector=%s location=%s "
                "hazard=%s exposure=%.2f sensitivity=%.4f "
                "adaptive=%.4f vulnerability=%.2f level=%s "
                "score_id=%s elapsed=%.3fs",
                sector,
                location,
                hazard_type,
                validated_exposure,
                adjusted_sensitivity,
                adaptive_capacity_score,
                final_vuln,
                vuln_level.value,
                score_id,
                elapsed,
            )

            return score_obj.to_dict()

        except (ValueError, TypeError):
            with self._lock:
                self._total_errors += 1
            raise
        except Exception as exc:
            with self._lock:
                self._total_errors += 1
            logger.error(
                "Unexpected error scoring sector vulnerability "
                "for sector=%s location=%s: %s",
                sector,
                location,
                exc,
                exc_info=True,
            )
            raise

    # ------------------------------------------------------------------
    # Public Method 3: create_sensitivity_profile
    # ------------------------------------------------------------------

    def create_sensitivity_profile(
        self,
        entity_id: str,
        sector: str,
        factors: Dict[str, float],
    ) -> Dict[str, Any]:
        """Create and store a sensitivity profile for an entity.

        A sensitivity profile captures sector-specific sensitivity
        factors for an entity, enabling consistent reuse across
        multiple vulnerability assessments.

        Args:
            entity_id: Unique identifier for the entity.
            sector: Economic sector for this profile.
            factors: Dictionary of sensitivity factor names to values
                (0.0 to 1.0 each).

        Returns:
            Dictionary containing:
                - profile_id: Unique profile identifier.
                - entity_id: Entity this profile belongs to.
                - sector: Economic sector.
                - factors: Validated factor values.
                - overall_sensitivity: Mean of all factor values.
                - created_at: ISO 8601 UTC timestamp.
                - updated_at: ISO 8601 UTC timestamp.
                - provenance_hash: SHA-256 audit trail hash.

        Raises:
            ValueError: If entity_id, sector, or factors is invalid.
            TypeError: If factors is not a dict.
        """
        self._validate_entity_id(entity_id)
        self._validate_sector(sector)
        validated_factors = self._validate_factor_values(factors, "sensitivity_factors")

        overall = _safe_mean(list(validated_factors.values()))
        profile_id = _generate_id("SP")
        now_iso = _utcnow_iso()

        provenance_data = {
            "profile_id": profile_id,
            "entity_id": entity_id,
            "sector": sector,
            "factors": validated_factors,
            "overall_sensitivity": round(overall, 6),
            "created_at": now_iso,
        }
        provenance_hash = self._record_provenance(
            entity_id=entity_id,
            action="create_sensitivity",
            data=provenance_data,
        )

        profile = SensitivityProfile(
            profile_id=profile_id,
            entity_id=entity_id,
            sector=sector,
            factors=validated_factors,
            overall_sensitivity=round(overall, 6),
            created_at=now_iso,
            updated_at=now_iso,
            provenance_hash=provenance_hash,
        )

        with self._lock:
            self._sensitivity_profiles[profile_id] = profile
            self._entity_sensitivity_index[entity_id].append(profile_id)
            self._total_profiles_created += 1

        logger.info(
            "Created sensitivity profile: entity=%s sector=%s "
            "factors=%d overall=%.4f profile_id=%s",
            entity_id,
            sector,
            len(validated_factors),
            overall,
            profile_id,
        )

        return profile.to_dict()

    # ------------------------------------------------------------------
    # Public Method 4: get_sensitivity_profile
    # ------------------------------------------------------------------

    def get_sensitivity_profile(
        self,
        profile_id: str,
    ) -> Optional[Dict[str, Any]]:
        """Retrieve a stored sensitivity profile by ID.

        Args:
            profile_id: Unique profile identifier.

        Returns:
            Dictionary representation of the sensitivity profile, or
            None if no profile exists with the given ID.
        """
        if not profile_id:
            return None

        with self._lock:
            profile = self._sensitivity_profiles.get(profile_id)

        if profile is None:
            logger.debug("Sensitivity profile not found: %s", profile_id)
            return None

        return profile.to_dict()

    # ------------------------------------------------------------------
    # Public Method 5: create_adaptive_capacity_profile
    # ------------------------------------------------------------------

    def create_adaptive_capacity_profile(
        self,
        entity_id: str,
        indicators: Dict[str, float],
    ) -> Dict[str, Any]:
        """Create and store an adaptive capacity profile for an entity.

        An adaptive capacity profile captures entity-level indicators
        for use across multiple vulnerability assessments.

        Args:
            entity_id: Unique identifier for the entity.
            indicators: Dictionary of adaptive capacity indicator names
                to values (0.0 to 1.0 each).

        Returns:
            Dictionary containing:
                - profile_id: Unique profile identifier.
                - entity_id: Entity this profile belongs to.
                - indicators: Validated indicator values.
                - overall_capacity: Mean of all indicator values.
                - created_at: ISO 8601 UTC timestamp.
                - updated_at: ISO 8601 UTC timestamp.
                - provenance_hash: SHA-256 audit trail hash.

        Raises:
            ValueError: If entity_id or indicators is invalid.
            TypeError: If indicators is not a dict.
        """
        self._validate_entity_id(entity_id)
        validated_indicators = self._validate_factor_values(
            indicators, "adaptive_capacity_indicators"
        )

        overall = _safe_mean(list(validated_indicators.values()))
        profile_id = _generate_id("ACP")
        now_iso = _utcnow_iso()

        provenance_data = {
            "profile_id": profile_id,
            "entity_id": entity_id,
            "indicators": validated_indicators,
            "overall_capacity": round(overall, 6),
            "created_at": now_iso,
        }
        provenance_hash = self._record_provenance(
            entity_id=entity_id,
            action="create_adaptive",
            data=provenance_data,
        )

        profile = AdaptiveCapacityProfile(
            profile_id=profile_id,
            entity_id=entity_id,
            indicators=validated_indicators,
            overall_capacity=round(overall, 6),
            created_at=now_iso,
            updated_at=now_iso,
            provenance_hash=provenance_hash,
        )

        with self._lock:
            self._adaptive_profiles[profile_id] = profile
            self._entity_adaptive_index[entity_id].append(profile_id)
            self._total_profiles_created += 1

        logger.info(
            "Created adaptive capacity profile: entity=%s "
            "indicators=%d overall=%.4f profile_id=%s",
            entity_id,
            len(validated_indicators),
            overall,
            profile_id,
        )

        return profile.to_dict()

    # ------------------------------------------------------------------
    # Public Method 6: get_adaptive_capacity_profile
    # ------------------------------------------------------------------

    def get_adaptive_capacity_profile(
        self,
        profile_id: str,
    ) -> Optional[Dict[str, Any]]:
        """Retrieve a stored adaptive capacity profile by ID.

        Args:
            profile_id: Unique profile identifier.

        Returns:
            Dictionary representation of the adaptive capacity profile,
            or None if no profile exists with the given ID.
        """
        if not profile_id:
            return None

        with self._lock:
            profile = self._adaptive_profiles.get(profile_id)

        if profile is None:
            logger.debug("Adaptive capacity profile not found: %s", profile_id)
            return None

        return profile.to_dict()

    # ------------------------------------------------------------------
    # Public Method 7: calculate_residual_risk
    # ------------------------------------------------------------------

    def calculate_residual_risk(
        self,
        vulnerability_score: float,
        adaptation_measures: List[Dict[str, Any]],
        entity_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """Calculate residual risk after applying adaptation measures.

        Each adaptation measure reduces the vulnerability score by its
        effectiveness factor. Measures are applied sequentially in the
        order provided. The residual score is clamped to [0, 100].

        Residual score formula (sequential application):
            remaining = original_score
            for each measure:
                remaining = remaining * (1 - effectiveness)
            residual = remaining

        Args:
            vulnerability_score: Original vulnerability score (0-100).
            adaptation_measures: List of dictionaries, each with:
                - measure_name (str): Name of the adaptation measure.
                - effectiveness (float): Effectiveness factor (0.0 to 1.0),
                  where 1.0 means 100% risk reduction.
                - cost_usd (float, optional): Cost of the measure in USD.
            entity_id: Optional entity identifier for provenance tracking.

        Returns:
            Dictionary containing:
                - result_id: Unique result identifier.
                - entity_id: Entity assessed (or 'anonymous').
                - original_score: Original vulnerability score.
                - residual_score: Post-adaptation vulnerability score.
                - risk_reduction_pct: Percentage reduction.
                - measures_applied: Detailed list of applied measures.
                - effectiveness_level: Overall effectiveness classification.
                - calculated_at: ISO 8601 UTC timestamp.
                - provenance_hash: SHA-256 audit trail hash.

        Raises:
            TypeError: If vulnerability_score is not numeric.
            ValueError: If adaptation_measures is empty.
        """
        start_time = time.time()

        try:
            # Validate inputs
            if not isinstance(vulnerability_score, (int, float)):
                raise TypeError(
                    f"vulnerability_score must be numeric, "
                    f"got {type(vulnerability_score).__name__}"
                )
            original = _clamp(float(vulnerability_score), 0.0, 100.0)

            if not isinstance(adaptation_measures, list):
                raise TypeError(
                    f"adaptation_measures must be a list, "
                    f"got {type(adaptation_measures).__name__}"
                )
            if not adaptation_measures:
                raise ValueError("adaptation_measures must not be empty")

            effective_entity = entity_id or "anonymous"

            # Apply measures sequentially
            remaining = original
            applied_measures: List[Dict[str, Any]] = []

            for idx, measure in enumerate(adaptation_measures):
                if not isinstance(measure, dict):
                    logger.warning(
                        "Skipping non-dict measure at index %d: %s",
                        idx,
                        type(measure).__name__,
                    )
                    continue

                measure_name = str(measure.get("measure_name", f"measure_{idx}"))
                raw_effectiveness = measure.get("effectiveness", 0.0)

                if not isinstance(raw_effectiveness, (int, float)):
                    logger.warning(
                        "Measure '%s' effectiveness is not numeric; "
                        "defaulting to 0.0",
                        measure_name,
                    )
                    raw_effectiveness = 0.0

                effectiveness = _clamp(float(raw_effectiveness), 0.0, 1.0)
                cost_usd = measure.get("cost_usd", 0.0)

                if not isinstance(cost_usd, (int, float)):
                    cost_usd = 0.0
                cost_usd = max(0.0, float(cost_usd))

                score_before = remaining
                remaining = remaining * (1.0 - effectiveness)
                score_after = remaining

                applied_measures.append(
                    {
                        "measure_name": measure_name,
                        "effectiveness": round(effectiveness, 6),
                        "cost_usd": round(cost_usd, 2),
                        "score_before": round(score_before, 4),
                        "score_after": round(score_after, 4),
                        "reduction": round(score_before - score_after, 4),
                    }
                )

            residual = _clamp(remaining, 0.0, 100.0)
            residual = round(residual, 4)

            # Compute reduction percentage
            if original > 0.0:
                reduction_pct = round(
                    ((original - residual) / original) * 100.0, 4
                )
            else:
                reduction_pct = 0.0

            effectiveness_level = _classify_effectiveness(reduction_pct)

            result_id = _generate_id("RR")
            calculated_at = _utcnow_iso()

            provenance_data = {
                "result_id": result_id,
                "entity_id": effective_entity,
                "original_score": original,
                "residual_score": residual,
                "risk_reduction_pct": reduction_pct,
                "measures_count": len(applied_measures),
                "calculated_at": calculated_at,
            }
            provenance_hash = self._record_provenance(
                entity_id=effective_entity,
                action="calculate_residual",
                data=provenance_data,
            )

            result_obj = ResidualRiskResult(
                result_id=result_id,
                entity_id=effective_entity,
                original_score=round(original, 4),
                residual_score=residual,
                risk_reduction_pct=reduction_pct,
                measures_applied=applied_measures,
                effectiveness_level=effectiveness_level.value,
                calculated_at=calculated_at,
                provenance_hash=provenance_hash,
            )

            with self._lock:
                self._residual_results[result_id] = result_obj
                self._total_residual_calcs += 1

            elapsed = time.time() - start_time
            logger.info(
                "Calculated residual risk: entity=%s original=%.2f "
                "residual=%.2f reduction=%.2f%% measures=%d "
                "effectiveness=%s result_id=%s elapsed=%.3fs",
                effective_entity,
                original,
                residual,
                reduction_pct,
                len(applied_measures),
                effectiveness_level.value,
                result_id,
                elapsed,
            )

            return result_obj.to_dict()

        except (ValueError, TypeError):
            with self._lock:
                self._total_errors += 1
            raise
        except Exception as exc:
            with self._lock:
                self._total_errors += 1
            logger.error(
                "Unexpected error calculating residual risk: %s",
                exc,
                exc_info=True,
            )
            raise

    # ------------------------------------------------------------------
    # Public Method 8: rank_entities
    # ------------------------------------------------------------------

    def rank_entities(
        self,
        entity_scores: List[Dict[str, Any]],
    ) -> List[Dict[str, Any]]:
        """Rank entities by vulnerability score (most vulnerable first).

        Sorts the provided entity scores in descending order by
        vulnerability_score and assigns 1-based rank positions and
        percentile values.

        Args:
            entity_scores: List of dictionaries, each containing at
                minimum:
                - entity_id (str): Entity identifier.
                - vulnerability_score (float): Vulnerability score (0-100).

        Returns:
            Sorted list of EntityRanking dictionaries containing:
                - rank: 1-based position (1 = most vulnerable).
                - entity_id: Entity identifier.
                - vulnerability_score: Score used for ranking.
                - vulnerability_level: Categorical level.
                - percentile: Percentile position (0-100).

        Raises:
            TypeError: If entity_scores is not a list.
            ValueError: If entity_scores is empty.
        """
        start_time = time.time()

        try:
            if not isinstance(entity_scores, list):
                raise TypeError(
                    f"entity_scores must be a list, "
                    f"got {type(entity_scores).__name__}"
                )
            if not entity_scores:
                raise ValueError("entity_scores must not be empty")

            # Extract and validate entries
            valid_entries: List[Tuple[str, float]] = []
            for idx, entry in enumerate(entity_scores):
                if not isinstance(entry, dict):
                    logger.warning(
                        "Skipping non-dict entity score at index %d", idx
                    )
                    continue

                eid = str(entry.get("entity_id", f"unknown_{idx}"))
                raw_score = entry.get("vulnerability_score", 0.0)

                if not isinstance(raw_score, (int, float)):
                    logger.warning(
                        "Entity '%s' has non-numeric vulnerability_score; "
                        "defaulting to 0.0",
                        eid,
                    )
                    raw_score = 0.0

                valid_entries.append((eid, float(raw_score)))

            if not valid_entries:
                raise ValueError(
                    "No valid entity scores found in the provided list"
                )

            # Sort descending by score (most vulnerable first)
            sorted_entries = sorted(
                valid_entries, key=lambda x: x[1], reverse=True
            )

            total = len(sorted_entries)
            rankings: List[Dict[str, Any]] = []

            for rank_idx, (eid, score) in enumerate(sorted_entries):
                rank = rank_idx + 1
                # Percentile: position from top as percentage
                # rank 1 of 10 = 100th percentile (most vulnerable)
                if total > 1:
                    percentile = round(
                        ((total - rank_idx) / total) * 100.0, 2
                    )
                else:
                    percentile = 100.0

                vuln_level = _classify_vulnerability(score)

                ranking = EntityRanking(
                    rank=rank,
                    entity_id=eid,
                    vulnerability_score=round(score, 4),
                    vulnerability_level=vuln_level.value,
                    percentile=percentile,
                )
                rankings.append(ranking.to_dict())

            # Record provenance for ranking operation
            provenance_data = {
                "operation": "rank_entities",
                "total_entities": total,
                "top_entity": sorted_entries[0][0] if sorted_entries else "",
                "top_score": round(sorted_entries[0][1], 4) if sorted_entries else 0.0,
                "bottom_entity": sorted_entries[-1][0] if sorted_entries else "",
                "bottom_score": round(sorted_entries[-1][1], 4) if sorted_entries else 0.0,
            }
            self._record_provenance(
                entity_id="rank_entities",
                action="rank_entities",
                data=provenance_data,
            )

            with self._lock:
                self._total_rankings += 1

            elapsed = time.time() - start_time
            logger.info(
                "Ranked %d entities by vulnerability: "
                "top=%s (%.2f) bottom=%s (%.2f) elapsed=%.3fs",
                total,
                sorted_entries[0][0] if sorted_entries else "none",
                sorted_entries[0][1] if sorted_entries else 0.0,
                sorted_entries[-1][0] if sorted_entries else "none",
                sorted_entries[-1][1] if sorted_entries else 0.0,
                elapsed,
            )

            return rankings

        except (ValueError, TypeError):
            with self._lock:
                self._total_errors += 1
            raise
        except Exception as exc:
            with self._lock:
                self._total_errors += 1
            logger.error(
                "Unexpected error ranking entities: %s",
                exc,
                exc_info=True,
            )
            raise

    # ------------------------------------------------------------------
    # Public Method 9: get_vulnerability_score
    # ------------------------------------------------------------------

    def get_vulnerability_score(
        self,
        score_id: str,
    ) -> Optional[Dict[str, Any]]:
        """Retrieve a stored vulnerability score by ID.

        Args:
            score_id: Unique vulnerability score identifier.

        Returns:
            Dictionary representation of the vulnerability score, or
            None if no score exists with the given ID.
        """
        if not score_id:
            return None

        with self._lock:
            score = self._scores.get(score_id)

        if score is None:
            logger.debug("Vulnerability score not found: %s", score_id)
            return None

        return score.to_dict()

    # ------------------------------------------------------------------
    # Public Method 10: list_vulnerability_scores
    # ------------------------------------------------------------------

    def list_vulnerability_scores(
        self,
        entity_id: Optional[str] = None,
        hazard_type: Optional[str] = None,
        vulnerability_level: Optional[str] = None,
        limit: int = 100,
    ) -> List[Dict[str, Any]]:
        """List stored vulnerability scores with optional filters.

        Supports filtering by entity_id, hazard_type, and/or
        vulnerability_level. When multiple filters are provided, they
        are combined with AND logic. Results are ordered by scored_at
        (most recent first) and truncated to the specified limit.

        Args:
            entity_id: Optional entity identifier to filter by.
            hazard_type: Optional hazard type to filter by.
            vulnerability_level: Optional vulnerability level to filter
                by (negligible, low, moderate, high, critical).
            limit: Maximum number of results to return (default 100).

        Returns:
            List of vulnerability score dictionaries matching the
            filters, ordered by scored_at descending.
        """
        with self._lock:
            # Start with all scores or use index for single filter
            if entity_id and not hazard_type and not vulnerability_level:
                score_ids = self._entity_score_index.get(entity_id, [])
                candidates = [
                    self._scores[sid]
                    for sid in score_ids
                    if sid in self._scores
                ]
            elif hazard_type and not entity_id and not vulnerability_level:
                score_ids = self._hazard_score_index.get(hazard_type, [])
                candidates = [
                    self._scores[sid]
                    for sid in score_ids
                    if sid in self._scores
                ]
            elif vulnerability_level and not entity_id and not hazard_type:
                score_ids = self._level_score_index.get(vulnerability_level, [])
                candidates = [
                    self._scores[sid]
                    for sid in score_ids
                    if sid in self._scores
                ]
            else:
                candidates = list(self._scores.values())

        # Apply combined filters
        results: List[VulnerabilityScore] = []
        for score in candidates:
            if entity_id and score.entity_id != entity_id:
                continue
            if hazard_type and score.hazard_type != hazard_type:
                continue
            if vulnerability_level and score.vulnerability_level != vulnerability_level:
                continue
            results.append(score)

        # Sort by scored_at descending (most recent first)
        results.sort(key=lambda s: s.scored_at, reverse=True)

        # Apply limit
        if limit > 0:
            results = results[:limit]

        return [s.to_dict() for s in results]

    # ------------------------------------------------------------------
    # Public Method 11: get_statistics
    # ------------------------------------------------------------------

    def get_statistics(self) -> Dict[str, Any]:
        """Return engine statistics and operational summary.

        Returns:
            Dictionary containing:
                - total_scores: Total vulnerability scores computed.
                - total_profiles: Total profiles created.
                - total_residual_calcs: Total residual risk calculations.
                - total_rankings: Total ranking operations.
                - total_errors: Total errors encountered.
                - stored_scores: Number of scores in memory.
                - stored_sensitivity_profiles: Number of sensitivity profiles.
                - stored_adaptive_profiles: Number of adaptive profiles.
                - stored_residual_results: Number of residual results.
                - unique_entities_scored: Number of unique entities.
                - unique_hazard_types_scored: Number of unique hazard types.
                - vulnerability_level_distribution: Count by level.
                - config_weights: Current weight configuration.
                - provenance_entries: Total provenance entries.
        """
        with self._lock:
            total_scores = self._total_scored
            total_profiles = self._total_profiles_created
            total_residual = self._total_residual_calcs
            total_rankings = self._total_rankings
            total_errors = self._total_errors
            stored_scores = len(self._scores)
            stored_sensitivity = len(self._sensitivity_profiles)
            stored_adaptive = len(self._adaptive_profiles)
            stored_residual = len(self._residual_results)
            unique_entities = len(self._entity_score_index)
            unique_hazards = len(self._hazard_score_index)

            # Level distribution
            level_dist: Dict[str, int] = {}
            for level_name, score_ids in self._level_score_index.items():
                level_dist[level_name] = len(score_ids)

        # Ensure all levels are represented
        for level in VulnerabilityLevel:
            if level.value not in level_dist:
                level_dist[level.value] = 0

        stats: Dict[str, Any] = {
            "total_scores": total_scores,
            "total_profiles": total_profiles,
            "total_residual_calcs": total_residual,
            "total_rankings": total_rankings,
            "total_errors": total_errors,
            "stored_scores": stored_scores,
            "stored_sensitivity_profiles": stored_sensitivity,
            "stored_adaptive_profiles": stored_adaptive,
            "stored_residual_results": stored_residual,
            "unique_entities_scored": unique_entities,
            "unique_hazard_types_scored": unique_hazards,
            "vulnerability_level_distribution": level_dist,
            "config_weights": {
                "exposure": self._get_weight_exposure(),
                "sensitivity": self._get_weight_sensitivity(),
                "adaptive_capacity": self._get_weight_adaptive(),
            },
            "provenance_entries": self._provenance.entry_count,
        }

        logger.debug(
            "Engine statistics: total_scores=%d stored=%d "
            "profiles=%d residual=%d errors=%d",
            total_scores,
            stored_scores,
            stored_sensitivity + stored_adaptive,
            stored_residual,
            total_errors,
        )

        return stats

    # ------------------------------------------------------------------
    # Public Method 12: clear
    # ------------------------------------------------------------------

    def clear(self) -> None:
        """Reset all engine state to initial empty condition.

        Clears all stored scores, profiles, residual results, indexes,
        and counters. Also resets the provenance tracker. Primarily
        intended for testing and memory management.
        """
        with self._lock:
            self._scores.clear()
            self._sensitivity_profiles.clear()
            self._adaptive_profiles.clear()
            self._residual_results.clear()
            self._entity_score_index.clear()
            self._hazard_score_index.clear()
            self._level_score_index.clear()
            self._entity_sensitivity_index.clear()
            self._entity_adaptive_index.clear()
            self._total_scored = 0
            self._total_profiles_created = 0
            self._total_residual_calcs = 0
            self._total_rankings = 0
            self._total_errors = 0

        try:
            self._provenance.reset()
        except Exception as exc:
            logger.warning("Failed to reset provenance tracker: %s", exc)

        logger.info("VulnerabilityScorerEngine cleared: all state reset")

    # ------------------------------------------------------------------
    # Additional public helpers
    # ------------------------------------------------------------------

    def get_sector_sensitivity_defaults(
        self,
        sector: str,
    ) -> Dict[str, float]:
        """Return the default sensitivity factors for a given sector.

        Args:
            sector: Economic sector name.

        Returns:
            Dictionary of factor_name -> default_value (0.5) for the
            sector. Returns an empty dictionary if the sector is not
            recognized.
        """
        return dict(SECTOR_SENSITIVITY_FACTORS.get(sector, {}))

    def get_adaptive_capacity_defaults(self) -> Dict[str, float]:
        """Return the default adaptive capacity indicators.

        Returns:
            Dictionary of indicator_name -> default_value (0.5).
        """
        return dict(DEFAULT_ADAPTIVE_CAPACITY_INDICATORS)

    def get_supported_sectors(self) -> List[str]:
        """Return list of supported sector names.

        Returns:
            Sorted list of sector strings with built-in defaults.
        """
        return sorted(SECTOR_SENSITIVITY_FACTORS.keys())

    def get_supported_hazard_types(self) -> List[str]:
        """Return list of supported climate hazard types.

        Returns:
            Sorted list of hazard type strings.
        """
        return sorted(VALID_HAZARD_TYPES)

    def get_vulnerability_levels(self) -> List[Dict[str, Any]]:
        """Return the vulnerability level classification scheme.

        Returns:
            List of dictionaries describing each level with name,
            lower bound, and upper bound.
        """
        return [
            {
                "level": VulnerabilityLevel.NEGLIGIBLE.value,
                "lower_bound": 0.0,
                "upper_bound": 20.0,
                "description": "Minimal vulnerability; no immediate action required.",
            },
            {
                "level": VulnerabilityLevel.LOW.value,
                "lower_bound": 20.0,
                "upper_bound": 40.0,
                "description": "Low vulnerability; monitor and include in long-term planning.",
            },
            {
                "level": VulnerabilityLevel.MODERATE.value,
                "lower_bound": 40.0,
                "upper_bound": 60.0,
                "description": "Moderate vulnerability; adaptation measures recommended.",
            },
            {
                "level": VulnerabilityLevel.HIGH.value,
                "lower_bound": 60.0,
                "upper_bound": 80.0,
                "description": "High vulnerability; prioritize adaptation investments.",
            },
            {
                "level": VulnerabilityLevel.CRITICAL.value,
                "lower_bound": 80.0,
                "upper_bound": 100.0,
                "description": "Critical vulnerability; immediate action required.",
            },
        ]

    def get_scenario_multipliers(self) -> Dict[str, float]:
        """Return the scenario severity multiplier table.

        Returns:
            Dictionary mapping scenario names to multiplier values.
        """
        return dict(SCENARIO_MULTIPLIERS)

    def get_time_horizon_multipliers(self) -> Dict[str, float]:
        """Return the time horizon multiplier table.

        Returns:
            Dictionary mapping time horizon names to multiplier values.
        """
        return dict(TIME_HORIZON_MULTIPLIERS)

    def get_hazard_sector_multipliers(self) -> Dict[str, Dict[str, float]]:
        """Return the hazard-sector sensitivity multiplier table.

        Returns:
            Nested dictionary of hazard_type -> sector -> multiplier.
        """
        return {
            ht: dict(sectors)
            for ht, sectors in HAZARD_SECTOR_MULTIPLIERS.items()
        }

    def list_sensitivity_profiles(
        self,
        entity_id: Optional[str] = None,
        limit: int = 100,
    ) -> List[Dict[str, Any]]:
        """List stored sensitivity profiles with optional entity filter.

        Args:
            entity_id: Optional entity identifier to filter by.
            limit: Maximum number of results (default 100).

        Returns:
            List of sensitivity profile dictionaries.
        """
        with self._lock:
            if entity_id:
                profile_ids = self._entity_sensitivity_index.get(entity_id, [])
                profiles = [
                    self._sensitivity_profiles[pid]
                    for pid in profile_ids
                    if pid in self._sensitivity_profiles
                ]
            else:
                profiles = list(self._sensitivity_profiles.values())

        # Sort by created_at descending
        profiles.sort(key=lambda p: p.created_at, reverse=True)

        if limit > 0:
            profiles = profiles[:limit]

        return [p.to_dict() for p in profiles]

    def list_adaptive_capacity_profiles(
        self,
        entity_id: Optional[str] = None,
        limit: int = 100,
    ) -> List[Dict[str, Any]]:
        """List stored adaptive capacity profiles with optional entity filter.

        Args:
            entity_id: Optional entity identifier to filter by.
            limit: Maximum number of results (default 100).

        Returns:
            List of adaptive capacity profile dictionaries.
        """
        with self._lock:
            if entity_id:
                profile_ids = self._entity_adaptive_index.get(entity_id, [])
                profiles = [
                    self._adaptive_profiles[pid]
                    for pid in profile_ids
                    if pid in self._adaptive_profiles
                ]
            else:
                profiles = list(self._adaptive_profiles.values())

        # Sort by created_at descending
        profiles.sort(key=lambda p: p.created_at, reverse=True)

        if limit > 0:
            profiles = profiles[:limit]

        return [p.to_dict() for p in profiles]

    def list_residual_risk_results(
        self,
        entity_id: Optional[str] = None,
        limit: int = 100,
    ) -> List[Dict[str, Any]]:
        """List stored residual risk results with optional entity filter.

        Args:
            entity_id: Optional entity identifier to filter by.
            limit: Maximum number of results (default 100).

        Returns:
            List of residual risk result dictionaries.
        """
        with self._lock:
            results = list(self._residual_results.values())

        if entity_id:
            results = [r for r in results if r.entity_id == entity_id]

        results.sort(key=lambda r: r.calculated_at, reverse=True)

        if limit > 0:
            results = results[:limit]

        return [r.to_dict() for r in results]

    def get_residual_risk_result(
        self,
        result_id: str,
    ) -> Optional[Dict[str, Any]]:
        """Retrieve a stored residual risk result by ID.

        Args:
            result_id: Unique result identifier.

        Returns:
            Dictionary representation of the residual risk result, or
            None if no result exists with the given ID.
        """
        if not result_id:
            return None

        with self._lock:
            result = self._residual_results.get(result_id)

        if result is None:
            logger.debug("Residual risk result not found: %s", result_id)
            return None

        return result.to_dict()

    def score_vulnerability_with_profiles(
        self,
        entity_id: str,
        hazard_type: str,
        exposure_score: float,
        sensitivity_profile_id: str,
        adaptive_profile_id: str,
        scenario: Optional[str] = None,
        time_horizon: Optional[str] = None,
    ) -> Dict[str, Any]:
        """Score vulnerability using stored profiles.

        Convenience method that looks up stored sensitivity and adaptive
        capacity profiles and uses them for vulnerability scoring.

        Args:
            entity_id: Entity identifier.
            hazard_type: Climate hazard type.
            exposure_score: Exposure score (0-100).
            sensitivity_profile_id: ID of a stored sensitivity profile.
            adaptive_profile_id: ID of a stored adaptive capacity profile.
            scenario: Optional climate scenario.
            time_horizon: Optional time horizon.

        Returns:
            Vulnerability score dictionary (same as score_vulnerability).

        Raises:
            ValueError: If either profile is not found.
        """
        sens_profile = self.get_sensitivity_profile(sensitivity_profile_id)
        if sens_profile is None:
            raise ValueError(
                f"Sensitivity profile not found: {sensitivity_profile_id}"
            )

        adapt_profile = self.get_adaptive_capacity_profile(adaptive_profile_id)
        if adapt_profile is None:
            raise ValueError(
                f"Adaptive capacity profile not found: {adaptive_profile_id}"
            )

        return self.score_vulnerability(
            entity_id=entity_id,
            hazard_type=hazard_type,
            exposure_score=exposure_score,
            sensitivity_factors=sens_profile["factors"],
            adaptive_capacity_indicators=adapt_profile["indicators"],
            scenario=scenario,
            time_horizon=time_horizon,
        )

    def batch_score_vulnerabilities(
        self,
        assessments: List[Dict[str, Any]],
    ) -> List[Dict[str, Any]]:
        """Score multiple entities in a single batch operation.

        Each assessment dictionary must contain the same keys as
        the score_vulnerability arguments:
            - entity_id (str)
            - hazard_type (str)
            - exposure_score (float)
            - sensitivity_factors (dict)
            - adaptive_capacity_indicators (dict)
            - scenario (str, optional)
            - time_horizon (str, optional)

        Failed assessments are included in the results with an
        error field instead of raising.

        Args:
            assessments: List of assessment parameter dictionaries.

        Returns:
            List of result dictionaries (one per input assessment).
            Successful results contain the vulnerability score;
            failed results contain an ``error`` field.
        """
        start_time = time.time()
        results: List[Dict[str, Any]] = []

        for idx, assessment in enumerate(assessments):
            if not isinstance(assessment, dict):
                results.append(
                    {
                        "index": idx,
                        "error": f"Assessment must be a dict, got {type(assessment).__name__}",
                    }
                )
                continue

            try:
                result = self.score_vulnerability(
                    entity_id=assessment.get("entity_id", f"batch_{idx}"),
                    hazard_type=assessment.get("hazard_type", "compound"),
                    exposure_score=assessment.get("exposure_score", 50.0),
                    sensitivity_factors=assessment.get("sensitivity_factors", {}),
                    adaptive_capacity_indicators=assessment.get(
                        "adaptive_capacity_indicators", {}
                    ),
                    scenario=assessment.get("scenario"),
                    time_horizon=assessment.get("time_horizon"),
                )
                result["index"] = idx
                results.append(result)
            except Exception as exc:
                results.append(
                    {
                        "index": idx,
                        "entity_id": assessment.get("entity_id", f"batch_{idx}"),
                        "error": str(exc),
                    }
                )

        elapsed = time.time() - start_time
        successful = sum(1 for r in results if "error" not in r)
        logger.info(
            "Batch scored %d/%d vulnerabilities in %.3fs",
            successful,
            len(assessments),
            elapsed,
        )

        return results

    def compare_scenarios(
        self,
        entity_id: str,
        hazard_type: str,
        exposure_score: float,
        sensitivity_factors: Dict[str, float],
        adaptive_capacity_indicators: Dict[str, float],
        scenarios: Optional[List[str]] = None,
        time_horizon: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """Compare vulnerability across multiple climate scenarios.

        Scores the same entity under each specified scenario to enable
        side-by-side comparison of vulnerability under different climate
        pathways.

        Args:
            entity_id: Entity identifier.
            hazard_type: Climate hazard type.
            exposure_score: Exposure score (0-100).
            sensitivity_factors: Sensitivity factor dictionary.
            adaptive_capacity_indicators: Adaptive capacity dictionary.
            scenarios: List of scenario strings to compare. Defaults to
                all SSP scenarios.
            time_horizon: Optional time horizon (applies to all).

        Returns:
            List of vulnerability score dictionaries, one per scenario,
            sorted by vulnerability_score descending.
        """
        if scenarios is None:
            scenarios = [
                "SSP1-1.9",
                "SSP1-2.6",
                "SSP2-4.5",
                "SSP3-7.0",
                "SSP5-8.5",
            ]

        results: List[Dict[str, Any]] = []
        for scen in scenarios:
            try:
                result = self.score_vulnerability(
                    entity_id=entity_id,
                    hazard_type=hazard_type,
                    exposure_score=exposure_score,
                    sensitivity_factors=sensitivity_factors,
                    adaptive_capacity_indicators=adaptive_capacity_indicators,
                    scenario=scen,
                    time_horizon=time_horizon,
                )
                results.append(result)
            except Exception as exc:
                results.append(
                    {
                        "scenario": scen,
                        "entity_id": entity_id,
                        "error": str(exc),
                    }
                )

        # Sort by vulnerability_score descending
        results.sort(
            key=lambda r: r.get("vulnerability_score", 0.0),
            reverse=True,
        )

        return results

    def compare_time_horizons(
        self,
        entity_id: str,
        hazard_type: str,
        exposure_score: float,
        sensitivity_factors: Dict[str, float],
        adaptive_capacity_indicators: Dict[str, float],
        scenario: Optional[str] = None,
        time_horizons: Optional[List[str]] = None,
    ) -> List[Dict[str, Any]]:
        """Compare vulnerability across multiple time horizons.

        Scores the same entity under each specified time horizon.

        Args:
            entity_id: Entity identifier.
            hazard_type: Climate hazard type.
            exposure_score: Exposure score (0-100).
            sensitivity_factors: Sensitivity factor dictionary.
            adaptive_capacity_indicators: Adaptive capacity dictionary.
            scenario: Optional climate scenario (applies to all).
            time_horizons: List of time horizon strings. Defaults to
                all three horizons.

        Returns:
            List of vulnerability score dictionaries, one per horizon,
            sorted by vulnerability_score descending.
        """
        if time_horizons is None:
            time_horizons = ["SHORT_TERM", "MID_TERM", "LONG_TERM"]

        results: List[Dict[str, Any]] = []
        for horizon in time_horizons:
            try:
                result = self.score_vulnerability(
                    entity_id=entity_id,
                    hazard_type=hazard_type,
                    exposure_score=exposure_score,
                    sensitivity_factors=sensitivity_factors,
                    adaptive_capacity_indicators=adaptive_capacity_indicators,
                    scenario=scenario,
                    time_horizon=horizon,
                )
                results.append(result)
            except Exception as exc:
                results.append(
                    {
                        "time_horizon": horizon,
                        "entity_id": entity_id,
                        "error": str(exc),
                    }
                )

        # Sort by vulnerability_score descending
        results.sort(
            key=lambda r: r.get("vulnerability_score", 0.0),
            reverse=True,
        )

        return results

    def get_entity_vulnerability_summary(
        self,
        entity_id: str,
    ) -> Dict[str, Any]:
        """Get a vulnerability summary for a specific entity.

        Aggregates all stored vulnerability scores for the entity and
        computes summary statistics.

        Args:
            entity_id: Entity identifier.

        Returns:
            Dictionary containing:
                - entity_id: Entity identifier.
                - total_assessments: Number of stored scores.
                - hazard_types_assessed: List of assessed hazard types.
                - average_vulnerability: Mean vulnerability score.
                - max_vulnerability: Maximum vulnerability score.
                - min_vulnerability: Minimum vulnerability score.
                - overall_level: Vulnerability level of the average.
                - assessments: List of individual score summaries.
        """
        scores = self.list_vulnerability_scores(entity_id=entity_id, limit=10000)

        if not scores:
            return {
                "entity_id": entity_id,
                "total_assessments": 0,
                "hazard_types_assessed": [],
                "average_vulnerability": 0.0,
                "max_vulnerability": 0.0,
                "min_vulnerability": 0.0,
                "overall_level": VulnerabilityLevel.NEGLIGIBLE.value,
                "assessments": [],
            }

        vuln_scores = [s["vulnerability_score"] for s in scores]
        hazard_types = list(set(s["hazard_type"] for s in scores))
        avg_vuln = _safe_mean(vuln_scores)

        return {
            "entity_id": entity_id,
            "total_assessments": len(scores),
            "hazard_types_assessed": sorted(hazard_types),
            "average_vulnerability": round(avg_vuln, 4),
            "max_vulnerability": round(max(vuln_scores), 4),
            "min_vulnerability": round(min(vuln_scores), 4),
            "overall_level": _classify_vulnerability(avg_vuln).value,
            "assessments": [
                {
                    "score_id": s["score_id"],
                    "hazard_type": s["hazard_type"],
                    "vulnerability_score": s["vulnerability_score"],
                    "vulnerability_level": s["vulnerability_level"],
                    "scenario": s["scenario"],
                    "time_horizon": s["time_horizon"],
                    "scored_at": s["scored_at"],
                }
                for s in scores
            ],
        }

    def get_hazard_vulnerability_summary(
        self,
        hazard_type: str,
    ) -> Dict[str, Any]:
        """Get a vulnerability summary for a specific hazard type.

        Aggregates all stored vulnerability scores for the hazard type
        and computes summary statistics.

        Args:
            hazard_type: Climate hazard type.

        Returns:
            Dictionary containing:
                - hazard_type: Hazard type.
                - total_assessments: Number of stored scores.
                - entities_assessed: Number of unique entities.
                - average_vulnerability: Mean vulnerability score.
                - max_vulnerability: Maximum vulnerability score.
                - min_vulnerability: Minimum vulnerability score.
                - overall_level: Vulnerability level of the average.
                - level_distribution: Count by vulnerability level.
        """
        scores = self.list_vulnerability_scores(
            hazard_type=hazard_type, limit=10000
        )

        if not scores:
            return {
                "hazard_type": hazard_type,
                "total_assessments": 0,
                "entities_assessed": 0,
                "average_vulnerability": 0.0,
                "max_vulnerability": 0.0,
                "min_vulnerability": 0.0,
                "overall_level": VulnerabilityLevel.NEGLIGIBLE.value,
                "level_distribution": {
                    level.value: 0 for level in VulnerabilityLevel
                },
            }

        vuln_scores = [s["vulnerability_score"] for s in scores]
        entities = set(s["entity_id"] for s in scores)
        avg_vuln = _safe_mean(vuln_scores)

        level_dist: Dict[str, int] = {level.value: 0 for level in VulnerabilityLevel}
        for s in scores:
            lvl = s["vulnerability_level"]
            if lvl in level_dist:
                level_dist[lvl] += 1

        return {
            "hazard_type": hazard_type,
            "total_assessments": len(scores),
            "entities_assessed": len(entities),
            "average_vulnerability": round(avg_vuln, 4),
            "max_vulnerability": round(max(vuln_scores), 4),
            "min_vulnerability": round(min(vuln_scores), 4),
            "overall_level": _classify_vulnerability(avg_vuln).value,
            "level_distribution": level_dist,
        }

    # ------------------------------------------------------------------
    # Dunder methods
    # ------------------------------------------------------------------

    def __repr__(self) -> str:
        """Return a developer-friendly string representation.

        Returns:
            String showing engine state summary.
        """
        with self._lock:
            n_scores = len(self._scores)
            n_sens = len(self._sensitivity_profiles)
            n_adapt = len(self._adaptive_profiles)
        return (
            f"VulnerabilityScorerEngine("
            f"scores={n_scores}, "
            f"sensitivity_profiles={n_sens}, "
            f"adaptive_profiles={n_adapt}, "
            f"total_scored={self._total_scored})"
        )

    def __len__(self) -> int:
        """Return the number of stored vulnerability scores.

        Returns:
            Integer count of scores in memory.
        """
        with self._lock:
            return len(self._scores)
