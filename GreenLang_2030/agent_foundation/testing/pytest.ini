[pytest]
# GreenLang Agent Foundation Testing Configuration
# Target: 90%+ test coverage with comprehensive quality validation

# Test discovery patterns
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Test directories
testpaths =
    unit_tests
    integration_tests
    e2e_tests
    performance_tests

# Minimum Python version
minversion = 3.8

# Strict markers - fail on unknown markers
strict_markers = true

# Coverage configuration
addopts =
    --verbose
    --strict
    --tb=short
    --cov=..
    --cov-report=html:htmlcov
    --cov-report=term-missing:skip-covered
    --cov-report=xml
    --cov-fail-under=90
    --maxfail=5
    --disable-warnings
    --color=yes
    -p no:cacheprovider

# Coverage targets per module
[coverage:run]
source = ..
omit =
    */tests/*
    */test_*
    */__pycache__/*
    */venv/*
    */env/*

[coverage:report]
precision = 2
show_missing = true
skip_covered = false
fail_under = 90
exclude_lines =
    pragma: no cover
    def __repr__
    if TYPE_CHECKING:
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    pass

[coverage:html]
directory = htmlcov
title = GreenLang Agent Foundation Coverage Report

# Test markers
markers =
    unit: Unit tests for individual components
    integration: Integration tests for component interactions
    e2e: End-to-end tests for complete workflows
    performance: Performance and load tests
    security: Security and vulnerability tests
    compliance: Regulatory compliance tests
    slow: Tests that take >1 second to run
    requires_gpu: Tests requiring GPU acceleration
    requires_llm: Tests requiring LLM API access
    smoke: Quick smoke tests for CI/CD
    regression: Regression test suite
    chaos: Chaos engineering tests
    benchmark: Performance benchmark tests

# Asyncio configuration
asyncio_mode = auto

# Logging
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s - %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = test_run.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(name)s - %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Timeout configuration
timeout = 300
timeout_method = thread

# Parallel execution (if using pytest-xdist)
# -n auto for automatic CPU count detection
# addopts = -n auto

# Test output
console_output_style = progress

# Warnings
filterwarnings =
    error
    ignore::UserWarning
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning

# Plugin configuration
plugins =
    cov
    html
    timeout
    asyncio
    benchmark
    mock

# Doctest configuration
doctest_optionflags = NORMALIZE_WHITESPACE IGNORE_EXCEPTION_DETAIL

# Test collection
collect_ignore =
    setup.py
    conftest.py

# Environment variables for tests
[pytest:env]
TESTING = true
LOG_LEVEL = DEBUG
MOCK_LLM = true
DETERMINISTIC = true
RANDOM_SEED = 42