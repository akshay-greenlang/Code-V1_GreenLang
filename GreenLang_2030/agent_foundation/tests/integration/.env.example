# ============================================================================
# GreenLang LLM Integration Tests - Environment Configuration
# ============================================================================
# Copy this file to .env and fill in your API keys and configuration
#
# Usage:
#   cp .env.example .env
#   nano .env  # Edit with your values
#
# IMPORTANT: Never commit .env to version control!
# ============================================================================

# ============================================================================
# API Keys (Required for real_api tests)
# ============================================================================

# Anthropic Claude API Key
# Get from: https://console.anthropic.com/account/keys
ANTHROPIC_API_KEY=sk-ant-api03-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

# OpenAI GPT API Key
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX


# ============================================================================
# Test Mode Configuration
# ============================================================================

# Test mode: "real", "mock", or "hybrid"
# - real: Use real API calls (requires API keys, costs money)
# - mock: Use mocked responses (fast, free, no API calls)
# - hybrid: Mix of real and mock (cost-effective)
TEST_MODE=mock


# ============================================================================
# Budget and Cost Controls
# ============================================================================

# Maximum budget for tests in USD (default: $1.00)
# Tests will stop if this budget is exceeded
TEST_BUDGET_USD=1.00

# Alert thresholds (as percentages of budget)
# Alerts at 80%, 90%, and 100% of budget
TEST_BUDGET_ALERT_THRESHOLDS=0.8,0.9,1.0


# ============================================================================
# Test Configuration
# ============================================================================

# Timeout for individual requests (seconds)
DEFAULT_TIMEOUT_S=30.0

# Health check timeout (seconds)
HEALTH_CHECK_TIMEOUT_S=10.0

# Performance targets
LATENCY_P95_TARGET_MS=2000  # P95 latency target in milliseconds
THROUGHPUT_TARGET_RPS=10     # Requests per second target

# Rate limiting (test mode - reduced from production)
ANTHROPIC_RATE_LIMIT_RPM=50   # Requests per minute (Anthropic)
OPENAI_RATE_LIMIT_RPM=100     # Requests per minute (OpenAI)


# ============================================================================
# Model Selection (for cost control)
# ============================================================================

# Use cheaper models for testing to reduce costs
# Anthropic models (cheaper to more expensive):
#   - claude-3-haiku-20240307     ($0.00025/$0.00125 per 1K tokens)
#   - claude-3-sonnet-20240229    ($0.003/$0.015 per 1K tokens)
#   - claude-3-opus-20240229      ($0.015/$0.075 per 1K tokens)
ANTHROPIC_MODEL=claude-3-haiku-20240307

# OpenAI models (cheaper to more expensive):
#   - gpt-3.5-turbo               ($0.0005/$0.0015 per 1K tokens)
#   - gpt-4-turbo-preview         ($0.01/$0.03 per 1K tokens)
#   - gpt-4                       ($0.03/$0.06 per 1K tokens)
OPENAI_MODEL=gpt-3.5-turbo


# ============================================================================
# Logging Configuration
# ============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log file path (optional, leave empty for console only)
LOG_FILE=

# Enable detailed request/response logging
ENABLE_REQUEST_LOGGING=false


# ============================================================================
# Circuit Breaker Configuration
# ============================================================================

# Number of failures before opening circuit breaker
CIRCUIT_BREAKER_THRESHOLD=5

# Recovery timeout in seconds (how long to wait before testing recovery)
CIRCUIT_BREAKER_TIMEOUT=60.0

# Maximum concurrent calls in half-open state
CIRCUIT_BREAKER_HALF_OPEN_MAX_CALLS=1


# ============================================================================
# Retry Configuration
# ============================================================================

# Maximum number of retries for failed requests
MAX_RETRIES=3

# Base delay for exponential backoff (seconds)
BASE_RETRY_DELAY=1.0

# Maximum retry delay (seconds)
MAX_RETRY_DELAY=8.0


# ============================================================================
# Performance Test Configuration
# ============================================================================

# Number of concurrent requests for stress testing
STRESS_TEST_CONCURRENT_REQUESTS=500

# Duration for sustained throughput tests (seconds)
SUSTAINED_THROUGHPUT_DURATION=60

# Memory usage threshold (MB increase per 1K requests)
MEMORY_THRESHOLD_MB=500


# ============================================================================
# CI/CD Configuration
# ============================================================================

# Skip real API tests in CI (set to "true" for CI environments)
CI_SKIP_REAL_API=false

# Maximum test duration in CI (seconds)
CI_MAX_TEST_DURATION=600


# ============================================================================
# Development/Debug Settings
# ============================================================================

# Enable pytest verbose output
PYTEST_VERBOSE=true

# Enable pytest debug mode
PYTEST_DEBUG=false

# Capture output (show print statements)
PYTEST_CAPTURE=no

# Stop on first failure
PYTEST_EXITFIRST=false


# ============================================================================
# Optional: Provider-Specific Configuration
# ============================================================================

# Anthropic-specific settings
ANTHROPIC_MAX_RETRIES=4
ANTHROPIC_TIMEOUT=60.0

# OpenAI-specific settings
OPENAI_MAX_RETRIES=4
OPENAI_TIMEOUT=60.0
OPENAI_MAX_CONNECTIONS=100


# ============================================================================
# Optional: Database Configuration (for persistence tests)
# ============================================================================

# Database URL for cost tracking persistence (optional)
# DATABASE_URL=postgresql://user:password@localhost:5432/greenlang_test

# Redis URL for caching (optional)
# REDIS_URL=redis://localhost:6379/0


# ============================================================================
# Optional: Monitoring and Observability
# ============================================================================

# Enable metrics collection
ENABLE_METRICS=true

# Metrics export interval (seconds)
METRICS_EXPORT_INTERVAL=60

# Enable distributed tracing
ENABLE_TRACING=false

# Jaeger endpoint for traces (optional)
# JAEGER_ENDPOINT=http://localhost:14268/api/traces


# ============================================================================
# Notes
# ============================================================================
#
# Cost Estimates (using cheapest models):
#   - Provider tests: ~$0.15 (30 API calls)
#   - Router tests: ~$0.12 (25 API calls)
#   - Failover tests: ~$0.20 (40 API calls)
#   - Performance tests: ~$0.45 (1500 API calls)
#   - Total: ~$0.92
#
# Recommended Settings:
#   - Development: TEST_MODE=mock (fast, free)
#   - Pre-commit: TEST_MODE=real with TEST_BUDGET_USD=0.50
#   - CI/CD: TEST_MODE=mock for PR, TEST_MODE=real for main branch
#   - Production validation: TEST_MODE=real with full budget
#
# Security:
#   - NEVER commit .env to version control
#   - Add .env to .gitignore
#   - Use environment variables in production
#   - Rotate API keys regularly
#
# ============================================================================
