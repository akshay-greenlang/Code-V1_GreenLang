{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSRD Platform SDK - Interactive Tutorial\n",
    "\n",
    "**Welcome to the CSRD Reporting Platform SDK Tutorial!**\n",
    "\n",
    "This Jupyter notebook provides a hands-on introduction to the CSRD Platform Python SDK.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Quick Start** - Generate your first CSRD report in minutes\n",
    "2. **Individual Agents** - Use each of the 6 agents separately\n",
    "3. **Advanced Configuration** - Customize the pipeline for your needs\n",
    "4. **Data Visualization** - Analyze ESG metrics with pandas and matplotlib\n",
    "5. **Troubleshooting** - Common issues and solutions\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.11+\n",
    "- All dependencies installed: `pip install -r requirements.txt`\n",
    "- OpenAI API key (for materiality assessment): `export OPENAI_API_KEY='your-key'`\n",
    "\n",
    "## About This Platform\n",
    "\n",
    "The CSRD Platform transforms raw ESG data into submission-ready EU CSRD reports with:\n",
    "\n",
    "- **6-Agent Pipeline**: Intake â†’ Materiality â†’ Calculate â†’ Aggregate â†’ Report â†’ Audit\n",
    "- **Zero Hallucination**: 100% accurate calculations (no LLM involvement)\n",
    "- **<30 Minute Processing**: Complete CSRD report for 10,000+ data points\n",
    "- **XBRL Digital Tagging**: ESEF-compliant submission packages\n",
    "\n",
    "Let's get started! ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and configure our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Data analysis imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# CSRD SDK imports\n",
    "from sdk.csrd_sdk import (\n",
    "    csrd_build_report,\n",
    "    csrd_validate_data,\n",
    "    csrd_assess_materiality,\n",
    "    csrd_calculate_metrics,\n",
    "    CSRDConfig,\n",
    "    CSRDReport\n",
    ")\n",
    "\n",
    "# Configure visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ“ All imports successful!\")\n",
    "print(f\"Working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths to demo data\n",
    "BASE_DIR = Path.cwd().parent\n",
    "DEMO_ESG_DATA = BASE_DIR / \"examples\" / \"demo_esg_data.csv\"\n",
    "DEMO_COMPANY_PROFILE = BASE_DIR / \"examples\" / \"demo_company_profile.json\"\n",
    "OUTPUT_DIR = BASE_DIR / \"output\" / \"notebook_demo\"\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"âœ“ Demo data: {DEMO_ESG_DATA.name}\")\n",
    "print(f\"âœ“ Company profile: {DEMO_COMPANY_PROFILE.name}\")\n",
    "print(f\"âœ“ Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for API key (required for materiality assessment)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if api_key:\n",
    "    print(\"âœ“ OpenAI API key found\")\n",
    "    print(f\"  Key starts with: {api_key[:8]}...\")\n",
    "else:\n",
    "    print(\"âš  OpenAI API key not found\")\n",
    "    print(\"  Set via: os.environ['OPENAI_API_KEY'] = 'your-key-here'\")\n",
    "    print(\"  Materiality assessment will be skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for pretty printing\n",
    "def print_section(title):\n",
    "    \"\"\"Print a section header.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(title)\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "def print_dict(d, indent=0):\n",
    "    \"\"\"Pretty print a dictionary.\"\"\"\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            print(\"  \" * indent + str(key) + \":\")\n",
    "            print_dict(value, indent + 1)\n",
    "        else:\n",
    "            print(\"  \" * indent + f\"{key}: {value}\")\n",
    "\n",
    "print(\"âœ“ Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Quick Start Example\n",
    "\n",
    "Let's generate your first CSRD report using the one-function API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load company profile to extract information\n",
    "with open(DEMO_COMPANY_PROFILE, 'r') as f:\n",
    "    company_data = json.load(f)\n",
    "\n",
    "print_section(\"Company Profile\")\n",
    "print(f\"Legal Name: {company_data.get('legal_name')}\")\n",
    "print(f\"Country: {company_data.get('country')}\")\n",
    "print(f\"Sector: {company_data.get('sector', {}).get('industry')}\")\n",
    "print(f\"Employees: {company_data.get('company_size', {}).get('employee_count'):,}\")\n",
    "print(f\"Revenue: â‚¬{company_data.get('company_size', {}).get('revenue_eur'):,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSRD configuration\n",
    "config = CSRDConfig(\n",
    "    company_name=company_data.get('legal_name'),\n",
    "    company_lei=company_data.get('lei_code'),\n",
    "    reporting_year=company_data.get('reporting_period', {}).get('fiscal_year', 2024),\n",
    "    sector=company_data.get('sector', {}).get('industry'),\n",
    "    country=company_data.get('country'),\n",
    "    employee_count=company_data.get('company_size', {}).get('employee_count'),\n",
    "    revenue=company_data.get('company_size', {}).get('revenue_eur'),\n",
    "    \n",
    "    # LLM configuration\n",
    "    llm_provider=\"openai\",\n",
    "    llm_model=\"gpt-4o\",\n",
    "    llm_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    \n",
    "    # Quality thresholds\n",
    "    quality_threshold=0.80,\n",
    "    impact_materiality_threshold=5.0,\n",
    "    financial_materiality_threshold=5.0\n",
    ")\n",
    "\n",
    "print(\"âœ“ CSRD configuration created\")\n",
    "print(f\"  Company: {config.company_name}\")\n",
    "print(f\"  Reporting Year: {config.reporting_year}\")\n",
    "print(f\"  Quality Threshold: {config.quality_threshold * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate complete CSRD report (one function call!)\n",
    "print_section(\"Generating CSRD Report\")\n",
    "print(\"This will execute all 6 agents...\")\n",
    "print(\"Expected time: 2-5 minutes for demo data\\n\")\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Skip materiality if no API key\n",
    "skip_mat = not bool(config.llm_api_key)\n",
    "if skip_mat:\n",
    "    print(\"âš  Skipping materiality assessment (no API key)\\n\")\n",
    "\n",
    "report = csrd_build_report(\n",
    "    esg_data=str(DEMO_ESG_DATA),\n",
    "    company_profile=str(DEMO_COMPANY_PROFILE),\n",
    "    config=config,\n",
    "    output_dir=str(OUTPUT_DIR),\n",
    "    skip_materiality=skip_mat,\n",
    "    skip_audit=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nâœ“ Report generated in {elapsed:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display report summary\n",
    "print(report.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access report properties\n",
    "print_section(\"Report Properties\")\n",
    "\n",
    "print(f\"Report ID: {report.report_id}\")\n",
    "print(f\"Company: {report.company_info.get('legal_name')}\")\n",
    "print(f\"Reporting Year: {report.reporting_period.get('year')}\")\n",
    "print(f\"\\nCompliance Status: {report.compliance_status.compliance_status}\")\n",
    "print(f\"Is Compliant: {report.is_compliant}\")\n",
    "print(f\"Is Audit Ready: {report.is_audit_ready}\")\n",
    "print(f\"\\nMaterial Topics: {report.materiality.material_topics_count}\")\n",
    "print(f\"Material Standards: {', '.join(report.material_standards)}\")\n",
    "print(f\"\\nMetrics Calculated: {report.metrics.total_metrics_calculated}\")\n",
    "print(f\"Processing Time: {report.processing_time_total_minutes:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Individual Agent Usage\n",
    "\n",
    "Now let's explore using each agent individually. This gives you more control over the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 1: Data Validation (IntakeAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate ESG data without generating a full report\n",
    "validation_result = csrd_validate_data(\n",
    "    esg_data=str(DEMO_ESG_DATA),\n",
    "    company_profile=str(DEMO_COMPANY_PROFILE),\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print_section(\"Data Validation Results\")\n",
    "metadata = validation_result.get('metadata', {})\n",
    "print(f\"Total Records: {metadata.get('total_records')}\")\n",
    "print(f\"Valid Records: {metadata.get('valid_records')}\")\n",
    "print(f\"Invalid Records: {metadata.get('invalid_records')}\")\n",
    "print(f\"Data Quality Score: {metadata.get('data_quality_score'):.1f}/100\")\n",
    "print(f\"Quality Threshold Met: {metadata.get('quality_threshold_met')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect validation issues\n",
    "issues = validation_result.get('validation_issues', [])\n",
    "print(f\"\\nValidation Issues Found: {len(issues)}\")\n",
    "\n",
    "if issues:\n",
    "    print(\"\\nFirst 5 issues:\")\n",
    "    for i, issue in enumerate(issues[:5], 1):\n",
    "        print(f\"\\n{i}. {issue.get('severity', 'unknown').upper()}\")\n",
    "        print(f\"   Code: {issue.get('error_code')}\")\n",
    "        print(f\"   Message: {issue.get('message')}\")\n",
    "        print(f\"   Field: {issue.get('field')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 2: Materiality Assessment (MaterialityAgent)\n",
    "\n",
    "**Note**: This requires an LLM API key and may take 5-10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run materiality assessment (if API key is available)\n",
    "if config.llm_api_key:\n",
    "    print(\"Running AI-powered double materiality assessment...\")\n",
    "    print(\"This may take 5-10 minutes...\\n\")\n",
    "    \n",
    "    materiality_result = csrd_assess_materiality(\n",
    "        esg_data=validation_result,\n",
    "        company_context=str(DEMO_COMPANY_PROFILE),\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    print_section(\"Materiality Assessment Results\")\n",
    "    stats = materiality_result.get('summary_statistics', {})\n",
    "    print(f\"Total Topics Assessed: {stats.get('total_topics_assessed')}\")\n",
    "    print(f\"Material Topics: {stats.get('material_topics_count')}\")\n",
    "    print(f\"Impact Material: {stats.get('material_from_impact')}\")\n",
    "    print(f\"Financial Material: {stats.get('material_from_financial')}\")\n",
    "    print(f\"Double Material: {stats.get('double_material_count')}\")\n",
    "    \n",
    "    print(f\"\\nESRS Standards Triggered:\")\n",
    "    for std in stats.get('esrs_standards_triggered', []):\n",
    "        print(f\"  â€¢ {std}\")\n",
    "else:\n",
    "    print(\"âš  Skipping materiality assessment (no API key)\")\n",
    "    print(\"Set OPENAI_API_KEY to enable this feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 3: Metrics Calculation (CalculatorAgent)\n",
    "\n",
    "**Zero Hallucination Guarantee**: All calculations are 100% deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ESRS metrics\n",
    "calc_result = csrd_calculate_metrics(\n",
    "    validated_data=validation_result,\n",
    "    metrics_to_calculate=[\"E1-1\", \"E1-2\", \"E1-3\", \"E1-4\", \"S1-1\", \"G1-1\"],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print_section(\"Metrics Calculation Results\")\n",
    "metadata = calc_result.get('metadata', {})\n",
    "print(f\"Metrics Requested: {metadata.get('total_metrics_requested')}\")\n",
    "print(f\"Metrics Calculated: {metadata.get('metrics_calculated')}\")\n",
    "print(f\"Calculation Errors: {metadata.get('calculation_errors')}\")\n",
    "print(f\"Processing Time: {metadata.get('processing_time_seconds'):.3f} seconds\")\n",
    "print(f\"Time per Metric: {metadata.get('ms_per_metric'):.2f} ms\")\n",
    "print(f\"\\nZero Hallucination: {metadata.get('zero_hallucination_guarantee')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect calculated metrics\n",
    "metrics = calc_result.get('calculated_metrics', [])\n",
    "print(f\"\\nCalculated Metrics ({len(metrics)} total):\\n\")\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"{metric.get('metric_code')}: {metric.get('metric_name')}\")\n",
    "    print(f\"  Value: {metric.get('value')} {metric.get('unit')}\")\n",
    "    print(f\"  Formula: {metric.get('formula_used')}\")\n",
    "    print(f\"  Provenance: {metric.get('calculation_provenance', {}).get('method')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Data Visualization\n",
    "\n",
    "Let's visualize some of the ESG metrics using pandas and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert report data to DataFrame\n",
    "df = report.to_dataframe()\n",
    "\n",
    "print(f\"ESG Data Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print_section(\"Data Summary\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize GHG emissions breakdown\n",
    "if report.metrics.scope_1_emissions_tco2e:\n",
    "    emissions_data = {\n",
    "        'Scope 1': report.metrics.scope_1_emissions_tco2e or 0,\n",
    "        'Scope 2': report.metrics.scope_2_emissions_tco2e or 0,\n",
    "        'Scope 3': report.metrics.scope_3_emissions_tco2e or 0\n",
    "    }\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    colors = ['#FF6B6B', '#FFA07A', '#FFD700']\n",
    "    bars = ax.bar(emissions_data.keys(), emissions_data.values(), color=colors)\n",
    "    \n",
    "    ax.set_ylabel('Emissions (tCO2e)', fontsize=12)\n",
    "    ax.set_title('GHG Emissions Breakdown by Scope', fontsize=14, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:,.0f}',\n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Total GHG Emissions: {report.metrics.total_ghg_emissions_tco2e:,.2f} tCO2e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data quality scores\n",
    "if 'data_quality' in df.columns:\n",
    "    quality_counts = df['data_quality'].value_counts()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    colors = ['#4CAF50', '#FFC107', '#F44336']\n",
    "    wedges, texts, autotexts = ax.pie(\n",
    "        quality_counts.values,\n",
    "        labels=quality_counts.index,\n",
    "        autopct='%1.1f%%',\n",
    "        colors=colors,\n",
    "        startangle=90\n",
    "    )\n",
    "    \n",
    "    ax.set_title('Data Quality Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Material standards distribution\n",
    "if report.material_standards:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    standards = report.material_standards\n",
    "    metrics_by_std = report.metrics.metrics_by_standard\n",
    "    \n",
    "    x = range(len(standards))\n",
    "    values = [metrics_by_std.get(std, 0) for std in standards]\n",
    "    \n",
    "    bars = ax.bar(x, values, color='#2196F3')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(standards)\n",
    "    ax.set_ylabel('Number of Metrics', fontsize=12)\n",
    "    ax.set_title('Metrics by Material ESRS Standard', fontsize=14, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Advanced Configuration\n",
    "\n",
    "Customize the pipeline for specific use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Configuration from YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from YAML file\n",
    "config_file = BASE_DIR / \"config\" / \"csrd_config.yaml\"\n",
    "\n",
    "if config_file.exists():\n",
    "    custom_config = CSRDConfig.from_yaml(str(config_file))\n",
    "    print(\"âœ“ Configuration loaded from YAML\")\n",
    "    print(f\"  Company: {custom_config.company_name}\")\n",
    "    print(f\"  LLM Provider: {custom_config.llm_provider}\")\n",
    "    print(f\"  LLM Model: {custom_config.llm_model}\")\n",
    "    print(f\"  Quality Threshold: {custom_config.quality_threshold}\")\n",
    "else:\n",
    "    print(\"âš  Config file not found, using default configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Materiality Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config with custom thresholds\n",
    "strict_config = CSRDConfig(\n",
    "    company_name=\"Example Corp\",\n",
    "    company_lei=\"549300EXAMPLE123456\",\n",
    "    reporting_year=2024,\n",
    "    sector=\"Manufacturing\",\n",
    "    \n",
    "    # Stricter thresholds\n",
    "    quality_threshold=0.95,  # 95% data quality required\n",
    "    impact_materiality_threshold=7.0,  # Higher bar for impact\n",
    "    financial_materiality_threshold=7.0,  # Higher bar for financial\n",
    ")\n",
    "\n",
    "print(\"Custom Configuration Created:\")\n",
    "print(f\"  Quality Threshold: {strict_config.quality_threshold * 100}%\")\n",
    "print(f\"  Impact Threshold: {strict_config.impact_materiality_threshold}/10\")\n",
    "print(f\"  Financial Threshold: {strict_config.financial_materiality_threshold}/10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Alternative LLM Providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure for Anthropic Claude\n",
    "anthropic_config = CSRDConfig(\n",
    "    company_name=\"Example Corp\",\n",
    "    company_lei=\"549300EXAMPLE123456\",\n",
    "    reporting_year=2024,\n",
    "    sector=\"Manufacturing\",\n",
    "    \n",
    "    # Anthropic configuration\n",
    "    llm_provider=\"anthropic\",\n",
    "    llm_model=\"claude-3-5-sonnet-20241022\",\n",
    "    llm_api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    ")\n",
    "\n",
    "print(\"Alternative LLM Configuration:\")\n",
    "print(f\"  Provider: {anthropic_config.llm_provider}\")\n",
    "print(f\"  Model: {anthropic_config.llm_model}\")\n",
    "print(f\"  API Key Set: {bool(anthropic_config.llm_api_key)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Working with Report Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Reports in Different Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as JSON\n",
    "json_path = OUTPUT_DIR / \"report.json\"\n",
    "report.save_json(str(json_path))\n",
    "print(f\"âœ“ Saved to JSON: {json_path}\")\n",
    "\n",
    "# Save summary as Markdown\n",
    "summary_path = OUTPUT_DIR / \"summary.md\"\n",
    "report.save_summary(str(summary_path))\n",
    "print(f\"âœ“ Saved summary: {summary_path}\")\n",
    "\n",
    "# Get JSON string\n",
    "json_str = report.to_json(indent=2)\n",
    "print(f\"\\nJSON size: {len(json_str):,} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Raw Report Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw report dictionary\n",
    "raw_report = report.to_dict()\n",
    "\n",
    "print(\"Raw Report Structure:\")\n",
    "for key in raw_report.keys():\n",
    "    print(f\"  â€¢ {key}\")\n",
    "\n",
    "# Access specific sections\n",
    "print(f\"\\nReport Metadata:\")\n",
    "print_dict(raw_report.get('report_metadata', {}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Compliance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed compliance analysis\n",
    "compliance = report.compliance_status\n",
    "\n",
    "print_section(\"Compliance Analysis\")\n",
    "print(f\"Status: {compliance.compliance_status}\")\n",
    "print(f\"\\nRule Execution:\")\n",
    "print(f\"  Total Rules: {compliance.total_rules_checked}\")\n",
    "print(f\"  Passed: {compliance.rules_passed} ({compliance.rules_passed/compliance.total_rules_checked*100:.1f}%)\")\n",
    "print(f\"  Failed: {compliance.rules_failed}\")\n",
    "print(f\"  Warnings: {compliance.rules_warning}\")\n",
    "print(f\"\\nFailure Breakdown:\")\n",
    "print(f\"  Critical: {compliance.critical_failures}\")\n",
    "print(f\"  Major: {compliance.major_failures}\")\n",
    "print(f\"  Minor: {compliance.minor_failures}\")\n",
    "print(f\"\\nAudit Readiness: {compliance.audit_ready}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize compliance results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Overall compliance pie chart\n",
    "labels = ['Passed', 'Failed', 'Warnings']\n",
    "sizes = [compliance.rules_passed, compliance.rules_failed, compliance.rules_warning]\n",
    "colors = ['#4CAF50', '#F44336', '#FFC107']\n",
    "explode = (0.1, 0, 0)\n",
    "\n",
    "ax1.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_title('Overall Compliance Status', fontweight='bold')\n",
    "\n",
    "# Failure severity breakdown\n",
    "failure_labels = ['Critical', 'Major', 'Minor']\n",
    "failure_sizes = [compliance.critical_failures, compliance.major_failures, compliance.minor_failures]\n",
    "failure_colors = ['#D32F2F', '#F57C00', '#FDD835']\n",
    "\n",
    "ax2.bar(failure_labels, failure_sizes, color=failure_colors)\n",
    "ax2.set_ylabel('Count', fontsize=12)\n",
    "ax2.set_title('Failure Severity Breakdown', fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Troubleshooting Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Issues and Solutions\n",
    "\n",
    "#### 1. Data Quality Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data quality before processing\n",
    "def check_data_quality(validation_result):\n",
    "    \"\"\"Check if data quality meets requirements.\"\"\"\n",
    "    metadata = validation_result.get('metadata', {})\n",
    "    score = metadata.get('data_quality_score', 0)\n",
    "    threshold = metadata.get('quality_threshold', 80)\n",
    "    \n",
    "    print(f\"Data Quality Score: {score:.1f}/100\")\n",
    "    print(f\"Required Threshold: {threshold}/100\")\n",
    "    \n",
    "    if score < threshold:\n",
    "        print(\"\\nâš  Data quality below threshold!\")\n",
    "        print(\"\\nRecommendations:\")\n",
    "        print(\"1. Review validation issues\")\n",
    "        print(\"2. Fix data completeness gaps\")\n",
    "        print(\"3. Verify metric codes against ESRS catalog\")\n",
    "        print(\"4. Check unit consistency\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"\\nâœ“ Data quality meets requirements\")\n",
    "        return True\n",
    "\n",
    "check_data_quality(validation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. API Key Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify API key configuration\n",
    "def check_api_keys():\n",
    "    \"\"\"Check API key availability.\"\"\"\n",
    "    openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    anthropic_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    \n",
    "    print(\"API Key Status:\")\n",
    "    print(f\"  OpenAI: {'âœ“ Set' if openai_key else 'âœ— Not set'}\")\n",
    "    print(f\"  Anthropic: {'âœ“ Set' if anthropic_key else 'âœ— Not set'}\")\n",
    "    \n",
    "    if not openai_key and not anthropic_key:\n",
    "        print(\"\\nâš  No LLM API keys found\")\n",
    "        print(\"\\nTo enable materiality assessment:\")\n",
    "        print(\"  export OPENAI_API_KEY='your-key'\")\n",
    "        print(\"  # or\")\n",
    "        print(\"  export ANTHROPIC_API_KEY='your-key'\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "check_api_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Performance Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance tips\n",
    "print(\"Performance Optimization Tips:\\n\")\n",
    "print(\"1. Skip materiality for faster processing (testing only):\")\n",
    "print(\"   skip_materiality=True\")\n",
    "print(\"\\n2. Process data in batches for large datasets\")\n",
    "print(\"\\n3. Use validation-only mode first:\")\n",
    "print(\"   result = csrd_validate_data(...)\")\n",
    "print(\"\\n4. Cache intermediate results\")\n",
    "print(\"\\n5. Expected performance:\")\n",
    "print(\"   - 1,000 data points: ~5 minutes\")\n",
    "print(\"   - 10,000 data points: ~15 minutes\")\n",
    "print(\"   - 50,000 data points: ~45 minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8: Next Steps\n",
    "\n",
    "### Further Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Congratulations! You've completed the CSRD Platform SDK tutorial.\\n\")\n",
    "print(\"Next Steps:\\n\")\n",
    "print(\"1. Read the User Guide:\")\n",
    "print(\"   docs/USER_GUIDE.md\")\n",
    "print(\"\\n2. Explore the API Reference:\")\n",
    "print(\"   docs/API_REFERENCE.md\")\n",
    "print(\"\\n3. Review deployment options:\")\n",
    "print(\"   docs/DEPLOYMENT_GUIDE.md\")\n",
    "print(\"\\n4. Try with your own data:\")\n",
    "print(\"   â€¢ Prepare ESG data in CSV format\")\n",
    "print(\"   â€¢ Create company profile JSON\")\n",
    "print(\"   â€¢ Run the pipeline\")\n",
    "print(\"\\n5. Join the community:\")\n",
    "print(\"   â€¢ GitHub Issues: Report bugs or request features\")\n",
    "print(\"   â€¢ Email: csrd@greenlang.io\")\n",
    "print(\"\\nHappy reporting! ðŸš€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Appendix: Quick Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference for common operations\n",
    "print(\"CSRD Platform SDK - Quick Reference\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n1. GENERATE COMPLETE REPORT\\n\")\n",
    "print(\"from sdk.csrd_sdk import csrd_build_report, CSRDConfig\")\n",
    "print(\"\")\n",
    "print(\"config = CSRDConfig(company_name='...', ...)\")\n",
    "print(\"report = csrd_build_report(\")\n",
    "print(\"    esg_data='data.csv',\")\n",
    "print(\"    company_profile='company.json',\")\n",
    "print(\"    config=config,\")\n",
    "print(\"    output_dir='output'\")\n",
    "print(\")\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\n2. VALIDATE DATA ONLY\\n\")\n",
    "print(\"from sdk.csrd_sdk import csrd_validate_data\")\n",
    "print(\"\")\n",
    "print(\"result = csrd_validate_data(\")\n",
    "print(\"    esg_data='data.csv',\")\n",
    "print(\"    config=config\")\n",
    "print(\")\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\n3. ACCESS REPORT DATA\\n\")\n",
    "print(\"report.summary()  # Text summary\")\n",
    "print(\"report.to_dataframe()  # Convert to pandas DataFrame\")\n",
    "print(\"report.save_json('report.json')  # Save to file\")\n",
    "print(\"report.is_compliant  # Check compliance status\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
