# GL-001 ProcessHeatOrchestrator - Continuous Integration Pipeline
# Comprehensive CI pipeline with quality gates, security scans, and performance tests
# Runs on every push and pull request to ensure production readiness

name: GL-001 CI

on:
  push:
    branches:
      - main
      - master
      - develop
      - 'release/**'
      - 'hotfix/**'
    paths:
      - 'applications/GL Agents/GL-001_Thermalcommand/**'
      - '.github/workflows/gl-001-ci.yaml'
      - 'requirements.txt'
      - 'pytest.ini'

  pull_request:
    branches:
      - main
      - master
      - develop
    paths:
      - 'applications/GL Agents/GL-001_Thermalcommand/**'
      - '.github/workflows/gl-001-ci.yaml'
      - 'requirements.txt'

  # Allow manual trigger
  workflow_dispatch:
    inputs:
      skip_tests:
        description: 'Skip test execution (for debugging)'
        required: false
        default: 'false'

# Ensure only one workflow runs at a time per branch
concurrency:
  group: gl-001-ci-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: '3.11'
  GL_001_PATH: 'applications/GL Agents/GL-001_Thermalcommand'
  COVERAGE_THRESHOLD: 85
  NODE_ENV: test

jobs:
  # ============================================================================
  # JOB 1: CODE QUALITY CHECKS
  # ============================================================================
  code-quality:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better analysis

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install linting tools
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install ruff mypy black isort pylint flake8 bandit

      - name: Run ruff linter
        run: |
          echo "üîç Running ruff linter..."
          ruff check ${{ env.GL_001_PATH }} --format=github
        continue-on-error: true

      - name: Check code formatting with black
        run: |
          echo "üé® Checking code formatting..."
          black --check --diff ${{ env.GL_001_PATH }}

      - name: Check import sorting with isort
        run: |
          echo "üì¶ Checking import sorting..."
          isort --check-only --diff ${{ env.GL_001_PATH }}

      - name: Type checking with mypy
        run: |
          echo "üî¨ Running type checker..."
          mypy ${{ env.GL_001_PATH }} \
            --ignore-missing-imports \
            --disallow-untyped-defs \
            --no-implicit-optional \
            --warn-redundant-casts \
            --warn-return-any
        continue-on-error: true

      - name: Lint with pylint
        run: |
          echo "üîç Running pylint..."
          pip install -r requirements.txt
          pylint ${{ env.GL_001_PATH }} \
            --disable=C0111,C0103,R0913,R0914 \
            --max-line-length=120
        continue-on-error: true

      - name: Check code complexity
        run: |
          echo "üìä Checking code complexity..."
          pip install radon
          radon cc ${{ env.GL_001_PATH }} -a -nb
          radon mi ${{ env.GL_001_PATH }} -nb

  # ============================================================================
  # JOB 2: SECURITY SCANNING
  # ============================================================================
  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    timeout-minutes: 20
    permissions:
      security-events: write
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install bandit safety pip-audit

      - name: Run bandit security scanner
        run: |
          echo "üîí Running bandit security scanner..."
          bandit -r ${{ env.GL_001_PATH }} \
            -f json -o bandit-report.json \
            -ll -i || true
          bandit -r ${{ env.GL_001_PATH }} -ll

      - name: Check for hardcoded secrets
        run: |
          echo "üîë Scanning for hardcoded secrets..."
          pip install detect-secrets
          detect-secrets scan ${{ env.GL_001_PATH }} \
            --baseline .secrets.baseline || true

      - name: Dependency vulnerability scan with pip-audit
        run: |
          echo "üì¶ Scanning dependencies for vulnerabilities..."
          pip-audit --requirement requirements.txt \
            --desc --format json \
            --output pip-audit-report.json || true
          pip-audit --requirement requirements.txt

      - name: Check dependencies with safety
        run: |
          echo "üõ°Ô∏è Checking dependency safety..."
          safety check --json --output safety-report.json || true
          safety check

      - name: Upload security reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: |
            bandit-report.json
            pip-audit-report.json
            safety-report.json
          retention-days: 30

  # ============================================================================
  # JOB 3: UNIT AND INTEGRATION TESTS
  # ============================================================================
  test:
    name: Unit & Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30

    services:
      postgres:
        image: postgres:14-alpine
        env:
          POSTGRES_DB: test_greenlang
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio pytest-mock pytest-xdist

      - name: Run unit tests with coverage
        if: ${{ github.event.inputs.skip_tests != 'true' }}
        env:
          DATABASE_URL: postgresql://test_user:test_password@localhost:5432/test_greenlang
          REDIS_URL: redis://localhost:6379/0
          PYTHONPATH: ${{ github.workspace }}
        run: |
          echo "üß™ Running unit tests..."
          cd ${{ env.GL_001_PATH }}
          pytest tests/ \
            --cov=. \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term \
            --cov-fail-under=${{ env.COVERAGE_THRESHOLD }} \
            --junitxml=test-results.xml \
            --maxfail=5 \
            -v

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            ${{ env.GL_001_PATH }}/htmlcov/
            ${{ env.GL_001_PATH }}/test-results.xml
            ${{ env.GL_001_PATH }}/coverage.xml
          retention-days: 30

      - name: Upload coverage to Codecov
        if: always()
        uses: codecov/codecov-action@v3
        with:
          files: ${{ env.GL_001_PATH }}/coverage.xml
          flags: gl-001-unittests
          name: GL-001-Coverage

  # ============================================================================
  # JOB 4: DETERMINISM VALIDATION
  # ============================================================================
  determinism:
    name: Determinism Validation
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest

      - name: Run determinism tests
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          echo "üîÑ Running determinism validation..."
          cd ${{ env.GL_001_PATH }}
          pytest tests/test_determinism.py -v --tb=short

      - name: Verify zero-hallucination guarantee
        run: |
          echo "‚úÖ Verifying zero-hallucination guarantee..."
          echo "Checking for eval() or exec() usage..."
          ! grep -r "eval(" ${{ env.GL_001_PATH }} --include="*.py" || (echo "ERROR: eval() found!" && exit 1)
          ! grep -r "exec(" ${{ env.GL_001_PATH }} --include="*.py" || (echo "ERROR: exec() found!" && exit 1)
          echo "‚úÖ No eval() or exec() found - zero-hallucination guarantee maintained"

  # ============================================================================
  # JOB 5: PERFORMANCE TESTING
  # ============================================================================
  performance:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    timeout-minutes: 25

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-benchmark locust

      - name: Run performance tests
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          echo "‚ö° Running performance benchmarks..."
          cd ${{ env.GL_001_PATH }}
          pytest tests/test_performance.py \
            --benchmark-only \
            --benchmark-autosave \
            --benchmark-json=benchmark-results.json
        continue-on-error: true

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-benchmarks
          path: ${{ env.GL_001_PATH }}/benchmark-results.json
          retention-days: 30

  # ============================================================================
  # JOB 6: BUILD VALIDATION
  # ============================================================================
  build:
    name: Build Validation
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image (no push)
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ${{ env.GL_001_PATH }}/Dockerfile
          push: false
          tags: gl-001-process-heat:ci-${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # ============================================================================
  # JOB 7: FINAL CI STATUS
  # ============================================================================
  ci-status:
    name: CI Pipeline Status
    runs-on: ubuntu-latest
    needs: [code-quality, security-scan, test, determinism, performance, build]
    if: always()

    steps:
      - name: Check job statuses
        run: |
          echo "üìä CI Pipeline Summary:"
          echo "Code Quality: ${{ needs.code-quality.result }}"
          echo "Security Scan: ${{ needs.security-scan.result }}"
          echo "Tests: ${{ needs.test.result }}"
          echo "Determinism: ${{ needs.determinism.result }}"
          echo "Performance: ${{ needs.performance.result }}"
          echo "Build: ${{ needs.build.result }}"

      - name: Fail if any required job failed
        if: |
          needs.code-quality.result == 'failure' ||
          needs.security-scan.result == 'failure' ||
          needs.test.result == 'failure' ||
          needs.determinism.result == 'failure' ||
          needs.build.result == 'failure'
        run: |
          echo "‚ùå CI Pipeline FAILED"
          exit 1

      - name: Success
        if: success()
        run: |
          echo "‚úÖ CI Pipeline PASSED - Ready for CD"
