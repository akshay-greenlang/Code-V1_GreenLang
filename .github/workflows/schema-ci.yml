# =============================================================================
# GreenLang Schema Service CI
# GreenLang Climate OS | AGENT-FOUND-002
# =============================================================================
# Validates schema service: Python lint, type-check, unit tests,
# integration tests, security tests, coverage enforcement, K8s manifests,
# dashboard JSON, alert rules, SQL migration, Docker build, and deployment.
# =============================================================================

name: Schema Service CI

on:
  pull_request:
    paths:
      - 'deployment/kubernetes/schema-service/**'
      - 'deployment/monitoring/dashboards/schema-*'
      - 'deployment/monitoring/alerts/schema-*'
      - 'deployment/database/migrations/sql/V022__schema_service.sql'
      - 'greenlang/schema/**'
      - 'tests/schema/**'
      - 'tests/unit/schema_service/**'
      - 'tests/integration/schema_service/**'
  push:
    branches: [master]
    paths:
      - 'deployment/kubernetes/schema-service/**'
      - 'greenlang/schema/**'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: "3.11"
  DASHBOARDS_DIR: deployment/monitoring/dashboards
  ALERTS_DIR: deployment/monitoring/alerts
  K8S_DIR: deployment/kubernetes/schema-service

jobs:
  # -------------------------------------------------------------------------
  # Job 1: Lint (ruff + black + isort + YAML + JSON)
  # -------------------------------------------------------------------------
  lint:
    name: Lint (ruff + black + isort + YAML + JSON)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install linting tools
        run: pip install --quiet ruff black isort pyyaml

      - name: Lint Python (ruff)
        run: |
          if [ -d "greenlang/schema" ]; then
            ruff check greenlang/schema/ --select E,F,W --ignore E501
          else
            echo "WARNING: greenlang/schema/ not found"
          fi

      - name: Check formatting (black)
        run: |
          if [ -d "greenlang/schema" ]; then
            black --check --diff greenlang/schema/
          else
            echo "WARNING: greenlang/schema/ not found"
          fi

      - name: Check imports (isort)
        run: |
          if [ -d "greenlang/schema" ]; then
            isort --check-only --diff greenlang/schema/
          else
            echo "WARNING: greenlang/schema/ not found"
          fi

      - name: Validate schema dashboard JSON syntax
        run: |
          echo "Validating JSON syntax for schema dashboard files..."
          ERRORS=0
          CHECKED=0
          for f in ${{ env.DASHBOARDS_DIR }}/schema-*.json; do
            [ -e "$f" ] || continue
            CHECKED=$((CHECKED + 1))
            if ! python -m json.tool "$f" > /dev/null 2>&1; then
              echo "ERROR: Invalid JSON in $f"
              ERRORS=$((ERRORS + 1))
            fi
          done
          if [ $CHECKED -eq 0 ]; then
            echo "WARNING: No schema dashboard JSON files found"
          fi
          if [ $ERRORS -gt 0 ]; then
            echo "Found $ERRORS files with invalid JSON"
            exit 1
          fi
          echo "All $CHECKED schema dashboard JSON files are valid"

      - name: Check required dashboard fields
        run: |
          python3 << 'PYEOF'
          import json
          import glob
          import sys

          REQUIRED_FIELDS = ["uid", "title", "panels"]
          DASHBOARD_PATTERNS = [
              "${{ env.DASHBOARDS_DIR }}/schema-*.json",
          ]

          errors = []
          checked = 0

          for pattern in DASHBOARD_PATTERNS:
              for path in sorted(glob.glob(pattern)):
                  checked += 1
                  with open(path) as f:
                      try:
                          data = json.load(f)
                      except json.JSONDecodeError:
                          errors.append(f"{path}: Invalid JSON")
                          continue

                      for field in REQUIRED_FIELDS:
                          if field not in data:
                              errors.append(f"{path}: Missing required field '{field}'")

                      uid = data.get("uid", "")
                      if uid and (" " in uid or uid != uid.lower()):
                          errors.append(f"{path}: UID '{uid}' should be lowercase kebab-case")

          if errors:
              print("Dashboard validation errors:")
              for e in errors:
                  print(f"  - {e}")
              sys.exit(1)

          if checked == 0:
              print("WARNING: No schema dashboard files found to validate")
          else:
              print(f"All {checked} schema dashboards have required fields")
          PYEOF

      - name: Validate alert YAML syntax
        run: |
          python3 << 'PYEOF'
          import yaml
          import glob
          import sys

          errors = []
          checked = 0

          for path in sorted(glob.glob("${{ env.ALERTS_DIR }}/schema-*.yaml")):
              checked += 1
              with open(path) as f:
                  try:
                      docs = list(yaml.safe_load_all(f))
                  except yaml.YAMLError as e:
                      errors.append(f"{path}: Invalid YAML - {e}")
                      continue

              for doc in docs:
                  if doc is None:
                      continue
                  if "spec" in doc and "groups" in doc.get("spec", {}):
                      for group in doc["spec"]["groups"]:
                          if "name" not in group:
                              errors.append(f"{path}: Alert group missing 'name'")
                          if "rules" not in group:
                              errors.append(f"{path}: Alert group '{group.get('name', '?')}' missing 'rules'")
                          else:
                              for rule in group["rules"]:
                                  if "alert" in rule and "expr" not in rule:
                                      errors.append(f"{path}: Alert '{rule['alert']}' missing 'expr'")
                                  if "alert" in rule:
                                      annotations = rule.get("annotations", {})
                                      if "summary" not in annotations:
                                          errors.append(f"{path}: Alert '{rule['alert']}' missing 'summary' annotation")
                                      if "description" not in annotations:
                                          errors.append(f"{path}: Alert '{rule['alert']}' missing 'description' annotation")

          if errors:
              print("Alert YAML validation errors:")
              for e in errors:
                  print(f"  - {e}")
              sys.exit(1)

          if checked == 0:
              print("WARNING: No schema alert YAML files found to validate")
          else:
              print(f"All {checked} alert YAML files are valid")
          PYEOF

      - name: Validate K8s YAML syntax
        run: |
          python3 << 'PYEOF'
          import yaml
          import glob
          import sys

          errors = []
          checked = 0

          for path in sorted(glob.glob("${{ env.K8S_DIR }}/*.yaml")):
              checked += 1
              with open(path) as f:
                  try:
                      docs = list(yaml.safe_load_all(f))
                  except yaml.YAMLError as e:
                      errors.append(f"{path}: Invalid YAML - {e}")
                      continue

                  for doc in docs:
                      if doc is None:
                          continue
                      if "apiVersion" not in doc and "kind" not in doc:
                          if "resources" not in doc:
                              errors.append(f"{path}: Missing apiVersion or kind")

          if errors:
              print("K8s YAML validation errors:")
              for e in errors:
                  print(f"  - {e}")
              sys.exit(1)

          print(f"All {checked} K8s YAML files are valid")
          PYEOF

      - name: Check dashboard file sizes
        run: |
          MAX_SIZE=512000  # 500KB
          ERRORS=0
          CHECKED=0
          for f in ${{ env.DASHBOARDS_DIR }}/schema-*.json; do
            [ -e "$f" ] || continue
            CHECKED=$((CHECKED + 1))
            SIZE=$(stat --format=%s "$f")
            if [ "$SIZE" -gt "$MAX_SIZE" ]; then
              echo "ERROR: $f exceeds 500KB ($SIZE bytes)"
              ERRORS=$((ERRORS + 1))
            fi
          done
          if [ $ERRORS -gt 0 ]; then
            exit 1
          fi
          echo "All $CHECKED dashboard files are within size limits"

  # -------------------------------------------------------------------------
  # Job 2: Type Check (mypy)
  # -------------------------------------------------------------------------
  type-check:
    name: Type Check (mypy)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -e ".[dev]" 2>/dev/null || pip install \
            mypy \
            pydantic \
            fastapi \
            prometheus-client \
            psycopg \
            redis \
            pyyaml \
            types-PyYAML \
            types-redis

      - name: Run mypy strict mode
        run: |
          if [ -d "greenlang/schema" ]; then
            mypy greenlang/schema/ \
              --strict \
              --ignore-missing-imports \
              --no-error-summary \
              --show-column-numbers
          else
            echo "WARNING: greenlang/schema/ not found"
          fi

  # -------------------------------------------------------------------------
  # Job 3: Unit Tests
  # -------------------------------------------------------------------------
  unit-test:
    name: Unit Tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -e ".[dev]" 2>/dev/null || pip install \
            pytest \
            pytest-asyncio \
            pytest-cov \
            pydantic \
            fastapi \
            httpx \
            structlog \
            prometheus-client \
            psycopg \
            redis \
            pyyaml

      - name: Run unit tests
        run: |
          FOUND=0
          DIRS=""
          if [ -d "tests/schema/unit" ] && [ "$(ls -A tests/schema/unit/)" ]; then
            DIRS="$DIRS tests/schema/unit/"
            FOUND=1
          fi
          if [ -d "tests/unit/schema_service" ] && [ "$(ls -A tests/unit/schema_service/)" ]; then
            DIRS="$DIRS tests/unit/schema_service/"
            FOUND=1
          fi
          if [ $FOUND -eq 1 ]; then
            pytest $DIRS -v --tb=short -q \
              --junitxml=junit-schema-unit.xml
          else
            echo "WARNING: No unit tests found in tests/schema/unit/ or tests/unit/schema_service/"
            echo "Unit tests will be required once the test suite is created"
          fi

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-results
          path: junit-schema-unit.xml
          if-no-files-found: ignore

  # -------------------------------------------------------------------------
  # Job 4: Integration Tests
  # -------------------------------------------------------------------------
  integration-test:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [unit-test]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -e ".[dev]" 2>/dev/null || pip install \
            pytest \
            pytest-asyncio \
            pydantic \
            fastapi \
            httpx \
            structlog \
            prometheus-client \
            psycopg \
            redis \
            pyyaml

      - name: Run integration tests
        run: |
          FOUND=0
          DIRS=""
          if [ -d "tests/schema/integration" ] && [ "$(ls -A tests/schema/integration/)" ]; then
            DIRS="$DIRS tests/schema/integration/"
            FOUND=1
          fi
          if [ -d "tests/integration/schema_service" ] && [ "$(ls -A tests/integration/schema_service/)" ]; then
            DIRS="$DIRS tests/integration/schema_service/"
            FOUND=1
          fi
          if [ $FOUND -eq 1 ]; then
            pytest $DIRS -v --tb=short -q \
              -m "integration or not integration" \
              --junitxml=junit-schema-integration.xml
          else
            echo "WARNING: No integration tests found"
            echo "Integration tests will be required once the test suite is created"
          fi

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: junit-schema-integration.xml
          if-no-files-found: ignore

  # -------------------------------------------------------------------------
  # Job 5: Security Tests
  # -------------------------------------------------------------------------
  security-test:
    name: Security Tests
    runs-on: ubuntu-latest
    needs: [unit-test]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -e ".[dev]" 2>/dev/null || pip install \
            pytest \
            pytest-asyncio \
            pydantic \
            fastapi \
            httpx \
            structlog \
            prometheus-client \
            psycopg \
            redis \
            pyyaml \
            bandit

      - name: Run security tests
        run: |
          if [ -d "tests/schema/security" ] && [ "$(ls -A tests/schema/security/)" ]; then
            pytest tests/schema/security/ -v --tb=short -q \
              --junitxml=junit-schema-security.xml
          else
            echo "WARNING: No security tests found in tests/schema/security/"
            echo "Security tests will be required once the test suite is created"
          fi

      - name: Run bandit security scan
        run: |
          if [ -d "greenlang/schema" ]; then
            bandit -r greenlang/schema/ -c .bandit.yml --severity-level medium || true
          fi

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-test-results
          path: junit-schema-security.xml
          if-no-files-found: ignore

  # -------------------------------------------------------------------------
  # Job 6: Coverage Check (>= 85%)
  # -------------------------------------------------------------------------
  coverage-check:
    name: Coverage Check (>= 85%)
    runs-on: ubuntu-latest
    needs: [unit-test]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -e ".[dev]" 2>/dev/null || pip install \
            pytest \
            pytest-asyncio \
            pytest-cov \
            pydantic \
            fastapi \
            httpx \
            structlog \
            prometheus-client \
            psycopg \
            redis \
            pyyaml

      - name: Run tests with coverage
        run: |
          FOUND=0
          DIRS=""
          if [ -d "tests/schema/unit" ] && [ "$(ls -A tests/schema/unit/)" ]; then
            DIRS="$DIRS tests/schema/unit/"
            FOUND=1
          fi
          if [ -d "tests/unit/schema_service" ] && [ "$(ls -A tests/unit/schema_service/)" ]; then
            DIRS="$DIRS tests/unit/schema_service/"
            FOUND=1
          fi
          if [ -d "tests/schema/integration" ] && [ "$(ls -A tests/schema/integration/)" ]; then
            DIRS="$DIRS tests/schema/integration/"
            FOUND=1
          fi
          if [ -d "tests/integration/schema_service" ] && [ "$(ls -A tests/integration/schema_service/)" ]; then
            DIRS="$DIRS tests/integration/schema_service/"
            FOUND=1
          fi
          if [ $FOUND -eq 1 ]; then
            pytest $DIRS -v --tb=short -q \
              --cov=greenlang/schema \
              --cov-report=term-missing \
              --cov-report=xml:coverage-schema.xml \
              --cov-fail-under=85
          else
            echo "WARNING: No tests found - coverage check will be enforced once tests exist"
          fi

      - name: Upload coverage
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-schema
          path: coverage-schema.xml
          if-no-files-found: ignore

  # -------------------------------------------------------------------------
  # Job 7: Docker Build
  # -------------------------------------------------------------------------
  docker-build:
    name: Docker Build
    runs-on: ubuntu-latest
    needs: [lint, type-check, unit-test]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image (no push)
        uses: docker/build-push-action@v5
        with:
          context: .
          push: false
          tags: |
            greenlang/schema-service:${{ github.sha }}
            greenlang/schema-service:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            PYTHON_VERSION=3.11
            SERVICE_NAME=schema-service

  # -------------------------------------------------------------------------
  # Job 8: Deploy to Staging (master only)
  # -------------------------------------------------------------------------
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [lint, type-check, unit-test, integration-test, security-test, coverage-check, docker-build]
    if: github.ref == 'refs/heads/master' && github.event_name == 'push'
    environment: staging
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'v1.29.0'

      - name: Configure kubectl
        run: |
          echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > kubeconfig
          export KUBECONFIG=kubeconfig

      - name: Validate Kustomize build
        run: |
          kubectl kustomize ${{ env.K8S_DIR }} > /dev/null
          echo "Kustomize build succeeded"

      - name: Apply Kubernetes manifests
        run: |
          export KUBECONFIG=kubeconfig
          kubectl apply -k ${{ env.K8S_DIR }}
          echo "Manifests applied"

      - name: Update deployment image
        run: |
          export KUBECONFIG=kubeconfig
          kubectl set image deployment/schema-service \
            schema-service=greenlang/schema-service:${{ github.sha }} \
            -n greenlang

      - name: Verify deployment rollout
        run: |
          export KUBECONFIG=kubeconfig
          kubectl rollout status deployment/schema-service -n greenlang --timeout=300s
          kubectl get pods -n greenlang -l app=schema-service

      - name: Run smoke test
        run: |
          export KUBECONFIG=kubeconfig
          POD=$(kubectl get pods -n greenlang -l app=schema-service -o jsonpath='{.items[0].metadata.name}')
          kubectl exec -n greenlang "$POD" -- curl -sf http://localhost:8080/health || {
            echo "ERROR: Health check failed after deployment"
            exit 1
          }
          echo "Smoke test passed"

  # -------------------------------------------------------------------------
  # Job: K8s Manifest Validation
  # -------------------------------------------------------------------------
  k8s-validate:
    name: K8s Manifest Validation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'v1.29.0'

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install pyyaml
        run: pip install --quiet pyyaml

      - name: Validate Kustomize build
        run: |
          if [ -f "${{ env.K8S_DIR }}/kustomization.yaml" ]; then
            kubectl kustomize ${{ env.K8S_DIR }} > /dev/null
            echo "Kustomize build succeeded"

            kubectl kustomize ${{ env.K8S_DIR }} | python3 -c "
          import sys, yaml
          docs = list(yaml.safe_load_all(sys.stdin))
          kinds = [d.get('kind', '?') for d in docs if d]
          print(f'Rendered {len(docs)} resources: {kinds}')
          required = {'Deployment', 'Service', 'ConfigMap', 'HorizontalPodAutoscaler'}
          rendered = set(kinds)
          missing = required - rendered
          if missing:
              print(f'ERROR: Missing required resource kinds: {missing}')
              sys.exit(1)
          print('All required resource kinds present')
          "
          else
            echo "WARNING: No kustomization.yaml found in ${{ env.K8S_DIR }}"
          fi

      - name: Validate resource limits and security context
        run: |
          python3 << 'PYEOF'
          import yaml
          import sys

          deployment_path = "${{ env.K8S_DIR }}/deployment.yaml"
          with open(deployment_path) as f:
              docs = list(yaml.safe_load_all(f))

          errors = []
          for doc in docs:
              if doc is None or doc.get("kind") != "Deployment":
                  continue

              containers = doc.get("spec", {}).get("template", {}).get("spec", {}).get("containers", [])
              for container in containers:
                  name = container.get("name", "unknown")
                  resources = container.get("resources", {})
                  if not resources.get("requests"):
                      errors.append(f"Container '{name}': missing resource requests")
                  if not resources.get("limits"):
                      errors.append(f"Container '{name}': missing resource limits")

                  if not container.get("livenessProbe"):
                      errors.append(f"Container '{name}': missing livenessProbe")
                  if not container.get("readinessProbe"):
                      errors.append(f"Container '{name}': missing readinessProbe")
                  if not container.get("startupProbe"):
                      errors.append(f"Container '{name}': missing startupProbe")

                  sc = container.get("securityContext", {})
                  if sc.get("allowPrivilegeEscalation") is not False:
                      errors.append(f"Container '{name}': allowPrivilegeEscalation not set to false")
                  if not sc.get("readOnlyRootFilesystem"):
                      errors.append(f"Container '{name}': readOnlyRootFilesystem not enabled")

          if errors:
              print("Deployment validation errors:")
              for e in errors:
                  print(f"  - {e}")
              sys.exit(1)

          print("Deployment validation passed")
          PYEOF

      - name: Validate NetworkPolicy completeness
        run: |
          python3 << 'PYEOF'
          import yaml
          import sys

          netpol_path = "${{ env.K8S_DIR }}/networkpolicy.yaml"
          with open(netpol_path) as f:
              docs = [d for d in yaml.safe_load_all(f) if d is not None]

          errors = []
          has_default_deny = False
          has_ingress = False
          has_egress = False

          for doc in docs:
              if doc.get("kind") != "NetworkPolicy":
                  continue
              name = doc.get("metadata", {}).get("name", "")
              spec = doc.get("spec", {})
              policy_types = spec.get("policyTypes", [])

              if "deny" in name.lower():
                  has_default_deny = True
              if "Ingress" in policy_types and spec.get("ingress"):
                  has_ingress = True
              if "Egress" in policy_types and spec.get("egress"):
                  has_egress = True

          if not has_default_deny:
              errors.append("Missing default-deny NetworkPolicy")
          if not has_ingress:
              errors.append("No ingress rules defined")
          if not has_egress:
              errors.append("No egress rules defined")

          if errors:
              print("NetworkPolicy validation errors:")
              for e in errors:
                  print(f"  - {e}")
              sys.exit(1)

          print("NetworkPolicy validation passed (default-deny + ingress + egress)")
          PYEOF

      - name: Validate SQL migration
        run: |
          python3 << 'PYEOF'
          import sys

          migration_path = "deployment/database/migrations/sql/V022__schema_service.sql"
          try:
              with open(migration_path) as f:
                  content = f.read()
          except FileNotFoundError:
              print(f"ERROR: {migration_path} not found")
              sys.exit(1)

          errors = []

          if "CREATE SCHEMA" not in content:
              errors.append("Missing CREATE SCHEMA statement")

          required_tables = [
              "schema_service.schema_registry",
              "schema_service.validation_audit_log",
              "schema_service.schema_cache_metadata",
          ]
          for table in required_tables:
              if f"CREATE TABLE {table}" not in content:
                  errors.append(f"Missing CREATE TABLE {table}")

          if "create_hypertable" not in content:
              errors.append("Missing create_hypertable call for validation_audit_log")

          if "MATERIALIZED VIEW" not in content:
              errors.append("Missing continuous aggregate (MATERIALIZED VIEW)")

          if "ROW LEVEL SECURITY" not in content:
              errors.append("Missing Row Level Security")

          if "security.permissions" not in content:
              errors.append("Missing security.permissions INSERT")

          if "add_retention_policy" not in content:
              errors.append("Missing retention policy")

          if "add_compression_policy" not in content:
              errors.append("Missing compression policy")

          if errors:
              print("SQL migration validation errors:")
              for e in errors:
                  print(f"  - {e}")
              sys.exit(1)

          print(f"SQL migration validation passed ({len(content)} bytes)")
          PYEOF

  # -------------------------------------------------------------------------
  # Job: Validate Alert Rules (promtool)
  # -------------------------------------------------------------------------
  validate-alerts:
    name: Validate Alert Rules
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install pyyaml
        run: pip install --quiet pyyaml

      - name: Extract and validate alert rules with promtool
        run: |
          # Download promtool
          PROM_VERSION="2.50.1"
          wget -q "https://github.com/prometheus/prometheus/releases/download/v${PROM_VERSION}/prometheus-${PROM_VERSION}.linux-amd64.tar.gz"
          tar xzf "prometheus-${PROM_VERSION}.linux-amd64.tar.gz"
          PROMTOOL="./prometheus-${PROM_VERSION}.linux-amd64/promtool"

          ERRORS=0
          CHECKED=0

          for f in ${{ env.ALERTS_DIR }}/schema-*.yaml; do
            [ -e "$f" ] || continue
            CHECKED=$((CHECKED + 1))

            python3 -c "
          import yaml, sys
          with open('$f') as fh:
              doc = yaml.safe_load(fh)
          if doc and 'spec' in doc and 'groups' in doc['spec']:
              rules = {'groups': doc['spec']['groups']}
              with open('/tmp/alerts_check.yml', 'w') as out:
                  yaml.dump(rules, out, default_flow_style=False)
          else:
              print('No spec.groups found, skipping')
              sys.exit(0)
          "

            if [ -f /tmp/alerts_check.yml ]; then
              if ! $PROMTOOL check rules /tmp/alerts_check.yml; then
                echo "ERROR: promtool check failed for $f"
                ERRORS=$((ERRORS + 1))
              fi
              rm -f /tmp/alerts_check.yml
            fi
          done

          if [ $ERRORS -gt 0 ]; then
            echo "Found $ERRORS files with invalid alert rules"
            exit 1
          fi

          echo "All $CHECKED alert rules files validated successfully"

      - name: Validate alert rules have required labels and annotations
        run: |
          python3 << 'PYEOF'
          import yaml
          import glob
          import sys

          REQUIRED_LABELS = ["severity", "team", "component", "prd"]
          REQUIRED_ANNOTATIONS = ["summary", "description", "runbook_url", "dashboard_url"]

          errors = []
          checked = 0

          for path in sorted(glob.glob("${{ env.ALERTS_DIR }}/schema-*.yaml")):
              with open(path) as f:
                  try:
                      docs = list(yaml.safe_load_all(f))
                  except yaml.YAMLError:
                      continue

              for doc in docs:
                  if doc is None:
                      continue
                  groups = doc.get("spec", {}).get("groups", doc.get("groups", []))
                  for group in groups:
                      for rule in group.get("rules", []):
                          if "alert" not in rule:
                              continue
                          checked += 1
                          alert_name = rule["alert"]
                          labels = rule.get("labels", {})
                          annotations = rule.get("annotations", {})

                          for label in REQUIRED_LABELS:
                              if label not in labels:
                                  errors.append(f"{path}: Alert '{alert_name}' missing label '{label}'")

                          for ann in REQUIRED_ANNOTATIONS:
                              if ann not in annotations:
                                  errors.append(f"{path}: Alert '{alert_name}' missing annotation '{ann}'")

          if errors:
              print("Alert rule validation errors:")
              for e in errors:
                  print(f"  - {e}")
              sys.exit(1)

          print(f"All {checked} alert rules have required labels and annotations")
          PYEOF
