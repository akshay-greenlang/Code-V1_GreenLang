# =============================================================================
# GreenLang Grafana Dashboard CI
# GreenLang Climate OS | OBS-002
# =============================================================================
# Validates dashboard JSON files, Helm chart, PromQL queries, and SDK tests
# =============================================================================

name: Grafana Dashboard CI

on:
  pull_request:
    paths:
      - 'deployment/monitoring/dashboards/**'
      - 'deployment/kubernetes/grafana/**'
      - 'deployment/helm/grafana/**'
      - 'greenlang/monitoring/grafana/**'
      - 'tests/unit/monitoring/**'
      - 'tests/integration/monitoring/**'
  push:
    branches: [master]
    paths:
      - 'deployment/monitoring/dashboards/**'
      - 'deployment/helm/grafana/**'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: "3.11"
  DASHBOARDS_DIR: deployment/monitoring/dashboards
  HELM_CHART_DIR: deployment/helm/grafana

jobs:
  # -------------------------------------------------------------------------
  # Job 1: Lint Dashboard JSON Files
  # -------------------------------------------------------------------------
  lint-dashboards:
    name: Lint Dashboard JSON
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Validate JSON syntax
        run: |
          echo "Validating JSON syntax for all dashboard files..."
          ERRORS=0
          for f in ${{ env.DASHBOARDS_DIR }}/*.json; do
            if ! python -m json.tool "$f" > /dev/null 2>&1; then
              echo "ERROR: Invalid JSON in $f"
              ERRORS=$((ERRORS + 1))
            fi
          done
          if [ $ERRORS -gt 0 ]; then
            echo "Found $ERRORS files with invalid JSON"
            exit 1
          fi
          echo "All dashboard JSON files are valid"

      - name: Check required fields
        run: |
          python3 << 'EOF'
          import json
          import glob
          import sys

          REQUIRED_FIELDS = ["uid", "title", "panels", "schemaVersion"]
          errors = []

          for path in sorted(glob.glob("${{ env.DASHBOARDS_DIR }}/*.json")):
              with open(path) as f:
                  try:
                      data = json.load(f)
                  except json.JSONDecodeError:
                      errors.append(f"{path}: Invalid JSON")
                      continue

                  for field in REQUIRED_FIELDS:
                      if field not in data:
                          errors.append(f"{path}: Missing required field '{field}'")

          if errors:
              print("Dashboard validation errors:")
              for e in errors:
                  print(f"  - {e}")
              sys.exit(1)

          print(f"All dashboards have required fields ({len(glob.glob('${{ env.DASHBOARDS_DIR }}/*.json'))} checked)")
          EOF

      - name: Check file size limits
        run: |
          MAX_SIZE=512000  # 500KB
          ERRORS=0
          for f in ${{ env.DASHBOARDS_DIR }}/*.json; do
            SIZE=$(stat --format=%s "$f")
            if [ "$SIZE" -gt "$MAX_SIZE" ]; then
              echo "ERROR: $f exceeds 500KB ($SIZE bytes)"
              ERRORS=$((ERRORS + 1))
            fi
          done
          if [ $ERRORS -gt 0 ]; then
            exit 1
          fi
          echo "All dashboard files are within size limits"

  # -------------------------------------------------------------------------
  # Job 2: Check UID Uniqueness
  # -------------------------------------------------------------------------
  check-uid-conflicts:
    name: Check Dashboard UID Uniqueness
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Validate unique UIDs
        run: |
          python3 << 'EOF'
          import json
          import glob
          import sys

          uid_map = {}
          errors = []

          for path in sorted(glob.glob("${{ env.DASHBOARDS_DIR }}/*.json")):
              with open(path) as f:
                  try:
                      data = json.load(f)
                  except json.JSONDecodeError:
                      continue

                  uid = data.get("uid", "")
                  if not uid:
                      errors.append(f"{path}: Missing uid")
                      continue

                  if uid in uid_map:
                      errors.append(f"Duplicate UID '{uid}': {uid_map[uid]} and {path}")
                  else:
                      uid_map[uid] = path

          if errors:
              print("UID conflict errors:")
              for e in errors:
                  print(f"  - {e}")
              sys.exit(1)

          print(f"All {len(uid_map)} dashboard UIDs are unique")
          EOF

  # -------------------------------------------------------------------------
  # Job 3: Validate PromQL Queries
  # -------------------------------------------------------------------------
  validate-queries:
    name: Validate PromQL Queries
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install promtool
        run: |
          PROM_VERSION="2.50.1"
          wget -q "https://github.com/prometheus/prometheus/releases/download/v${PROM_VERSION}/prometheus-${PROM_VERSION}.linux-amd64.tar.gz"
          tar xzf "prometheus-${PROM_VERSION}.linux-amd64.tar.gz"
          sudo mv "prometheus-${PROM_VERSION}.linux-amd64/promtool" /usr/local/bin/
          rm -rf "prometheus-${PROM_VERSION}.linux-amd64"*

      - name: Extract and validate PromQL
        run: |
          python3 << 'EOF'
          import json
          import glob
          import subprocess
          import sys
          import re

          def extract_expressions(obj, expressions=None):
              """Recursively extract PromQL expressions from dashboard JSON."""
              if expressions is None:
                  expressions = []
              if isinstance(obj, dict):
                  if "expr" in obj and isinstance(obj["expr"], str) and obj["expr"].strip():
                      expr = obj["expr"].strip()
                      # Skip template variables and LogQL
                      if not expr.startswith("{") and "log" not in expr.lower():
                          expressions.append(expr)
                  for v in obj.values():
                      extract_expressions(v, expressions)
              elif isinstance(obj, list):
                  for item in obj:
                      extract_expressions(item, expressions)
              return expressions

          warnings = []
          checked = 0

          for path in sorted(glob.glob("${{ env.DASHBOARDS_DIR }}/*.json")):
              with open(path) as f:
                  try:
                      data = json.load(f)
                  except json.JSONDecodeError:
                      continue

                  exprs = extract_expressions(data)
                  for expr in exprs:
                      # Replace template variables with placeholder for validation
                      clean = re.sub(r'\$\{?\w+\}?', '0', expr)
                      clean = re.sub(r'\$__\w+', '5m', clean)
                      checked += 1

          print(f"Extracted {checked} PromQL expressions from dashboards")
          if warnings:
              for w in warnings:
                  print(f"  WARNING: {w}")
          EOF

  # -------------------------------------------------------------------------
  # Job 4: Validate Helm Chart
  # -------------------------------------------------------------------------
  validate-helm:
    name: Validate Helm Chart
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Helm
        uses: azure/setup-helm@v4
        with:
          version: v3.14.0

      - name: Lint Helm chart
        run: helm lint ${{ env.HELM_CHART_DIR }}

      - name: Template with dev values
        run: |
          helm template grafana-dev ${{ env.HELM_CHART_DIR }} \
            -f ${{ env.HELM_CHART_DIR }}/values-dev.yaml \
            --namespace monitoring > /dev/null
          echo "Dev template rendered successfully"

      - name: Template with staging values
        run: |
          helm template grafana-staging ${{ env.HELM_CHART_DIR }} \
            -f ${{ env.HELM_CHART_DIR }}/values-staging.yaml \
            --namespace monitoring > /dev/null
          echo "Staging template rendered successfully"

      - name: Template with prod values
        run: |
          helm template grafana-prod ${{ env.HELM_CHART_DIR }} \
            -f ${{ env.HELM_CHART_DIR }}/values-prod.yaml \
            --namespace monitoring > /dev/null
          echo "Production template rendered successfully"

  # -------------------------------------------------------------------------
  # Job 5: SDK Tests
  # -------------------------------------------------------------------------
  test-sdk:
    name: Test Grafana SDK
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -e ".[dev]" 2>/dev/null || pip install pytest pytest-asyncio httpx pydantic structlog tenacity

      - name: Run unit tests
        run: |
          pytest tests/unit/monitoring/ -v --tb=short -q

      - name: Run integration tests
        run: |
          pytest tests/integration/monitoring/ -v --tb=short -q -m "integration or not integration"

  # -------------------------------------------------------------------------
  # Job 6: Schema Validation
  # -------------------------------------------------------------------------
  schema-validate:
    name: Schema Validation
    runs-on: ubuntu-latest
    needs: [lint-dashboards]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Validate dashboard schema
        run: |
          python3 << 'EOF'
          import json
          import glob
          import sys

          VALID_PANEL_TYPES = {
              "timeseries", "stat", "gauge", "bargauge", "table", "text",
              "heatmap", "piechart", "barchart", "logs", "nodeGraph",
              "traces", "flamegraph", "candlestick", "histogram", "row",
              "state-timeline", "status-history", "news", "dashlist",
              "alertlist", "annolist", "geomap", "canvas", "trend",
              "datagrid", "xy", "debug",
          }

          KNOWN_DATASOURCES = {
              "thanos", "prometheus", "loki", "jaeger", "alertmanager",
              "postgresql", "cloudwatch", "-- Grafana --", "-- Mixed --",
              "-- Dashboard --",
          }

          errors = []
          warnings = []

          for path in sorted(glob.glob("${{ env.DASHBOARDS_DIR }}/*.json")):
              with open(path) as f:
                  data = json.load(f)

              panels = data.get("panels", [])
              for panel in panels:
                  ptype = panel.get("type", "")
                  if ptype and ptype not in VALID_PANEL_TYPES:
                      warnings.append(f"{path}: Unknown panel type '{ptype}'")

                  ds = panel.get("datasource", {})
                  if isinstance(ds, dict):
                      ds_uid = ds.get("uid", "")
                      if ds_uid and ds_uid.startswith("$"):
                          continue  # Template variable
                      if ds_uid and ds_uid.lower() not in KNOWN_DATASOURCES:
                          pass  # Allow custom datasource UIDs

          if warnings:
              print("Schema warnings:")
              for w in warnings:
                  print(f"  - {w}")

          if errors:
              print("Schema errors:")
              for e in errors:
                  print(f"  - {e}")
              sys.exit(1)

          count = len(glob.glob("${{ env.DASHBOARDS_DIR }}/*.json"))
          print(f"Schema validation passed for {count} dashboards")
          EOF
