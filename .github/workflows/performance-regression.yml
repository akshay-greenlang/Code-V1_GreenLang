name: Performance Regression Testing

on:
  pull_request:
    branches: [main, master]
  push:
    branches: [main, master]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM

jobs:
  benchmark:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: greenlang_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for comparison

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -e .
          pip install pytest pytest-benchmark pytest-asyncio pytest-cov
          pip install psutil memory_profiler

      - name: Download baseline benchmarks
        uses: actions/cache@v3
        with:
          path: benchmarks/baselines
          key: benchmark-baseline-${{ github.base_ref || 'main' }}
          restore-keys: |
            benchmark-baseline-

      - name: Run infrastructure benchmarks
        run: |
          pytest benchmarks/infrastructure/test_benchmarks.py \
            --benchmark-only \
            --benchmark-json=benchmarks/results/infrastructure.json \
            --benchmark-min-rounds=5 \
            -v

      - name: Run application benchmarks
        run: |
          pytest benchmarks/applications/test_app_benchmarks.py \
            --benchmark-only \
            --benchmark-json=benchmarks/results/applications.json \
            --benchmark-min-rounds=3 \
            -v

      - name: Compare against baseline
        id: compare
        run: |
          python tools/benchmarking/compare_benchmarks.py \
            --current benchmarks/results/infrastructure.json \
            --baseline benchmarks/baselines/infrastructure.json \
            --threshold 10 \
            --output benchmarks/results/comparison.md

      - name: Check for regressions
        run: |
          python tools/benchmarking/check_regressions.py \
            --comparison benchmarks/results/comparison.md \
            --max-regression 10

      - name: Generate performance report
        if: always()
        run: |
          python tools/reporting/generate_performance_report.py \
            --results-dir benchmarks/results \
            --output performance_report.md

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-results
          path: |
            benchmarks/results/
            performance_report.md

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('performance_report.md', 'utf8');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });

      - name: Fail on significant regression
        if: failure()
        run: |
          echo "Performance regression detected!"
          echo "Review the benchmark results and comparison report."
          exit 1

      - name: Update baseline (on main branch)
        if: github.ref == 'refs/heads/main' && success()
        run: |
          mkdir -p benchmarks/baselines
          cp benchmarks/results/infrastructure.json benchmarks/baselines/
          cp benchmarks/results/applications.json benchmarks/baselines/

      - name: Upload new baseline
        if: github.ref == 'refs/heads/main' && success()
        uses: actions/cache@v3
        with:
          path: benchmarks/baselines
          key: benchmark-baseline-main-${{ github.sha }}

  memory-profiling:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -e .
          pip install memory_profiler psutil

      - name: Run memory profiling
        run: |
          python tools/profiling/profile_memory.py \
            --script benchmarks/memory_test.py \
            --leak-detection \
            --report

      - name: Check for memory leaks
        run: |
          python tools/profiling/check_memory_leaks.py \
            --report profiles/memory_report.html \
            --threshold 50  # Max 50MB growth

      - name: Upload memory profile
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: memory-profile
          path: profiles/memory_report.html

  cost-analysis:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -e .

      - name: Analyze LLM costs
        run: |
          python tools/profiling/analyze_llm_costs.py \
            --test-scenarios benchmarks/llm_test_scenarios.json \
            --report

      - name: Check cost regression
        run: |
          python tools/benchmarking/check_cost_regression.py \
            --current profiles/llm_cost_report.html \
            --threshold 20  # Max 20% cost increase

      - name: Upload cost analysis
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: cost-analysis
          path: profiles/llm_cost_report.html
