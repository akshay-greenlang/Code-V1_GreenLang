# -*- coding: utf-8 -*-
"""
Unit tests for GL-007 Performance Anomaly Detection

Tests the detect_performance_anomalies tool with comprehensive coverage:
- Statistical process control (SPC)
- Pattern recognition
- Multi-parameter anomaly detection
- Root cause analysis
- False positive rate validation

Target Coverage: 90%+
Target: 95% detection rate, <5% false positive rate
"""

import pytest
import json
from pathlib import Path
from datetime import datetime, timedelta
from unittest.mock import Mock, patch
import numpy as np
from greenlang.determinism import DeterministicClock


FIXTURES_DIR = Path(__file__).parent.parent / "fixtures"


class TestPerformanceAnomalyDetection:
    """Test suite for performance anomaly detection."""

    def test_detect_temperature_spike(self, sample_historical_baseline):
        """Test detection of sudden temperature spike."""
        real_time_data = {
            "timestamp": DeterministicClock.now().isoformat(),
            "temperatures": [185.0, 188.0, 245.0, 242.0],  # Spike to 245Â°C
            "pressures": [-25.0, -24.5, -23.0, -22.5],
            "flows": [1850.0, 1860.0, 1855.0, 1858.0],
            "emissions": {
                "nox_ppm": 45.0,
                "co_ppm": 18.0,
                "o2_percent": 3.5
            },
            "efficiency": 73.5,
            "production_rate": 18.5
        }

        result = self._detect_anomalies(real_time_data, sample_historical_baseline)

        # Should detect temperature anomaly
        assert len(result["anomalies_detected"]) > 0

        # Find temperature anomaly
        temp_anomalies = [a for a in result["anomalies_detected"] if "temp" in a["parameter"].lower()]
        assert len(temp_anomalies) > 0

        # Verify severity
        temp_anomaly = temp_anomalies[0]
        assert temp_anomaly["severity"] in ["high", "critical"]
        assert temp_anomaly["anomaly_type"] == "spike"

    def test_detect_efficiency_degradation(self, sample_historical_baseline):
        """Test detection of gradual efficiency degradation."""
        real_time_data = {
            "timestamp": DeterministicClock.now().isoformat(),
            "temperatures": [195.0, 198.0, 200.0, 202.0],
            "pressures": [-25.0, -25.0, -25.0, -25.0],
            "flows": [1850.0, 1850.0, 1850.0, 1850.0],
            "emissions": {
                "nox_ppm": 48.0,
                "co_ppm": 22.0,
                "o2_percent": 4.2
            },
            "efficiency": 76.8,  # Below baseline of 81.5%
            "production_rate": 18.5
        }

        result = self._detect_anomalies(real_time_data, sample_historical_baseline)

        # Should detect efficiency anomaly
        efficiency_anomalies = [a for a in result["anomalies_detected"] if "efficiency" in a["parameter"].lower()]
        assert len(efficiency_anomalies) > 0

        # Check severity and type
        eff_anomaly = efficiency_anomalies[0]
        assert eff_anomaly["anomaly_type"] in ["drift", "step_change"]
        assert eff_anomaly["severity"] in ["medium", "high"]

    def test_detect_co_emissions_spike(self, sample_historical_baseline):
        """Test detection of dangerous CO emissions spike."""
        real_time_data = {
            "timestamp": DeterministicClock.now().isoformat(),
            "temperatures": [185.0, 185.0, 185.0, 185.0],
            "pressures": [-25.0, -25.0, -25.0, -25.0],
            "flows": [1850.0, 1850.0, 1850.0, 1850.0],
            "emissions": {
                "nox_ppm": 45.0,
                "co_ppm": 85.0,  # Dangerously high CO
                "o2_percent": 3.5
            },
            "efficiency": 81.0,
            "production_rate": 18.5
        }

        result = self._detect_anomalies(real_time_data, sample_historical_baseline)

        # Should detect CO anomaly with CRITICAL severity
        co_anomalies = [a for a in result["anomalies_detected"] if "co" in a["parameter"].lower()]
        assert len(co_anomalies) > 0

        co_anomaly = co_anomalies[0]
        assert co_anomaly["severity"] == "critical"
        assert "combustion" in str(co_anomaly["probable_causes"]).lower()

    def test_no_anomalies_normal_operation(self, sample_historical_baseline):
        """Test that normal operation does not trigger false positives."""
        # All values within normal range
        real_time_data = {
            "timestamp": DeterministicClock.now().isoformat(),
            "temperatures": [185.0, 186.0, 184.0, 185.5],
            "pressures": [-25.0, -24.8, -25.2, -25.0],
            "flows": [1850.0, 1855.0, 1848.0, 1852.0],
            "emissions": {
                "nox_ppm": 45.0,
                "co_ppm": 18.0,
                "o2_percent": 3.5
            },
            "efficiency": 81.5,
            "production_rate": 18.5
        }

        result = self._detect_anomalies(real_time_data, sample_historical_baseline)

        # Should NOT detect anomalies
        assert len(result["anomalies_detected"]) == 0

    def test_multiple_simultaneous_anomalies(self, sample_historical_baseline):
        """Test detection of multiple simultaneous anomalies."""
        real_time_data = {
            "timestamp": DeterministicClock.now().isoformat(),
            "temperatures": [265.0, 268.0, 270.0, 272.0],  # High temp
            "pressures": [-15.0, -14.5, -14.0, -13.5],  # High pressure
            "flows": [1650.0, 1640.0, 1630.0, 1620.0],  # Low flow
            "emissions": {
                "nox_ppm": 125.0,  # High NOx
                "co_ppm": 95.0,  # High CO
                "o2_percent": 7.5  # High O2
            },
            "efficiency": 65.5,  # Low efficiency
            "production_rate": 15.2  # Low production
        }

        result = self._detect_anomalies(real_time_data, sample_historical_baseline)

        # Should detect multiple anomalies
        assert len(result["anomalies_detected"]) >= 3

        # Should have critical severity for at least one
        severities = [a["severity"] for a in result["anomalies_detected"]]
        assert "critical" in severities

    def test_root_cause_analysis(self, sample_historical_baseline):
        """Test root cause analysis provides meaningful diagnosis."""
        real_time_data = {
            "timestamp": DeterministicClock.now().isoformat(),
            "temperatures": [245.0, 242.0, 244.0, 243.0],
            "pressures": [-25.0, -25.0, -25.0, -25.0],
            "flows": [1850.0, 1850.0, 1850.0, 1850.0],
            "emissions": {
                "nox_ppm": 48.0,
                "co_ppm": 22.0,
                "o2_percent": 4.2
            },
            "efficiency": 75.0,
            "production_rate": 18.5
        }

        result = self._detect_anomalies(real_time_data, sample_historical_baseline)

        # Should provide root cause analysis
        assert "root_cause_analysis" in result
        assert "primary_cause" in result["root_cause_analysis"]
        assert "contributing_factors" in result["root_cause_analysis"]
        assert "corrective_actions" in result["root_cause_analysis"]

        # Root cause should be meaningful
        assert result["root_cause_analysis"]["primary_cause"] != ""

    def test_performance_impact_quantification(self, sample_historical_baseline):
        """Test performance impact is quantified."""
        real_time_data = {
            "timestamp": DeterministicClock.now().isoformat(),
            "temperatures": [220.0, 222.0, 224.0, 223.0],
            "pressures": [-25.0, -25.0, -25.0, -25.0],
            "flows": [1850.0, 1850.0, 1850.0, 1850.0],
            "emissions": {
                "nox_ppm": 55.0,
                "co_ppm": 25.0,
                "o2_percent": 5.0
            },
            "efficiency": 77.0,
            "production_rate": 18.5
        }

        result = self._detect_anomalies(real_time_data, sample_historical_baseline)

        # Should quantify impact
        assert "performance_impact" in result
        impact = result["performance_impact"]

        assert "efficiency_loss_percent" in impact
        assert "energy_waste_mwh" in impact
        assert "cost_impact_usd" in impact
        assert "emissions_impact_kg_co2" in impact

        # Impacts should be non-negative
        assert impact["efficiency_loss_percent"] >= 0
        assert impact["energy_waste_mwh"] >= 0
        assert impact["cost_impact_usd"] >= 0

    @pytest.mark.parametrize("z_threshold,expected_sensitivity", [
        (2.0, "high"),  # More sensitive
        (2.5, "medium"),  # Standard
        (3.0, "low"),  # Less sensitive
    ])
    def test_detection_sensitivity_tuning(
        self,
        sample_historical_baseline,
        z_threshold,
        expected_sensitivity
    ):
        """Test detection sensitivity can be tuned."""
        real_time_data = {
            "timestamp": DeterministicClock.now().isoformat(),
            "temperatures": [205.0, 207.0, 206.0, 208.0],  # Moderate deviation
            "pressures": [-25.0, -25.0, -25.0, -25.0],
            "flows": [1850.0, 1850.0, 1850.0, 1850.0],
            "emissions": {
                "nox_ppm": 52.0,
                "co_ppm": 20.0,
                "o2_percent": 4.0
            },
            "efficiency": 80.0,
            "production_rate": 18.5
        }

        detection_sensitivity = {
            "z_score_threshold": z_threshold,
            "moving_average_window": 20,
            "min_duration_seconds": 60,
        }

        result = self._detect_anomalies(
            real_time_data,
            sample_historical_baseline,
            detection_sensitivity
        )

        # Lower threshold should detect more anomalies
        # This is a basic check - actual behavior depends on implementation

    def test_oscillation_detection(self, sample_historical_baseline):
        """Test detection of oscillating parameter (control instability)."""
        # Simulate oscillating CO readings
        real_time_data = {
            "timestamp": DeterministicClock.now().isoformat(),
            "temperatures": [185.0, 185.0, 185.0, 185.0],
            "pressures": [-25.0, -25.0, -25.0, -25.0],
            "flows": [1850.0, 1850.0, 1850.0, 1850.0],
            "emissions": {
                "nox_ppm": 45.0,
                "co_ppm": 30.0,  # Oscillating value
                "o2_percent": 3.5
            },
            "efficiency": 81.0,
            "production_rate": 18.5,
            "oscillation_detected": True  # Signal for testing
        }

        result = self._detect_anomalies(real_time_data, sample_historical_baseline)

        # May detect oscillation pattern
        anomaly_types = [a["anomaly_type"] for a in result["anomalies_detected"]]

        # Either oscillation or out_of_range
        if result["anomalies_detected"]:
            assert any(t in ["oscillation", "out_of_range"] for t in anomaly_types)

    def test_load_fixture_test_cases(self):
        """Test using fixture test cases from JSON."""
        test_cases_file = FIXTURES_DIR / "anomaly_detection_test_cases.json"

        if test_cases_file.exists():
            with open(test_cases_file, 'r') as f:
                test_data = json.load(f)

            baseline = {
                "mean_values": {
                    "efficiency": 81.5,
                    "stack_temp_c": 185.0,
                    "o2_percent": 3.5,
                    "nox_ppm": 45.0,
                    "co_ppm": 18.0,
                },
                "standard_deviations": {
                    "efficiency": 1.2,
                    "stack_temp_c": 8.5,
                    "o2_percent": 0.5,
                    "nox_ppm": 5.0,
                    "co_ppm": 3.0,
                },
                "control_limits_upper": {
                    "efficiency": 84.0,
                    "stack_temp_c": 210.0,
                    "o2_percent": 5.0,
                    "nox_ppm": 60.0,
                    "co_ppm": 30.0,
                },
                "control_limits_lower": {
                    "efficiency": 79.0,
                    "stack_temp_c": 160.0,
                    "o2_percent": 2.0,
                    "nox_ppm": 30.0,
                    "co_ppm": 8.0,
                },
            }

            for case in test_data["test_cases"]:
                result = self._detect_anomalies(case["real_time_data"], baseline)

                expected_count = len(case["expected_anomalies"])

                if expected_count == 0:
                    # Should not detect anomalies
                    assert len(result["anomalies_detected"]) == 0, \
                        f"Case {case['case_id']}: False positive detected"
                else:
                    # Should detect anomalies
                    assert len(result["anomalies_detected"]) > 0, \
                        f"Case {case['case_id']}: Failed to detect anomaly"

    @pytest.mark.performance
    def test_detection_performance(self, sample_historical_baseline, benchmark):
        """Test detection meets performance target (<80ms)."""
        real_time_data = {
            "timestamp": DeterministicClock.now().isoformat(),
            "temperatures": [185.0, 186.0, 184.0, 185.5],
            "pressures": [-25.0, -24.8, -25.2, -25.0],
            "flows": [1850.0, 1855.0, 1848.0, 1852.0],
            "emissions": {
                "nox_ppm": 45.0,
                "co_ppm": 18.0,
                "o2_percent": 3.5
            },
            "efficiency": 81.5,
            "production_rate": 18.5
        }

        def run_detection():
            return self._detect_anomalies(real_time_data, sample_historical_baseline)

        result = benchmark(run_detection)

    def test_invalid_input_missing_baseline(self):
        """Test error handling for missing baseline data."""
        real_time_data = {
            "timestamp": DeterministicClock.now().isoformat(),
            "efficiency": 81.5,
        }

        with pytest.raises(ValueError):
            self._detect_anomalies(real_time_data, {})

    # ========================================================================
    # HELPER METHODS (Mock implementation)
    # ========================================================================

    def _detect_anomalies(
        self,
        real_time_data: dict,
        historical_baseline: dict,
        detection_sensitivity: dict = None
    ) -> dict:
        """Mock implementation of anomaly detection."""
        if not historical_baseline:
            raise ValueError("Historical baseline is required")

        if detection_sensitivity is None:
            detection_sensitivity = {
                "z_score_threshold": 2.5,
                "moving_average_window": 20,
                "min_duration_seconds": 60,
            }

        anomalies = []

        # Check efficiency
        if "efficiency" in real_time_data:
            eff = real_time_data["efficiency"]
            baseline_eff = historical_baseline["mean_values"]["efficiency"]
            std_eff = historical_baseline["standard_deviations"]["efficiency"]

            z_score = abs((eff - baseline_eff) / std_eff)

            if z_score > detection_sensitivity["z_score_threshold"]:
                severity = "critical" if z_score > 4 else "high" if z_score > 3 else "medium"
                anomalies.append({
                    "anomaly_id": f"ANO-{DeterministicClock.now().strftime('%Y%m%d%H%M%S')}-001",
                    "parameter": "thermal_efficiency",
                    "detection_time": DeterministicClock.now().isoformat(),
                    "anomaly_type": "drift" if eff < baseline_eff else "spike",
                    "severity": severity,
                    "deviation_magnitude": abs(eff - baseline_eff),
                    "statistical_significance": z_score,
                    "duration_seconds": 120.0,
                    "probable_causes": ["tube_fouling", "excess_air", "air_infiltration"],
                    "recommended_actions": ["inspect_heat_transfer_surfaces", "check_oxygen_trim", "seal_air_leaks"],
                })

        # Check temperatures
        if "temperatures" in real_time_data:
            temps = real_time_data["temperatures"]
            baseline_temp = historical_baseline["mean_values"]["stack_temp_c"]
            std_temp = historical_baseline["standard_deviations"]["stack_temp_c"]

            max_temp = max(temps)
            z_score = abs((max_temp - baseline_temp) / std_temp)

            if z_score > detection_sensitivity["z_score_threshold"]:
                severity = "critical" if z_score > 4 else "high" if z_score > 3 else "medium"
                anomalies.append({
                    "anomaly_id": f"ANO-{DeterministicClock.now().strftime('%Y%m%d%H%M%S')}-002",
                    "parameter": "flue_gas_temperature",
                    "detection_time": DeterministicClock.now().isoformat(),
                    "anomaly_type": "spike",
                    "severity": severity,
                    "deviation_magnitude": abs(max_temp - baseline_temp),
                    "statistical_significance": z_score,
                    "duration_seconds": 180.0,
                    "probable_causes": ["burner_malfunction", "control_valve_failure", "fouling"],
                    "recommended_actions": ["inspect_burners", "check_control_system", "clean_surfaces"],
                })

        # Check CO emissions
        if "emissions" in real_time_data and "co_ppm" in real_time_data["emissions"]:
            co = real_time_data["emissions"]["co_ppm"]
            baseline_co = historical_baseline["mean_values"]["co_ppm"]
            std_co = historical_baseline["standard_deviations"]["co_ppm"]

            z_score = abs((co - baseline_co) / std_co)

            if z_score > detection_sensitivity["z_score_threshold"] or co > 50:
                severity = "critical" if co > 80 or z_score > 4 else "high"
                anomalies.append({
                    "anomaly_id": f"ANO-{DeterministicClock.now().strftime('%Y%m%d%H%M%S')}-003",
                    "parameter": "co_emissions",
                    "detection_time": DeterministicClock.now().isoformat(),
                    "anomaly_type": "out_of_range",
                    "severity": severity,
                    "deviation_magnitude": abs(co - baseline_co),
                    "statistical_significance": z_score,
                    "duration_seconds": 90.0,
                    "probable_causes": ["incomplete_combustion", "fuel_air_ratio_imbalance", "burner_degradation"],
                    "recommended_actions": ["adjust_air_fuel_ratio", "inspect_burners", "check_fuel_quality"],
                })

        # Root cause analysis
        root_cause = self._analyze_root_cause(anomalies)

        # Performance impact
        impact = self._calculate_impact(anomalies, real_time_data, historical_baseline)

        return {
            "anomalies_detected": anomalies,
            "root_cause_analysis": root_cause,
            "performance_impact": impact,
        }

    def _analyze_root_cause(self, anomalies: list) -> dict:
        """Analyze root cause from detected anomalies."""
        if not anomalies:
            return {
                "primary_cause": "none",
                "contributing_factors": [],
                "confidence_level": 1.0,
                "similar_historical_events": [],
                "corrective_actions": [],
            }

        # Simple logic for demo
        primary_cause = "furnace_performance_degradation"
        if any("temp" in a["parameter"] for a in anomalies):
            primary_cause = "heat_transfer_degradation"
        if any("co" in a["parameter"].lower() for a in anomalies):
            primary_cause = "combustion_instability"

        return {
            "primary_cause": primary_cause,
            "contributing_factors": ["fouling", "excess_air", "aging_equipment"],
            "confidence_level": 0.85,
            "similar_historical_events": [],
            "corrective_actions": ["clean_heat_transfer_surfaces", "optimize_combustion", "schedule_maintenance"],
        }

    def _calculate_impact(self, anomalies: list, real_time_data: dict, baseline: dict) -> dict:
        """Calculate performance impact of anomalies."""
        baseline_eff = baseline["mean_values"]["efficiency"]
        current_eff = real_time_data.get("efficiency", baseline_eff)

        efficiency_loss = max(0, baseline_eff - current_eff)
        energy_waste = efficiency_loss * 0.5  # MWh (simplified)
        cost_impact = energy_waste * 50  # USD (simplified)
        emissions_impact = energy_waste * 500  # kg CO2 (simplified)

        return {
            "efficiency_loss_percent": efficiency_loss,
            "energy_waste_mwh": energy_waste,
            "cost_impact_usd": cost_impact,
            "emissions_impact_kg_co2": emissions_impact,
            "production_impact_percent": 0.0,
        }
