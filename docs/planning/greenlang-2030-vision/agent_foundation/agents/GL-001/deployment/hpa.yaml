# GL-001 ProcessHeatOrchestrator - Horizontal Pod Autoscaler
# Intelligent autoscaling based on CPU, memory, and custom business metrics
# Maintains 3-10 pods in production, scales based on thermal efficiency workload

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: gl-001-process-heat-hpa
  namespace: greenlang
  labels:
    app: gl-001-process-heat
    agent: "GL-001"
    version: "1.0.0"
    component: "autoscaling"
  annotations:
    description: "Horizontal Pod Autoscaler for GL-001 ProcessHeatOrchestrator"
    autoscaling.alpha.kubernetes.io/metrics: '[{"type":"Resource","resource":{"name":"cpu","target":{"type":"Utilization","averageUtilization":70}}},{"type":"Resource","resource":{"name":"memory","target":{"type":"Utilization","averageUtilization":80}}}]'

spec:
  # Target the GL-001 deployment
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: gl-001-process-heat

  # Replica bounds
  minReplicas: 3   # Minimum 3 pods for high availability
  maxReplicas: 10  # Maximum 10 pods for cost control

  # Scaling metrics (multiple metrics = OR logic, any trigger causes scaling)
  metrics:
    # ========================================================================
    # RESOURCE METRICS
    # ========================================================================
    # Scale on CPU utilization
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70  # Target 70% average CPU across all pods

    # Scale on memory utilization
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80  # Target 80% average memory across all pods

    # ========================================================================
    # CUSTOM METRICS (requires Prometheus Adapter or custom metrics API)
    # ========================================================================
    # Scale based on request rate
    - type: Pods
      pods:
        metric:
          name: http_requests_per_second
        target:
          type: AverageValue
          averageValue: "100"  # 100 req/s per pod

    # Scale based on optimization queue depth
    - type: Pods
      pods:
        metric:
          name: optimization_queue_depth
        target:
          type: AverageValue
          averageValue: "10"  # 10 pending optimizations per pod

    # Scale based on agent coordination load
    - type: Pods
      pods:
        metric:
          name: active_agent_tasks
        target:
          type: AverageValue
          averageValue: "50"  # 50 active tasks per pod

    # ========================================================================
    # OBJECT METRICS (scale based on external objects)
    # ========================================================================
    # Scale based on Ingress request rate
    - type: Object
      object:
        metric:
          name: requests-per-second
        describedObject:
          apiVersion: networking.k8s.io/v1
          kind: Ingress
          name: gl-001-process-heat-ingress
        target:
          type: Value
          value: "1000"  # Total 1000 req/s across all pods

  # ============================================================================
  # SCALING BEHAVIOR
  # ============================================================================
  behavior:
    # Scale UP behavior (aggressive for handling load spikes)
    scaleUp:
      # Stabilization window - wait before consecutive scale-ups
      stabilizationWindowSeconds: 30  # 30 seconds (quick response)

      # Scaling policies (multiple policies, selectPolicy determines which is used)
      policies:
        # Policy 1: Scale up by 100% (double the pods)
        - type: Percent
          value: 100
          periodSeconds: 30

        # Policy 2: Scale up by 2 pods
        - type: Pods
          value: 2
          periodSeconds: 60

        # Policy 3: Scale up by 4 pods for emergency spike
        - type: Pods
          value: 4
          periodSeconds: 30

      # Select the policy that scales up the most
      selectPolicy: Max

    # Scale DOWN behavior (conservative to prevent thrashing)
    scaleDown:
      # Stabilization window - wait before scale-down to avoid thrashing
      stabilizationWindowSeconds: 300  # 5 minutes (conservative)

      # Scaling policies
      policies:
        # Policy 1: Scale down by 50% (remove half the excess pods)
        - type: Percent
          value: 50
          periodSeconds: 60

        # Policy 2: Scale down by 1 pod
        - type: Pods
          value: 1
          periodSeconds: 120  # 2 minutes between each pod removal

      # Select the policy that scales down the least (conservative)
      selectPolicy: Min

---
# Vertical Pod Autoscaler (VPA) for resource optimization
# Recommends or automatically adjusts resource requests/limits
# Install VPA: kubectl apply -f https://github.com/kubernetes/autoscaler/releases/download/vertical-pod-autoscaler-0.14.0/vpa-v0.14.0.yaml

apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: gl-001-process-heat-vpa
  namespace: greenlang
  labels:
    app: gl-001-process-heat
    agent: "GL-001"
  annotations:
    description: "Vertical Pod Autoscaler for GL-001 (resource optimization)"

spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: gl-001-process-heat

  # Update policy
  updatePolicy:
    updateMode: "Off"  # Options: Off, Initial, Recreate, Auto
    # Off: Only provide recommendations (safe for production)
    # Initial: Set resources on pod creation
    # Recreate: Update existing pods by recreating them
    # Auto: Update pods in-place (requires feature gate)

  # Resource policy - define bounds for VPA recommendations
  resourcePolicy:
    containerPolicies:
      - containerName: gl-001-process-heat
        # Minimum allowed resources
        minAllowed:
          memory: "512Mi"
          cpu: "500m"
        # Maximum allowed resources
        maxAllowed:
          memory: "4Gi"
          cpu: "4000m"
        # Controlled resources
        controlledResources:
          - cpu
          - memory
        # Controlled values (requests, limits, or both)
        controlledValues: RequestsAndLimits

---
# Pod Disruption Budget (PDB) - Ensure availability during scaling
# Prevents too many pods from being terminated simultaneously

apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: gl-001-process-heat-pdb
  namespace: greenlang
  labels:
    app: gl-001-process-heat
    agent: "GL-001"
  annotations:
    description: "Pod Disruption Budget for GL-001 (high availability)"

spec:
  # Selector matches deployment pods
  selector:
    matchLabels:
      app: gl-001-process-heat
      agent: "GL-001"

  # Minimum available pods during disruptions
  minAvailable: 2  # Always keep at least 2 pods running

  # Alternative: maxUnavailable (use one or the other, not both)
  # maxUnavailable: 1  # Only 1 pod can be unavailable at a time

  # Unhealthy pod eviction policy
  unhealthyPodEvictionPolicy: IfHealthyBudget

---
# Prometheus Adapter ConfigMap for custom metrics
# Exposes custom metrics from Prometheus to HPA
# Requires Prometheus Adapter to be installed in the cluster

apiVersion: v1
kind: ConfigMap
metadata:
  name: adapter-config
  namespace: monitoring
data:
  config.yaml: |
    rules:
      # HTTP requests per second metric
      - seriesQuery: 'http_requests_total{namespace="greenlang",pod=~"gl-001-process-heat-.*"}'
        resources:
          overrides:
            namespace: {resource: "namespace"}
            pod: {resource: "pod"}
        name:
          matches: "^(.*)_total$"
          as: "${1}_per_second"
        metricsQuery: 'sum(rate(<<.Series>>{<<.LabelMatchers>>}[1m])) by (<<.GroupBy>>)'

      # Optimization queue depth metric
      - seriesQuery: 'optimization_queue_depth{namespace="greenlang",pod=~"gl-001-process-heat-.*"}'
        resources:
          overrides:
            namespace: {resource: "namespace"}
            pod: {resource: "pod"}
        name:
          as: "optimization_queue_depth"
        metricsQuery: 'avg(<<.Series>>{<<.LabelMatchers>>}) by (<<.GroupBy>>)'

      # Active agent tasks metric
      - seriesQuery: 'active_agent_tasks{namespace="greenlang",pod=~"gl-001-process-heat-.*"}'
        resources:
          overrides:
            namespace: {resource: "namespace"}
            pod: {resource: "pod"}
        name:
          as: "active_agent_tasks"
        metricsQuery: 'sum(<<.Series>>{<<.LabelMatchers>>}) by (<<.GroupBy>>)'

---
# Scaling Strategy Documentation
# ============================================================================
# GL-001 uses an INTELLIGENT SCALING STRATEGY optimized for:
# 1. Real-time thermal efficiency optimization (latency-sensitive)
# 2. Agent coordination workloads (stateful connections)
# 3. SCADA/ERP integration (connection pool management)
#
# SCALING TRIGGERS:
# Primary: CPU > 70% → Scale up (computational load)
# Secondary: Memory > 80% → Scale up (cache/buffer load)
# Tertiary: Request rate > 100/s per pod → Scale up (API load)
# Quaternary: Queue depth > 10 per pod → Scale up (backlog)
#
# SCALING PATTERNS:
# Scale UP: Fast (30s stabilization, +100% or +2 pods)
#   - Quick response to load spikes
#   - Prevents request queuing
#   - Maintains sub-500ms p95 latency
#
# Scale DOWN: Slow (5min stabilization, -50% or -1 pod)
#   - Prevents thrashing
#   - Allows connection draining
#   - Preserves warm caches
#
# HIGH AVAILABILITY:
# - Min 3 replicas (survives 1 node failure)
# - PDB ensures 2 pods always available
# - Session affinity maintains agent state
#
# RESOURCE OPTIMIZATION:
# - VPA monitors and recommends resource adjustments
# - Initial: 512Mi RAM / 500m CPU
# - Maximum: 4Gi RAM / 4000m CPU
# - Actual usage drives VPA recommendations
#
# MONITORING:
# - Check HPA status: kubectl get hpa -n greenlang
# - View scaling events: kubectl describe hpa gl-001-process-heat-hpa -n greenlang
# - Monitor metrics: kubectl get --raw /apis/metrics.k8s.io/v1beta1/namespaces/greenlang/pods
# ============================================================================
