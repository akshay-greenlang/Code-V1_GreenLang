# GL-008 SteamTrapInspector - Kubernetes Deployment
# Acoustic and thermal inspection system for steam trap monitoring
# High availability deployment with ML inference capabilities

apiVersion: apps/v1
kind: Deployment
metadata:
  name: gl-008-steam-trap-inspector
  namespace: greenlang
  labels:
    app: gl-008-steam-trap-inspector
    agent: "GL-008"
    version: v1.0.0
    tier: inspection-system
  annotations:
    description: "Steam trap inspection agent with acoustic and thermal analysis"
    sla.uptime: "99.5%"
    sla.latency: "<500ms"
spec:
  # Replicas managed by HPA (3-10 replicas)
  replicas: 3

  # Rolling update strategy for zero-downtime deployments
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1        # Add 1 pod before removing old ones
      maxUnavailable: 0  # Never take down pods during update (zero-downtime)

  # Selector for pod matching
  selector:
    matchLabels:
      app: gl-008-steam-trap-inspector
      agent: "GL-008"

  # Pod template
  template:
    metadata:
      labels:
        app: gl-008-steam-trap-inspector
        agent: "GL-008"
        version: v1.0.0
        tier: inspection-system
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9091"
        prometheus.io/path: "/metrics"
    spec:
      # Service account for RBAC
      serviceAccountName: gl-008-service-account

      # Security context for pod
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        seccompProfile:
          type: RuntimeDefault

      # Anti-affinity for high availability (spread across nodes)
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - gl-008-steam-trap-inspector
                topologyKey: kubernetes.io/hostname

      # Topology spread for even distribution
      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: ScheduleAnyway
          labelSelector:
            matchLabels:
              app: gl-008-steam-trap-inspector

      # Init containers for pre-flight checks
      initContainers:
        - name: database-ready
          image: postgres:14-alpine
          command:
            - sh
            - -c
            - |
              until pg_isready -h ${DATABASE_HOST} -p ${DATABASE_PORT} -U ${DATABASE_USER}; do
                echo "Waiting for database..."
                sleep 2
              done
          env:
            - name: DATABASE_HOST
              valueFrom:
                configMapKeyRef:
                  name: gl-008-config
                  key: database_host
            - name: DATABASE_PORT
              value: "5432"
            - name: DATABASE_USER
              valueFrom:
                secretKeyRef:
                  name: gl-008-secrets
                  key: database_user

        - name: redis-ready
          image: redis:7-alpine
          command:
            - sh
            - -c
            - |
              until redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} ping; do
                echo "Waiting for Redis..."
                sleep 2
              done
          env:
            - name: REDIS_HOST
              valueFrom:
                configMapKeyRef:
                  name: gl-008-config
                  key: redis_host
            - name: REDIS_PORT
              value: "6379"

        - name: ml-models-loader
          image: busybox:1.36
          command:
            - sh
            - -c
            - |
              echo "Checking ML models availability..."
              if [ -d "/models" ]; then
                echo "ML models directory found"
                ls -la /models
              else
                echo "Warning: ML models directory not found"
              fi
          volumeMounts:
            - name: ml-models
              mountPath: /models

      # Main application container
      containers:
        - name: gl-008-steam-trap-inspector
          image: gcr.io/greenlang/gl-008-steam-trap-inspector:1.0.0
          imagePullPolicy: Always

          # Ports
          ports:
            - name: http
              containerPort: 9090
              protocol: TCP
            - name: metrics
              containerPort: 9091
              protocol: TCP

          # Environment variables
          env:
            - name: ENVIRONMENT
              value: "production"
            - name: APP_NAME
              value: "GL-008 SteamTrapInspector"
            - name: LOG_LEVEL
              value: "INFO"
            - name: PORT
              value: "9090"
            - name: METRICS_PORT
              value: "9091"

            # Database configuration
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: gl-008-secrets
                  key: database_url

            # Redis configuration
            - name: REDIS_URL
              valueFrom:
                secretKeyRef:
                  name: gl-008-secrets
                  key: redis_url

            # AI API keys
            - name: ANTHROPIC_API_KEY
              valueFrom:
                secretKeyRef:
                  name: gl-008-secrets
                  key: anthropic_api_key

            # S3 configuration for data storage
            - name: AWS_S3_BUCKET
              valueFrom:
                configMapKeyRef:
                  name: gl-008-config
                  key: s3_bucket_name

            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: gl-008-secrets
                  key: aws_access_key_id

            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: gl-008-secrets
                  key: aws_secret_access_key

            # ML model configuration
            - name: ML_MODELS_PATH
              value: "/models"

            # Kubernetes metadata
            - name: KUBERNETES_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: KUBERNETES_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: KUBERNETES_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName

          # Environment from ConfigMap
          envFrom:
            - configMapRef:
                name: gl-008-config

          # Resource requests and limits
          resources:
            requests:
              memory: "512Mi"
              cpu: "1000m"
            limits:
              memory: "2Gi"
              cpu: "4000m"

          # Liveness probe (is the app alive?)
          livenessProbe:
            httpGet:
              path: /api/v1/health
              port: 9090
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
            successThreshold: 1

          # Readiness probe (is the app ready to serve traffic?)
          readinessProbe:
            httpGet:
              path: /api/v1/ready
              port: 9090
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 3
            failureThreshold: 3
            successThreshold: 1

          # Startup probe (for slow-starting containers with ML models)
          startupProbe:
            httpGet:
              path: /api/v1/health
              port: 9090
            initialDelaySeconds: 0
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 18  # 18 * 10s = 180s max startup time (ML model loading)
            successThreshold: 1

          # Security context for container
          securityContext:
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            runAsUser: 1000
            readOnlyRootFilesystem: true
            capabilities:
              drop:
                - ALL

          # Volume mounts
          volumeMounts:
            - name: logs
              mountPath: /app/logs
            - name: data
              mountPath: /app/data
            - name: cache
              mountPath: /app/cache
            - name: tmp
              mountPath: /tmp
            - name: ml-models
              mountPath: /models
              readOnly: true
            - name: acoustic-data
              mountPath: /app/acoustic-data
            - name: thermal-data
              mountPath: /app/thermal-data

      # Volumes
      volumes:
        - name: logs
          emptyDir:
            sizeLimit: 1Gi
        - name: data
          emptyDir:
            sizeLimit: 5Gi
        - name: cache
          emptyDir:
            sizeLimit: 1Gi
        - name: tmp
          emptyDir:
            sizeLimit: 512Mi
        - name: acoustic-data
          emptyDir:
            sizeLimit: 2Gi
        - name: thermal-data
          emptyDir:
            sizeLimit: 2Gi
        - name: ml-models
          persistentVolumeClaim:
            claimName: gl-008-ml-models-pvc

      # DNS policy
      dnsPolicy: ClusterFirst

      # Restart policy
      restartPolicy: Always

      # Termination grace period (for graceful shutdown)
      terminationGracePeriodSeconds: 60

      # Priority class (for important workloads)
      # priorityClassName: medium-priority
