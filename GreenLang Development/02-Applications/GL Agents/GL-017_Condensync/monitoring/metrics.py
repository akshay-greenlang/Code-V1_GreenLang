# -*- coding: utf-8 -*-
"""
GL-017 CONDENSYNC - Prometheus Metrics Module
==============================================

Comprehensive Prometheus metrics for condenser optimization monitoring.
Implements RED (Rate, Errors, Duration) and USE (Utilization, Saturation, Errors)
metrics patterns for production observability.

Key Metric Categories:
- Condenser KPI Gauges (Cleanliness Factor, TTD, Vacuum, Heat Duty)
- Calculation Latency Histograms (per calculation type)
- Recommendation Counters (by type, priority, status)
- Data Quality Scores (completeness, freshness, accuracy)
- Alert Counters (by severity, type, acknowledgment status)

Standards Compliance:
- OpenMetrics specification
- Prometheus naming conventions
- Kubernetes observability patterns
- GreenLang Global AI Standards v2.0

Example:
    >>> from monitoring.metrics import CondenserMetrics, get_metrics_instance
    >>> metrics = get_metrics_instance()
    >>> metrics.record_condenser_kpi(
    ...     condenser_id="COND-001",
    ...     cleanliness_factor=0.85,
    ...     ttd=3.5,
    ...     vacuum_pressure=0.035,
    ...     heat_duty=125000
    ... )

Author: GL-BackendDeveloper
Date: December 2025
Version: 1.0.0
"""

from __future__ import annotations

import logging
import os
import threading
import time
from contextlib import contextmanager
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from typing import Any, Callable, Dict, Generator, List, Optional, Set

from prometheus_client import (
    Counter,
    Gauge,
    Histogram,
    Info,
    Summary,
    REGISTRY,
    CONTENT_TYPE_LATEST,
    CollectorRegistry,
    generate_latest,
)

logger = logging.getLogger(__name__)


# =============================================================================
# METRIC LABEL ENUMS
# =============================================================================

class CondenserType(str, Enum):
    """Types of condensers supported by the system."""
    SURFACE = "surface"
    DIRECT_CONTACT = "direct_contact"
    AIR_COOLED = "air_cooled"
    EVAPORATIVE = "evaporative"
    SHELL_AND_TUBE = "shell_and_tube"
    PLATE = "plate"
    UNKNOWN = "unknown"


class CalculationType(str, Enum):
    """Types of calculations performed by the agent."""
    CLEANLINESS_FACTOR = "cleanliness_factor"
    TERMINAL_TEMP_DIFFERENCE = "terminal_temp_difference"
    HEAT_DUTY = "heat_duty"
    VACUUM_PRESSURE = "vacuum_pressure"
    FOULING_RESISTANCE = "fouling_resistance"
    OVERALL_HEAT_TRANSFER = "overall_heat_transfer"
    LMTD = "lmtd"
    EFFECTIVENESS = "effectiveness"
    NTU = "ntu"
    SUBCOOLING = "subcooling"
    AIR_INGRESS = "air_ingress"
    TUBE_LEAK_DETECTION = "tube_leak_detection"


class RecommendationType(str, Enum):
    """Types of recommendations generated by the agent."""
    TUBE_CLEANING = "tube_cleaning"
    VACUUM_IMPROVEMENT = "vacuum_improvement"
    CW_FLOW_ADJUSTMENT = "cw_flow_adjustment"
    AIR_LEAK_REPAIR = "air_leak_repair"
    TUBE_PLUGGING = "tube_plugging"
    CHEMICAL_TREATMENT = "chemical_treatment"
    LOAD_REDUCTION = "load_reduction"
    MAINTENANCE_SCHEDULING = "maintenance_scheduling"
    OPERATIONAL_ADJUSTMENT = "operational_adjustment"


class RecommendationPriority(str, Enum):
    """Priority levels for recommendations."""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"


class AlertSeverity(str, Enum):
    """Severity levels for alerts."""
    CRITICAL = "critical"
    WARNING = "warning"
    INFO = "info"


class DataQualityDimension(str, Enum):
    """Dimensions of data quality assessment."""
    COMPLETENESS = "completeness"
    FRESHNESS = "freshness"
    ACCURACY = "accuracy"
    CONSISTENCY = "consistency"
    VALIDITY = "validity"


class DependencyType(str, Enum):
    """Types of external dependencies."""
    OPC_UA = "opc_ua"
    KAFKA = "kafka"
    CMMS = "cmms"
    DATABASE = "database"
    CACHE = "cache"
    PI_SERVER = "pi_server"
    HISTORIAN = "historian"


# =============================================================================
# PROMETHEUS METRIC DEFINITIONS
# =============================================================================

# -----------------------------------------------------------------------------
# CONDENSER KPI GAUGES
# -----------------------------------------------------------------------------

CLEANLINESS_FACTOR_GAUGE = Gauge(
    name="condensync_cleanliness_factor",
    documentation="Condenser cleanliness factor (0-1 scale, 1=clean)",
    labelnames=["condenser_id", "condenser_type", "unit"],
)

TERMINAL_TEMP_DIFFERENCE_GAUGE = Gauge(
    name="condensync_ttd_celsius",
    documentation="Terminal Temperature Difference in Celsius",
    labelnames=["condenser_id", "condenser_type", "unit"],
)

VACUUM_PRESSURE_GAUGE = Gauge(
    name="condensync_vacuum_pressure_bar_abs",
    documentation="Condenser vacuum pressure in bar absolute",
    labelnames=["condenser_id", "condenser_type", "unit"],
)

HEAT_DUTY_GAUGE = Gauge(
    name="condensync_heat_duty_kw",
    documentation="Condenser heat duty in kilowatts",
    labelnames=["condenser_id", "condenser_type", "unit"],
)

OVERALL_HEAT_TRANSFER_GAUGE = Gauge(
    name="condensync_overall_heat_transfer_coefficient",
    documentation="Overall heat transfer coefficient (W/m2K)",
    labelnames=["condenser_id", "condenser_type", "unit"],
)

FOULING_RESISTANCE_GAUGE = Gauge(
    name="condensync_fouling_resistance",
    documentation="Fouling resistance (m2K/W)",
    labelnames=["condenser_id", "condenser_type", "unit"],
)

EFFECTIVENESS_GAUGE = Gauge(
    name="condensync_effectiveness",
    documentation="Condenser effectiveness (0-1 scale)",
    labelnames=["condenser_id", "condenser_type", "unit"],
)

SUBCOOLING_GAUGE = Gauge(
    name="condensync_subcooling_celsius",
    documentation="Condensate subcooling in Celsius",
    labelnames=["condenser_id", "condenser_type", "unit"],
)

AIR_INGRESS_GAUGE = Gauge(
    name="condensync_air_ingress_indicator",
    documentation="Air ingress indicator (0=none, 1=detected)",
    labelnames=["condenser_id", "unit"],
)

CW_FLOW_RATE_GAUGE = Gauge(
    name="condensync_cw_flow_rate_m3_hr",
    documentation="Cooling water flow rate in m3/hr",
    labelnames=["condenser_id", "unit"],
)

CW_INLET_TEMP_GAUGE = Gauge(
    name="condensync_cw_inlet_temp_celsius",
    documentation="Cooling water inlet temperature in Celsius",
    labelnames=["condenser_id", "unit"],
)

CW_OUTLET_TEMP_GAUGE = Gauge(
    name="condensync_cw_outlet_temp_celsius",
    documentation="Cooling water outlet temperature in Celsius",
    labelnames=["condenser_id", "unit"],
)

STEAM_FLOW_GAUGE = Gauge(
    name="condensync_steam_flow_kg_hr",
    documentation="Steam flow rate to condenser in kg/hr",
    labelnames=["condenser_id", "unit"],
)

CONDENSER_LOAD_PERCENT_GAUGE = Gauge(
    name="condensync_load_percent",
    documentation="Condenser load as percentage of design capacity",
    labelnames=["condenser_id", "unit"],
)

# Performance trend gauges
CF_TREND_GAUGE = Gauge(
    name="condensync_cf_trend",
    documentation="Cleanliness factor trend indicator (-1=declining, 0=stable, 1=improving)",
    labelnames=["condenser_id", "unit"],
)

PERFORMANCE_INDEX_GAUGE = Gauge(
    name="condensync_performance_index",
    documentation="Overall performance index (0-100 scale)",
    labelnames=["condenser_id", "unit"],
)

# -----------------------------------------------------------------------------
# CALCULATION LATENCY HISTOGRAMS
# -----------------------------------------------------------------------------

CALCULATION_LATENCY_HISTOGRAM = Histogram(
    name="condensync_calculation_latency_seconds",
    documentation="Time taken for calculations in seconds",
    labelnames=["calculation_type", "condenser_type"],
    buckets=(0.001, 0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0),
)

BATCH_CALCULATION_LATENCY_HISTOGRAM = Histogram(
    name="condensync_batch_calculation_latency_seconds",
    documentation="Time taken for batch calculations in seconds",
    labelnames=["calculation_type", "batch_size_bucket"],
    buckets=(0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0, 120.0),
)

RECOMMENDATION_GENERATION_LATENCY_HISTOGRAM = Histogram(
    name="condensync_recommendation_generation_latency_seconds",
    documentation="Time taken to generate recommendations in seconds",
    labelnames=["recommendation_type"],
    buckets=(0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0),
)

DATA_INGESTION_LATENCY_HISTOGRAM = Histogram(
    name="condensync_data_ingestion_latency_seconds",
    documentation="Time taken for data ingestion in seconds",
    labelnames=["source_type", "condenser_id"],
    buckets=(0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5),
)

# Summary for percentile tracking
CALCULATION_DURATION_SUMMARY = Summary(
    name="condensync_calculation_duration_seconds",
    documentation="Summary of calculation durations",
    labelnames=["calculation_type"],
)

# -----------------------------------------------------------------------------
# RECOMMENDATION COUNTERS
# -----------------------------------------------------------------------------

RECOMMENDATIONS_GENERATED_COUNTER = Counter(
    name="condensync_recommendations_generated_total",
    documentation="Total recommendations generated",
    labelnames=["recommendation_type", "priority", "condenser_id"],
)

RECOMMENDATIONS_ACCEPTED_COUNTER = Counter(
    name="condensync_recommendations_accepted_total",
    documentation="Total recommendations accepted by operators",
    labelnames=["recommendation_type", "priority"],
)

RECOMMENDATIONS_REJECTED_COUNTER = Counter(
    name="condensync_recommendations_rejected_total",
    documentation="Total recommendations rejected by operators",
    labelnames=["recommendation_type", "priority", "rejection_reason"],
)

RECOMMENDATIONS_IMPLEMENTED_COUNTER = Counter(
    name="condensync_recommendations_implemented_total",
    documentation="Total recommendations implemented",
    labelnames=["recommendation_type", "priority"],
)

RECOMMENDATIONS_EXPIRED_COUNTER = Counter(
    name="condensync_recommendations_expired_total",
    documentation="Total recommendations expired without action",
    labelnames=["recommendation_type", "priority"],
)

# Active recommendations gauge
ACTIVE_RECOMMENDATIONS_GAUGE = Gauge(
    name="condensync_active_recommendations",
    documentation="Number of currently active recommendations",
    labelnames=["recommendation_type", "priority"],
)

# Recommendation savings estimate
ESTIMATED_SAVINGS_GAUGE = Gauge(
    name="condensync_estimated_savings_usd_hr",
    documentation="Estimated hourly savings from recommendations in USD/hr",
    labelnames=["condenser_id", "recommendation_type"],
)

# -----------------------------------------------------------------------------
# DATA QUALITY SCORES
# -----------------------------------------------------------------------------

DATA_QUALITY_SCORE_GAUGE = Gauge(
    name="condensync_data_quality_score",
    documentation="Data quality score (0-1 scale)",
    labelnames=["dimension", "condenser_id", "source"],
)

DATA_COMPLETENESS_GAUGE = Gauge(
    name="condensync_data_completeness",
    documentation="Percentage of expected data points received (0-100)",
    labelnames=["condenser_id", "tag_group"],
)

DATA_FRESHNESS_SECONDS_GAUGE = Gauge(
    name="condensync_data_freshness_seconds",
    documentation="Age of latest data point in seconds",
    labelnames=["condenser_id", "tag_id", "source"],
)

DATA_VALIDATION_FAILURES_COUNTER = Counter(
    name="condensync_data_validation_failures_total",
    documentation="Total data validation failures",
    labelnames=["validation_type", "condenser_id", "tag_id"],
)

MISSING_DATA_POINTS_COUNTER = Counter(
    name="condensync_missing_data_points_total",
    documentation="Total missing data points detected",
    labelnames=["condenser_id", "tag_group"],
)

OUT_OF_RANGE_VALUES_COUNTER = Counter(
    name="condensync_out_of_range_values_total",
    documentation="Total out-of-range values detected",
    labelnames=["condenser_id", "tag_id", "range_type"],
)

# -----------------------------------------------------------------------------
# ALERT COUNTERS
# -----------------------------------------------------------------------------

ALERTS_RAISED_COUNTER = Counter(
    name="condensync_alerts_raised_total",
    documentation="Total alerts raised",
    labelnames=["alert_type", "severity", "condenser_id"],
)

ALERTS_ACKNOWLEDGED_COUNTER = Counter(
    name="condensync_alerts_acknowledged_total",
    documentation="Total alerts acknowledged",
    labelnames=["alert_type", "severity"],
)

ALERTS_RESOLVED_COUNTER = Counter(
    name="condensync_alerts_resolved_total",
    documentation="Total alerts resolved",
    labelnames=["alert_type", "severity", "resolution_type"],
)

ALERTS_ESCALATED_COUNTER = Counter(
    name="condensync_alerts_escalated_total",
    documentation="Total alerts escalated",
    labelnames=["alert_type", "severity", "escalation_level"],
)

ACTIVE_ALERTS_GAUGE = Gauge(
    name="condensync_active_alerts",
    documentation="Number of currently active alerts",
    labelnames=["alert_type", "severity"],
)

ALERT_RESPONSE_TIME_HISTOGRAM = Histogram(
    name="condensync_alert_response_time_seconds",
    documentation="Time from alert raised to acknowledgment in seconds",
    labelnames=["alert_type", "severity"],
    buckets=(60, 300, 600, 1800, 3600, 7200, 14400, 28800),
)

# -----------------------------------------------------------------------------
# API AND PROCESSING METRICS (RED Pattern)
# -----------------------------------------------------------------------------

API_REQUESTS_COUNTER = Counter(
    name="condensync_api_requests_total",
    documentation="Total API requests",
    labelnames=["method", "endpoint", "status_code"],
)

API_LATENCY_HISTOGRAM = Histogram(
    name="condensync_api_latency_seconds",
    documentation="API request latency in seconds",
    labelnames=["method", "endpoint"],
    buckets=(0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0),
)

PROCESSING_ERRORS_COUNTER = Counter(
    name="condensync_processing_errors_total",
    documentation="Total processing errors",
    labelnames=["error_type", "component", "condenser_id"],
)

# -----------------------------------------------------------------------------
# DEPENDENCY METRICS (USE Pattern)
# -----------------------------------------------------------------------------

DEPENDENCY_UP_GAUGE = Gauge(
    name="condensync_dependency_up",
    documentation="Dependency availability (1=up, 0=down)",
    labelnames=["dependency_type", "instance"],
)

DEPENDENCY_LATENCY_HISTOGRAM = Histogram(
    name="condensync_dependency_latency_seconds",
    documentation="Dependency call latency in seconds",
    labelnames=["dependency_type", "operation"],
    buckets=(0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0),
)

DEPENDENCY_ERRORS_COUNTER = Counter(
    name="condensync_dependency_errors_total",
    documentation="Total dependency errors",
    labelnames=["dependency_type", "error_type"],
)

ACTIVE_CONNECTIONS_GAUGE = Gauge(
    name="condensync_active_connections",
    documentation="Number of active connections by type",
    labelnames=["connection_type", "instance"],
)

# -----------------------------------------------------------------------------
# AGENT INFO
# -----------------------------------------------------------------------------

AGENT_INFO_METRIC = Info(
    name="condensync_agent",
    documentation="Agent metadata and version information",
)


# =============================================================================
# DATA CLASSES
# =============================================================================

@dataclass(frozen=True)
class CondenserKPI:
    """
    Immutable condenser KPI data point.

    Attributes:
        condenser_id: Unique condenser identifier
        condenser_type: Type of condenser
        unit: Plant unit identifier
        cleanliness_factor: CF value (0-1)
        ttd: Terminal temperature difference (Celsius)
        vacuum_pressure: Vacuum pressure (bar abs)
        heat_duty: Heat duty (kW)
        overall_u: Overall heat transfer coefficient (W/m2K)
        fouling_resistance: Fouling resistance (m2K/W)
        effectiveness: Effectiveness (0-1)
        subcooling: Subcooling (Celsius)
        cw_flow_rate: Cooling water flow rate (m3/hr)
        cw_inlet_temp: CW inlet temperature (Celsius)
        cw_outlet_temp: CW outlet temperature (Celsius)
        steam_flow: Steam flow rate (kg/hr)
        timestamp: Data timestamp
    """
    condenser_id: str
    condenser_type: str = "surface"
    unit: str = "default"
    cleanliness_factor: Optional[float] = None
    ttd: Optional[float] = None
    vacuum_pressure: Optional[float] = None
    heat_duty: Optional[float] = None
    overall_u: Optional[float] = None
    fouling_resistance: Optional[float] = None
    effectiveness: Optional[float] = None
    subcooling: Optional[float] = None
    cw_flow_rate: Optional[float] = None
    cw_inlet_temp: Optional[float] = None
    cw_outlet_temp: Optional[float] = None
    steam_flow: Optional[float] = None
    timestamp: Optional[datetime] = None


@dataclass(frozen=True)
class RecommendationMetrics:
    """
    Immutable recommendation metrics.

    Attributes:
        recommendation_id: Unique recommendation identifier
        recommendation_type: Type of recommendation
        priority: Priority level
        condenser_id: Target condenser
        estimated_savings_usd_hr: Estimated hourly savings
        generation_time_seconds: Time to generate recommendation
        accepted: Whether recommendation was accepted
        implemented: Whether recommendation was implemented
    """
    recommendation_id: str
    recommendation_type: str
    priority: str
    condenser_id: str
    estimated_savings_usd_hr: float = 0.0
    generation_time_seconds: float = 0.0
    accepted: Optional[bool] = None
    implemented: Optional[bool] = None


@dataclass(frozen=True)
class DataQualityMetrics:
    """
    Immutable data quality metrics.

    Attributes:
        condenser_id: Condenser identifier
        source: Data source
        completeness: Completeness score (0-1)
        freshness_seconds: Data age in seconds
        accuracy: Accuracy score (0-1)
        consistency: Consistency score (0-1)
        validity: Validity score (0-1)
    """
    condenser_id: str
    source: str
    completeness: float = 1.0
    freshness_seconds: float = 0.0
    accuracy: float = 1.0
    consistency: float = 1.0
    validity: float = 1.0


@dataclass
class AlertMetrics:
    """
    Alert metrics tracking.

    Attributes:
        alert_id: Unique alert identifier
        alert_type: Type of alert
        severity: Alert severity
        condenser_id: Related condenser
        raised_at: Time alert was raised
        acknowledged_at: Time alert was acknowledged
        resolved_at: Time alert was resolved
    """
    alert_id: str
    alert_type: str
    severity: str
    condenser_id: str
    raised_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    acknowledged_at: Optional[datetime] = None
    resolved_at: Optional[datetime] = None


# =============================================================================
# CONDENSER METRICS CLASS
# =============================================================================

class CondenserMetrics:
    """
    Comprehensive metrics manager for GL-017 CONDENSYNC.

    Provides methods for recording all condenser-related metrics including
    KPIs, calculations, recommendations, data quality, and alerts.

    Thread-safe implementation with support for batch operations.

    Example:
        >>> metrics = CondenserMetrics()
        >>> metrics.initialize("1.0.0", "production")
        >>>
        >>> # Record condenser KPIs
        >>> metrics.record_condenser_kpi(
        ...     condenser_id="COND-001",
        ...     cleanliness_factor=0.85,
        ...     ttd=3.5,
        ...     vacuum_pressure=0.035
        ... )
        >>>
        >>> # Measure calculation
        >>> with metrics.measure_calculation("cleanliness_factor", "surface"):
        ...     result = calculate_cf(data)
        >>>
        >>> # Record recommendation
        >>> metrics.record_recommendation(
        ...     recommendation_type="tube_cleaning",
        ...     priority="high",
        ...     condenser_id="COND-001"
        ... )

    Attributes:
        registry: Prometheus CollectorRegistry
        version: Agent version
        environment: Deployment environment
    """

    VERSION = "1.0.0"

    def __init__(self, registry: Optional[CollectorRegistry] = None):
        """
        Initialize condenser metrics manager.

        Args:
            registry: Optional custom registry for testing isolation
        """
        self.registry = registry or REGISTRY
        self.version: str = "1.0.0"
        self.environment: str = "development"
        self._initialized: bool = False
        self._lock = threading.Lock()

        # Track active items
        self._active_recommendations: Dict[str, Set[str]] = {}
        self._active_alerts: Dict[str, Set[str]] = {}

        logger.debug("CondenserMetrics instance created")

    def initialize(
        self,
        version: str,
        environment: str,
        instance_id: Optional[str] = None,
    ) -> None:
        """
        Initialize metrics with agent metadata.

        Args:
            version: Agent version string
            environment: Deployment environment
            instance_id: Optional instance identifier
        """
        self.version = version
        self.environment = environment

        AGENT_INFO_METRIC.info({
            "agent_id": "GL-017",
            "agent_name": "CONDENSYNC",
            "version": version,
            "environment": environment,
            "instance_id": instance_id or os.getenv("HOSTNAME", "default"),
            "metrics_version": self.VERSION,
        })

        self._initialized = True
        logger.info(
            f"CondenserMetrics v{self.VERSION} initialized: "
            f"version={version}, environment={environment}"
        )

    # =========================================================================
    # CONDENSER KPI METHODS
    # =========================================================================

    def record_condenser_kpi(
        self,
        condenser_id: str,
        cleanliness_factor: Optional[float] = None,
        ttd: Optional[float] = None,
        vacuum_pressure: Optional[float] = None,
        heat_duty: Optional[float] = None,
        condenser_type: str = "surface",
        unit: str = "default",
        overall_u: Optional[float] = None,
        fouling_resistance: Optional[float] = None,
        effectiveness: Optional[float] = None,
        subcooling: Optional[float] = None,
    ) -> None:
        """
        Record condenser KPI values.

        Args:
            condenser_id: Unique condenser identifier
            cleanliness_factor: CF value (0-1)
            ttd: Terminal temperature difference (Celsius)
            vacuum_pressure: Vacuum pressure (bar abs)
            heat_duty: Heat duty (kW)
            condenser_type: Type of condenser
            unit: Plant unit identifier
            overall_u: Overall heat transfer coefficient
            fouling_resistance: Fouling resistance
            effectiveness: Effectiveness ratio
            subcooling: Subcooling value
        """
        labels = {
            "condenser_id": condenser_id,
            "condenser_type": condenser_type,
            "unit": unit,
        }

        if cleanliness_factor is not None:
            CLEANLINESS_FACTOR_GAUGE.labels(**labels).set(cleanliness_factor)

        if ttd is not None:
            TERMINAL_TEMP_DIFFERENCE_GAUGE.labels(**labels).set(ttd)

        if vacuum_pressure is not None:
            VACUUM_PRESSURE_GAUGE.labels(**labels).set(vacuum_pressure)

        if heat_duty is not None:
            HEAT_DUTY_GAUGE.labels(**labels).set(heat_duty)

        if overall_u is not None:
            OVERALL_HEAT_TRANSFER_GAUGE.labels(**labels).set(overall_u)

        if fouling_resistance is not None:
            FOULING_RESISTANCE_GAUGE.labels(**labels).set(fouling_resistance)

        if effectiveness is not None:
            EFFECTIVENESS_GAUGE.labels(**labels).set(effectiveness)

        if subcooling is not None:
            SUBCOOLING_GAUGE.labels(**labels).set(subcooling)

        logger.debug(
            f"Recorded KPIs for {condenser_id}: "
            f"CF={cleanliness_factor}, TTD={ttd}, VP={vacuum_pressure}"
        )

    def record_kpi_batch(self, kpis: List[CondenserKPI]) -> None:
        """
        Record multiple condenser KPIs in batch.

        Args:
            kpis: List of CondenserKPI objects
        """
        for kpi in kpis:
            self.record_condenser_kpi(
                condenser_id=kpi.condenser_id,
                condenser_type=kpi.condenser_type,
                unit=kpi.unit,
                cleanliness_factor=kpi.cleanliness_factor,
                ttd=kpi.ttd,
                vacuum_pressure=kpi.vacuum_pressure,
                heat_duty=kpi.heat_duty,
                overall_u=kpi.overall_u,
                fouling_resistance=kpi.fouling_resistance,
                effectiveness=kpi.effectiveness,
                subcooling=kpi.subcooling,
            )

    def record_cooling_water_metrics(
        self,
        condenser_id: str,
        flow_rate: float,
        inlet_temp: float,
        outlet_temp: float,
        unit: str = "default",
    ) -> None:
        """
        Record cooling water metrics.

        Args:
            condenser_id: Condenser identifier
            flow_rate: Flow rate in m3/hr
            inlet_temp: Inlet temperature in Celsius
            outlet_temp: Outlet temperature in Celsius
            unit: Plant unit identifier
        """
        CW_FLOW_RATE_GAUGE.labels(condenser_id=condenser_id, unit=unit).set(flow_rate)
        CW_INLET_TEMP_GAUGE.labels(condenser_id=condenser_id, unit=unit).set(inlet_temp)
        CW_OUTLET_TEMP_GAUGE.labels(condenser_id=condenser_id, unit=unit).set(outlet_temp)

    def record_steam_flow(
        self,
        condenser_id: str,
        steam_flow: float,
        unit: str = "default",
    ) -> None:
        """
        Record steam flow to condenser.

        Args:
            condenser_id: Condenser identifier
            steam_flow: Steam flow rate in kg/hr
            unit: Plant unit identifier
        """
        STEAM_FLOW_GAUGE.labels(condenser_id=condenser_id, unit=unit).set(steam_flow)

    def record_condenser_load(
        self,
        condenser_id: str,
        load_percent: float,
        unit: str = "default",
    ) -> None:
        """
        Record condenser load percentage.

        Args:
            condenser_id: Condenser identifier
            load_percent: Load as percentage of design capacity
            unit: Plant unit identifier
        """
        CONDENSER_LOAD_PERCENT_GAUGE.labels(
            condenser_id=condenser_id,
            unit=unit,
        ).set(load_percent)

    def record_performance_index(
        self,
        condenser_id: str,
        performance_index: float,
        cf_trend: int = 0,
        unit: str = "default",
    ) -> None:
        """
        Record overall performance index and trend.

        Args:
            condenser_id: Condenser identifier
            performance_index: Performance index (0-100)
            cf_trend: Trend indicator (-1=declining, 0=stable, 1=improving)
            unit: Plant unit identifier
        """
        PERFORMANCE_INDEX_GAUGE.labels(
            condenser_id=condenser_id,
            unit=unit,
        ).set(performance_index)

        CF_TREND_GAUGE.labels(
            condenser_id=condenser_id,
            unit=unit,
        ).set(cf_trend)

    def record_air_ingress(
        self,
        condenser_id: str,
        detected: bool,
        unit: str = "default",
    ) -> None:
        """
        Record air ingress detection status.

        Args:
            condenser_id: Condenser identifier
            detected: Whether air ingress is detected
            unit: Plant unit identifier
        """
        AIR_INGRESS_GAUGE.labels(
            condenser_id=condenser_id,
            unit=unit,
        ).set(1 if detected else 0)

    # =========================================================================
    # CALCULATION LATENCY METHODS
    # =========================================================================

    @contextmanager
    def measure_calculation(
        self,
        calculation_type: str,
        condenser_type: str = "surface",
    ) -> Generator[None, None, None]:
        """
        Context manager to measure calculation duration.

        Args:
            calculation_type: Type of calculation
            condenser_type: Type of condenser

        Yields:
            None - timing is automatic

        Example:
            >>> with metrics.measure_calculation("cleanliness_factor", "surface"):
            ...     result = calculate_cf(data)
        """
        start_time = time.perf_counter()
        try:
            yield
        finally:
            duration = time.perf_counter() - start_time

            CALCULATION_LATENCY_HISTOGRAM.labels(
                calculation_type=calculation_type,
                condenser_type=condenser_type,
            ).observe(duration)

            CALCULATION_DURATION_SUMMARY.labels(
                calculation_type=calculation_type,
            ).observe(duration)

            logger.debug(
                f"Calculation completed: type={calculation_type}, "
                f"duration={duration:.4f}s"
            )

    @contextmanager
    def measure_batch_calculation(
        self,
        calculation_type: str,
        batch_size: int,
    ) -> Generator[None, None, None]:
        """
        Context manager to measure batch calculation duration.

        Args:
            calculation_type: Type of calculation
            batch_size: Number of items in batch

        Yields:
            None - timing is automatic
        """
        # Determine batch size bucket
        if batch_size <= 10:
            bucket = "1-10"
        elif batch_size <= 50:
            bucket = "11-50"
        elif batch_size <= 100:
            bucket = "51-100"
        elif batch_size <= 500:
            bucket = "101-500"
        else:
            bucket = "500+"

        start_time = time.perf_counter()
        try:
            yield
        finally:
            duration = time.perf_counter() - start_time

            BATCH_CALCULATION_LATENCY_HISTOGRAM.labels(
                calculation_type=calculation_type,
                batch_size_bucket=bucket,
            ).observe(duration)

    def record_calculation_latency(
        self,
        calculation_type: str,
        duration_seconds: float,
        condenser_type: str = "surface",
    ) -> None:
        """
        Record calculation latency manually.

        Args:
            calculation_type: Type of calculation
            duration_seconds: Duration in seconds
            condenser_type: Type of condenser
        """
        CALCULATION_LATENCY_HISTOGRAM.labels(
            calculation_type=calculation_type,
            condenser_type=condenser_type,
        ).observe(duration_seconds)

        CALCULATION_DURATION_SUMMARY.labels(
            calculation_type=calculation_type,
        ).observe(duration_seconds)

    @contextmanager
    def measure_data_ingestion(
        self,
        source_type: str,
        condenser_id: str,
    ) -> Generator[None, None, None]:
        """
        Context manager to measure data ingestion latency.

        Args:
            source_type: Type of data source
            condenser_id: Condenser identifier

        Yields:
            None - timing is automatic
        """
        start_time = time.perf_counter()
        try:
            yield
        finally:
            duration = time.perf_counter() - start_time

            DATA_INGESTION_LATENCY_HISTOGRAM.labels(
                source_type=source_type,
                condenser_id=condenser_id,
            ).observe(duration)

    # =========================================================================
    # RECOMMENDATION METHODS
    # =========================================================================

    def record_recommendation(
        self,
        recommendation_type: str,
        priority: str,
        condenser_id: str,
        recommendation_id: Optional[str] = None,
        estimated_savings_usd_hr: float = 0.0,
    ) -> None:
        """
        Record a generated recommendation.

        Args:
            recommendation_type: Type of recommendation
            priority: Priority level
            condenser_id: Target condenser
            recommendation_id: Optional unique ID
            estimated_savings_usd_hr: Estimated hourly savings
        """
        RECOMMENDATIONS_GENERATED_COUNTER.labels(
            recommendation_type=recommendation_type,
            priority=priority,
            condenser_id=condenser_id,
        ).inc()

        if estimated_savings_usd_hr > 0:
            ESTIMATED_SAVINGS_GAUGE.labels(
                condenser_id=condenser_id,
                recommendation_type=recommendation_type,
            ).set(estimated_savings_usd_hr)

        # Track active recommendation
        with self._lock:
            key = f"{recommendation_type}:{priority}"
            if key not in self._active_recommendations:
                self._active_recommendations[key] = set()
            if recommendation_id:
                self._active_recommendations[key].add(recommendation_id)

            ACTIVE_RECOMMENDATIONS_GAUGE.labels(
                recommendation_type=recommendation_type,
                priority=priority,
            ).set(len(self._active_recommendations.get(key, set())))

    @contextmanager
    def measure_recommendation_generation(
        self,
        recommendation_type: str,
    ) -> Generator[None, None, None]:
        """
        Context manager to measure recommendation generation time.

        Args:
            recommendation_type: Type of recommendation

        Yields:
            None - timing is automatic
        """
        start_time = time.perf_counter()
        try:
            yield
        finally:
            duration = time.perf_counter() - start_time

            RECOMMENDATION_GENERATION_LATENCY_HISTOGRAM.labels(
                recommendation_type=recommendation_type,
            ).observe(duration)

    def record_recommendation_accepted(
        self,
        recommendation_type: str,
        priority: str,
        recommendation_id: Optional[str] = None,
    ) -> None:
        """
        Record a recommendation acceptance.

        Args:
            recommendation_type: Type of recommendation
            priority: Priority level
            recommendation_id: Optional recommendation ID
        """
        RECOMMENDATIONS_ACCEPTED_COUNTER.labels(
            recommendation_type=recommendation_type,
            priority=priority,
        ).inc()

    def record_recommendation_rejected(
        self,
        recommendation_type: str,
        priority: str,
        rejection_reason: str = "other",
        recommendation_id: Optional[str] = None,
    ) -> None:
        """
        Record a recommendation rejection.

        Args:
            recommendation_type: Type of recommendation
            priority: Priority level
            rejection_reason: Reason for rejection
            recommendation_id: Optional recommendation ID
        """
        RECOMMENDATIONS_REJECTED_COUNTER.labels(
            recommendation_type=recommendation_type,
            priority=priority,
            rejection_reason=rejection_reason,
        ).inc()

        # Remove from active
        with self._lock:
            key = f"{recommendation_type}:{priority}"
            if key in self._active_recommendations and recommendation_id:
                self._active_recommendations[key].discard(recommendation_id)
                ACTIVE_RECOMMENDATIONS_GAUGE.labels(
                    recommendation_type=recommendation_type,
                    priority=priority,
                ).set(len(self._active_recommendations[key]))

    def record_recommendation_implemented(
        self,
        recommendation_type: str,
        priority: str,
        recommendation_id: Optional[str] = None,
    ) -> None:
        """
        Record a recommendation implementation.

        Args:
            recommendation_type: Type of recommendation
            priority: Priority level
            recommendation_id: Optional recommendation ID
        """
        RECOMMENDATIONS_IMPLEMENTED_COUNTER.labels(
            recommendation_type=recommendation_type,
            priority=priority,
        ).inc()

        # Remove from active
        with self._lock:
            key = f"{recommendation_type}:{priority}"
            if key in self._active_recommendations and recommendation_id:
                self._active_recommendations[key].discard(recommendation_id)
                ACTIVE_RECOMMENDATIONS_GAUGE.labels(
                    recommendation_type=recommendation_type,
                    priority=priority,
                ).set(len(self._active_recommendations[key]))

    def record_recommendation_expired(
        self,
        recommendation_type: str,
        priority: str,
        recommendation_id: Optional[str] = None,
    ) -> None:
        """
        Record a recommendation expiration.

        Args:
            recommendation_type: Type of recommendation
            priority: Priority level
            recommendation_id: Optional recommendation ID
        """
        RECOMMENDATIONS_EXPIRED_COUNTER.labels(
            recommendation_type=recommendation_type,
            priority=priority,
        ).inc()

        # Remove from active
        with self._lock:
            key = f"{recommendation_type}:{priority}"
            if key in self._active_recommendations and recommendation_id:
                self._active_recommendations[key].discard(recommendation_id)
                ACTIVE_RECOMMENDATIONS_GAUGE.labels(
                    recommendation_type=recommendation_type,
                    priority=priority,
                ).set(len(self._active_recommendations[key]))

    # =========================================================================
    # DATA QUALITY METHODS
    # =========================================================================

    def record_data_quality(
        self,
        condenser_id: str,
        source: str,
        completeness: float = 1.0,
        freshness_seconds: float = 0.0,
        accuracy: float = 1.0,
        consistency: float = 1.0,
        validity: float = 1.0,
    ) -> None:
        """
        Record data quality metrics.

        Args:
            condenser_id: Condenser identifier
            source: Data source
            completeness: Completeness score (0-1)
            freshness_seconds: Data age in seconds
            accuracy: Accuracy score (0-1)
            consistency: Consistency score (0-1)
            validity: Validity score (0-1)
        """
        base_labels = {"condenser_id": condenser_id, "source": source}

        DATA_QUALITY_SCORE_GAUGE.labels(
            dimension="completeness", **base_labels
        ).set(completeness)

        DATA_QUALITY_SCORE_GAUGE.labels(
            dimension="accuracy", **base_labels
        ).set(accuracy)

        DATA_QUALITY_SCORE_GAUGE.labels(
            dimension="consistency", **base_labels
        ).set(consistency)

        DATA_QUALITY_SCORE_GAUGE.labels(
            dimension="validity", **base_labels
        ).set(validity)

        DATA_FRESHNESS_SECONDS_GAUGE.labels(
            condenser_id=condenser_id,
            tag_id="aggregate",
            source=source,
        ).set(freshness_seconds)

    def record_data_quality_metrics(self, metrics: DataQualityMetrics) -> None:
        """
        Record data quality from dataclass.

        Args:
            metrics: DataQualityMetrics instance
        """
        self.record_data_quality(
            condenser_id=metrics.condenser_id,
            source=metrics.source,
            completeness=metrics.completeness,
            freshness_seconds=metrics.freshness_seconds,
            accuracy=metrics.accuracy,
            consistency=metrics.consistency,
            validity=metrics.validity,
        )

    def record_data_completeness(
        self,
        condenser_id: str,
        tag_group: str,
        completeness_percent: float,
    ) -> None:
        """
        Record data completeness percentage.

        Args:
            condenser_id: Condenser identifier
            tag_group: Group of tags
            completeness_percent: Completeness percentage (0-100)
        """
        DATA_COMPLETENESS_GAUGE.labels(
            condenser_id=condenser_id,
            tag_group=tag_group,
        ).set(completeness_percent)

    def record_data_freshness(
        self,
        condenser_id: str,
        tag_id: str,
        source: str,
        age_seconds: float,
    ) -> None:
        """
        Record data freshness.

        Args:
            condenser_id: Condenser identifier
            tag_id: Tag identifier
            source: Data source
            age_seconds: Age of data in seconds
        """
        DATA_FRESHNESS_SECONDS_GAUGE.labels(
            condenser_id=condenser_id,
            tag_id=tag_id,
            source=source,
        ).set(age_seconds)

    def record_validation_failure(
        self,
        validation_type: str,
        condenser_id: str,
        tag_id: str,
    ) -> None:
        """
        Record a data validation failure.

        Args:
            validation_type: Type of validation that failed
            condenser_id: Condenser identifier
            tag_id: Tag that failed validation
        """
        DATA_VALIDATION_FAILURES_COUNTER.labels(
            validation_type=validation_type,
            condenser_id=condenser_id,
            tag_id=tag_id,
        ).inc()

    def record_missing_data(
        self,
        condenser_id: str,
        tag_group: str,
        count: int = 1,
    ) -> None:
        """
        Record missing data points.

        Args:
            condenser_id: Condenser identifier
            tag_group: Group of tags
            count: Number of missing points
        """
        MISSING_DATA_POINTS_COUNTER.labels(
            condenser_id=condenser_id,
            tag_group=tag_group,
        ).inc(count)

    def record_out_of_range(
        self,
        condenser_id: str,
        tag_id: str,
        range_type: str = "bounds",
    ) -> None:
        """
        Record out-of-range value.

        Args:
            condenser_id: Condenser identifier
            tag_id: Tag identifier
            range_type: Type of range violation (bounds, rate, etc.)
        """
        OUT_OF_RANGE_VALUES_COUNTER.labels(
            condenser_id=condenser_id,
            tag_id=tag_id,
            range_type=range_type,
        ).inc()

    # =========================================================================
    # ALERT METHODS
    # =========================================================================

    def record_alert_raised(
        self,
        alert_type: str,
        severity: str,
        condenser_id: str,
        alert_id: Optional[str] = None,
    ) -> None:
        """
        Record an alert being raised.

        Args:
            alert_type: Type of alert
            severity: Alert severity
            condenser_id: Related condenser
            alert_id: Optional unique alert ID
        """
        ALERTS_RAISED_COUNTER.labels(
            alert_type=alert_type,
            severity=severity,
            condenser_id=condenser_id,
        ).inc()

        # Track active alert
        with self._lock:
            key = f"{alert_type}:{severity}"
            if key not in self._active_alerts:
                self._active_alerts[key] = set()
            if alert_id:
                self._active_alerts[key].add(alert_id)

            ACTIVE_ALERTS_GAUGE.labels(
                alert_type=alert_type,
                severity=severity,
            ).set(len(self._active_alerts.get(key, set())))

    def record_alert_acknowledged(
        self,
        alert_type: str,
        severity: str,
        response_time_seconds: Optional[float] = None,
        alert_id: Optional[str] = None,
    ) -> None:
        """
        Record an alert acknowledgment.

        Args:
            alert_type: Type of alert
            severity: Alert severity
            response_time_seconds: Time from raised to acknowledged
            alert_id: Optional alert ID
        """
        ALERTS_ACKNOWLEDGED_COUNTER.labels(
            alert_type=alert_type,
            severity=severity,
        ).inc()

        if response_time_seconds is not None:
            ALERT_RESPONSE_TIME_HISTOGRAM.labels(
                alert_type=alert_type,
                severity=severity,
            ).observe(response_time_seconds)

    def record_alert_resolved(
        self,
        alert_type: str,
        severity: str,
        resolution_type: str = "manual",
        alert_id: Optional[str] = None,
    ) -> None:
        """
        Record an alert resolution.

        Args:
            alert_type: Type of alert
            severity: Alert severity
            resolution_type: How alert was resolved
            alert_id: Optional alert ID
        """
        ALERTS_RESOLVED_COUNTER.labels(
            alert_type=alert_type,
            severity=severity,
            resolution_type=resolution_type,
        ).inc()

        # Remove from active
        with self._lock:
            key = f"{alert_type}:{severity}"
            if key in self._active_alerts and alert_id:
                self._active_alerts[key].discard(alert_id)
                ACTIVE_ALERTS_GAUGE.labels(
                    alert_type=alert_type,
                    severity=severity,
                ).set(len(self._active_alerts[key]))

    def record_alert_escalated(
        self,
        alert_type: str,
        severity: str,
        escalation_level: str = "L2",
    ) -> None:
        """
        Record an alert escalation.

        Args:
            alert_type: Type of alert
            severity: Alert severity
            escalation_level: Level of escalation
        """
        ALERTS_ESCALATED_COUNTER.labels(
            alert_type=alert_type,
            severity=severity,
            escalation_level=escalation_level,
        ).inc()

    # =========================================================================
    # API AND PROCESSING METHODS
    # =========================================================================

    @contextmanager
    def measure_api_request(
        self,
        method: str,
        endpoint: str,
    ) -> Generator[None, None, None]:
        """
        Context manager to measure API request duration.

        Args:
            method: HTTP method
            endpoint: API endpoint

        Yields:
            None - timing is automatic
        """
        start_time = time.perf_counter()
        status_code = "200"
        try:
            yield
        except Exception:
            status_code = "500"
            raise
        finally:
            duration = time.perf_counter() - start_time

            API_LATENCY_HISTOGRAM.labels(
                method=method,
                endpoint=endpoint,
            ).observe(duration)

            API_REQUESTS_COUNTER.labels(
                method=method,
                endpoint=endpoint,
                status_code=status_code,
            ).inc()

    def record_api_request(
        self,
        method: str,
        endpoint: str,
        status_code: int,
        duration_seconds: float,
    ) -> None:
        """
        Record API request manually.

        Args:
            method: HTTP method
            endpoint: API endpoint
            status_code: HTTP status code
            duration_seconds: Request duration
        """
        API_REQUESTS_COUNTER.labels(
            method=method,
            endpoint=endpoint,
            status_code=str(status_code),
        ).inc()

        API_LATENCY_HISTOGRAM.labels(
            method=method,
            endpoint=endpoint,
        ).observe(duration_seconds)

    def record_processing_error(
        self,
        error_type: str,
        component: str,
        condenser_id: str = "unknown",
    ) -> None:
        """
        Record a processing error.

        Args:
            error_type: Type of error
            component: Component where error occurred
            condenser_id: Related condenser
        """
        PROCESSING_ERRORS_COUNTER.labels(
            error_type=error_type,
            component=component,
            condenser_id=condenser_id,
        ).inc()

        logger.warning(
            f"Processing error recorded: type={error_type}, "
            f"component={component}, condenser={condenser_id}"
        )

    # =========================================================================
    # DEPENDENCY METHODS
    # =========================================================================

    def set_dependency_status(
        self,
        dependency_type: str,
        instance: str,
        is_up: bool,
    ) -> None:
        """
        Set dependency availability status.

        Args:
            dependency_type: Type of dependency
            instance: Instance identifier
            is_up: Whether dependency is available
        """
        DEPENDENCY_UP_GAUGE.labels(
            dependency_type=dependency_type,
            instance=instance,
        ).set(1 if is_up else 0)

    @contextmanager
    def measure_dependency_call(
        self,
        dependency_type: str,
        operation: str,
    ) -> Generator[None, None, None]:
        """
        Context manager to measure dependency call latency.

        Args:
            dependency_type: Type of dependency
            operation: Operation being performed

        Yields:
            None - timing is automatic
        """
        start_time = time.perf_counter()
        try:
            yield
        except Exception as e:
            DEPENDENCY_ERRORS_COUNTER.labels(
                dependency_type=dependency_type,
                error_type=type(e).__name__,
            ).inc()
            raise
        finally:
            duration = time.perf_counter() - start_time

            DEPENDENCY_LATENCY_HISTOGRAM.labels(
                dependency_type=dependency_type,
                operation=operation,
            ).observe(duration)

    def record_dependency_error(
        self,
        dependency_type: str,
        error_type: str,
    ) -> None:
        """
        Record a dependency error.

        Args:
            dependency_type: Type of dependency
            error_type: Type of error
        """
        DEPENDENCY_ERRORS_COUNTER.labels(
            dependency_type=dependency_type,
            error_type=error_type,
        ).inc()

    def set_active_connections(
        self,
        connection_type: str,
        instance: str,
        count: int,
    ) -> None:
        """
        Set number of active connections.

        Args:
            connection_type: Type of connection
            instance: Instance identifier
            count: Number of active connections
        """
        ACTIVE_CONNECTIONS_GAUGE.labels(
            connection_type=connection_type,
            instance=instance,
        ).set(count)

    # =========================================================================
    # METRICS OUTPUT
    # =========================================================================

    def get_metrics(self) -> bytes:
        """
        Generate Prometheus metrics output.

        Returns:
            Prometheus-formatted metrics as bytes
        """
        return generate_latest(self.registry)

    def get_content_type(self) -> str:
        """
        Get content type for metrics response.

        Returns:
            Prometheus content type string
        """
        return CONTENT_TYPE_LATEST

    def get_summary(self) -> Dict[str, Any]:
        """
        Get human-readable metrics summary.

        Returns:
            Dictionary with metric summaries
        """
        with self._lock:
            return {
                "initialized": self._initialized,
                "version": self.version,
                "environment": self.environment,
                "active_recommendations": {
                    k: len(v) for k, v in self._active_recommendations.items()
                },
                "active_alerts": {
                    k: len(v) for k, v in self._active_alerts.items()
                },
            }


# =============================================================================
# GLOBAL INSTANCE
# =============================================================================

_global_metrics: Optional[CondenserMetrics] = None
_metrics_lock = threading.Lock()


def get_metrics_instance() -> CondenserMetrics:
    """
    Get or create global metrics instance.

    Thread-safe singleton pattern.

    Returns:
        CondenserMetrics instance
    """
    global _global_metrics
    with _metrics_lock:
        if _global_metrics is None:
            _global_metrics = CondenserMetrics()
        return _global_metrics


def initialize_metrics(
    version: str,
    environment: str,
    instance_id: Optional[str] = None,
) -> CondenserMetrics:
    """
    Initialize global metrics with configuration.

    Args:
        version: Agent version
        environment: Deployment environment
        instance_id: Optional instance identifier

    Returns:
        Initialized CondenserMetrics instance
    """
    metrics = get_metrics_instance()
    metrics.initialize(version, environment, instance_id)
    return metrics


# =============================================================================
# MODULE EXPORTS
# =============================================================================

__all__ = [
    # Main class
    "CondenserMetrics",
    "get_metrics_instance",
    "initialize_metrics",
    # Data classes
    "CondenserKPI",
    "RecommendationMetrics",
    "DataQualityMetrics",
    "AlertMetrics",
    # Enums
    "CondenserType",
    "CalculationType",
    "RecommendationType",
    "RecommendationPriority",
    "AlertSeverity",
    "DataQualityDimension",
    "DependencyType",
    # Prometheus metrics (for direct access)
    "CLEANLINESS_FACTOR_GAUGE",
    "TERMINAL_TEMP_DIFFERENCE_GAUGE",
    "VACUUM_PRESSURE_GAUGE",
    "HEAT_DUTY_GAUGE",
    "CALCULATION_LATENCY_HISTOGRAM",
    "RECOMMENDATIONS_GENERATED_COUNTER",
    "DATA_QUALITY_SCORE_GAUGE",
    "ALERTS_RAISED_COUNTER",
    "API_REQUESTS_COUNTER",
]
