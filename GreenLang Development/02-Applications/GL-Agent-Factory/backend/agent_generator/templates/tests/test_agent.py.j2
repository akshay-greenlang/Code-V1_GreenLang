"""
Test Suite for {{ pack.name }}

Agent ID: {{ pack.id }}
Version: {{ pack.version }}

This test suite is AUTO-GENERATED by the GreenLang Agent Factory.
Regenerate from pack.yaml to update.

Generated: {{ generated_at }}

Test Categories:
1. Golden Tests - Expected input/output pairs
2. Determinism Tests - Verify reproducibility
3. Provenance Tests - Audit trail verification
4. Property Tests - Invariant checks
"""

import hashlib
import json
import pytest
from datetime import datetime
from typing import Dict, Any

from {{ module_path }} import (
    {{ pack.id | replace('-', '_') | pascal_case }}Agent,
    {{ pack.id | replace('-', '_') | pascal_case }}Input,
    {{ pack.id | replace('-', '_') | pascal_case }}Output,
)


# =============================================================================
# Fixtures
# =============================================================================

@pytest.fixture
def agent():
    """Create agent instance for testing."""
    return {{ pack.id | replace('-', '_') | pascal_case }}Agent()


@pytest.fixture
def agent_strict():
    """Create agent instance with strict mode."""
    return {{ pack.id | replace('-', '_') | pascal_case }}Agent(config={"strict_mode": True})


# =============================================================================
# Golden Tests
# =============================================================================

class TestGoldenCases:
    """Golden test cases from pack.yaml specification."""

{% for test in tests.golden %}
    def test_{{ test.name | snake_case }}(self, agent):
        """
        {{ test.description | default(test.name) }}

        Input: {{ test.input | tojson | truncate(100) }}
        Expected: {{ test.expect | tojson | truncate(100) }}
        """
        # Arrange
        input_data = {{ pack.id | replace('-', '_') | pascal_case }}Input(
{% for key, value in test.input.items() %}
            {{ key }}={{ value | tojson }},
{% endfor %}
        )

        # Act
        result = agent.run(input_data)

        # Assert
{% for field, expected in test.expect.items() %}
{% if test.tolerance is defined and field in test.tolerance %}
        assert result.{{ field }} == pytest.approx(
            {{ expected }},
            abs={{ test.tolerance[field] }}
        ), f"{{ field }} mismatch: expected {{ expected }}, got {result.{{ field }}}"
{% else %}
        assert result.{{ field }} == {{ expected | tojson }}, \
            f"{{ field }} mismatch: expected {{ expected | tojson }}, got {result.{{ field }}}"
{% endif %}
{% endfor %}

        # Verify provenance exists
        assert result.provenance_hash is not None
        assert len(result.provenance_hash) == 64, "Provenance hash should be SHA-256"

{% endfor %}


# =============================================================================
# Determinism Tests
# =============================================================================

class TestDeterminism:
    """Verify deterministic outputs (critical for regulatory compliance)."""

{% if tests.golden | length > 0 %}
{% set first_test = tests.golden[0] %}
    def test_deterministic_repeatability(self, agent):
        """
        Same inputs must produce identical outputs.

        Runs {{ tests.properties[0].iterations | default(100) }} iterations to verify.
        """
        input_data = {{ pack.id | replace('-', '_') | pascal_case }}Input(
{% for key, value in first_test.input.items() %}
            {{ key }}={{ value | tojson }},
{% endfor %}
        )

        # Run multiple times
        results = []
        for _ in range(100):
            result = agent.run(input_data)
            results.append(result)

        # All provenance hashes must be identical
        provenance_hashes = [r.provenance_hash for r in results]
        unique_hashes = set(provenance_hashes)

        assert len(unique_hashes) == 1, (
            f"Non-deterministic outputs detected! "
            f"Found {len(unique_hashes)} unique hashes in 100 runs"
        )

    def test_deterministic_across_instances(self):
        """Different agent instances should produce identical results."""
        agent1 = {{ pack.id | replace('-', '_') | pascal_case }}Agent()
        agent2 = {{ pack.id | replace('-', '_') | pascal_case }}Agent()

        input_data = {{ pack.id | replace('-', '_') | pascal_case }}Input(
{% for key, value in first_test.input.items() %}
            {{ key }}={{ value | tojson }},
{% endfor %}
        )

        result1 = agent1.run(input_data)
        result2 = agent2.run(input_data)

        # Exclude timestamp fields for comparison
        dict1 = result1.dict(exclude={"calculated_at"})
        dict2 = result2.dict(exclude={"calculated_at"})

        assert dict1 == dict2, "Results differ between agent instances"
{% endif %}


# =============================================================================
# Provenance Tests
# =============================================================================

class TestProvenance:
    """Verify provenance tracking for audit trail."""

{% if tests.golden | length > 0 %}
{% set first_test = tests.golden[0] %}
    def test_provenance_completeness(self, agent):
        """Provenance hash must include all required fields."""
        input_data = {{ pack.id | replace('-', '_') | pascal_case }}Input(
{% for key, value in first_test.input.items() %}
            {{ key }}={{ value | tojson }},
{% endfor %}
        )

        result = agent.run(input_data)

        # Required provenance fields
        assert result.provenance_hash is not None
        assert len(result.provenance_hash) == 64, "Should be SHA-256 hex string"
        assert all(c in "0123456789abcdef" for c in result.provenance_hash), \
            "Should be valid hex"

    def test_provenance_changes_with_input(self, agent):
        """Different inputs must produce different provenance hashes."""
        # First calculation
        input1 = {{ pack.id | replace('-', '_') | pascal_case }}Input(
{% for key, value in first_test.input.items() %}
            {{ key }}={{ value | tojson }},
{% endfor %}
        )
        result1 = agent.run(input1)

        # Modify input slightly
        input2 = {{ pack.id | replace('-', '_') | pascal_case }}Input(
{% for key, value in first_test.input.items() %}
{% if value is number %}
            {{ key }}={{ value * 1.1 }},
{% else %}
            {{ key }}={{ value | tojson }},
{% endif %}
{% endfor %}
        )
        result2 = agent.run(input2)

        assert result1.provenance_hash != result2.provenance_hash, \
            "Different inputs should produce different provenance hashes"
{% endif %}


# =============================================================================
# Property Tests
# =============================================================================

class TestProperties:
    """Property-based invariant checks."""

{% for prop in tests.properties | default([]) %}
    def test_{{ prop.name | snake_case }}(self, agent):
        """
        {{ prop.description | default(prop.name) }}

        Rule: {{ prop.rule }}
        """
{% if "non_negative" in prop.name %}
{% if tests.golden | length > 0 %}
{% set first_test = tests.golden[0] %}
        input_data = {{ pack.id | replace('-', '_') | pascal_case }}Input(
{% for key, value in first_test.input.items() %}
            {{ key }}={{ value | tojson }},
{% endfor %}
        )

        result = agent.run(input_data)

        # Check non-negative constraint
        for field_name in dir(result):
            if not field_name.startswith("_"):
                value = getattr(result, field_name)
                if isinstance(value, (int, float)) and "emission" in field_name.lower():
                    assert value >= 0, f"{field_name} should not be negative"
{% endif %}
{% elif "provenance_hash_format" in prop.name %}
{% if tests.golden | length > 0 %}
{% set first_test = tests.golden[0] %}
        input_data = {{ pack.id | replace('-', '_') | pascal_case }}Input(
{% for key, value in first_test.input.items() %}
            {{ key }}={{ value | tojson }},
{% endfor %}
        )

        result = agent.run(input_data)

        # Verify SHA-256 format
        assert len(result.provenance_hash) == 64
        assert all(c in "0123456789abcdef" for c in result.provenance_hash)
{% endif %}
{% else %}
        # Property: {{ prop.rule }}
        pytest.skip("Property test implementation pending")
{% endif %}

{% endfor %}


# =============================================================================
# Edge Case Tests
# =============================================================================

class TestEdgeCases:
    """Edge case and boundary condition tests."""

{% for test in tests.golden | selectattr('name', 'contains', 'zero') | list %}
{% if test %}
    def test_{{ test.name | snake_case }}(self, agent):
        """{{ test.description | default(test.name) }}"""
        input_data = {{ pack.id | replace('-', '_') | pascal_case }}Input(
{% for key, value in test.input.items() %}
            {{ key }}={{ value | tojson }},
{% endfor %}
        )

        result = agent.run(input_data)

{% for field, expected in test.expect.items() %}
        assert result.{{ field }} == pytest.approx({{ expected }}, abs={{ test.tolerance.get(field, 0.001) if test.tolerance else 0.001 }})
{% endfor %}
{% endif %}
{% endfor %}

    def test_invalid_input_rejected(self):
        """Invalid inputs should be rejected by Pydantic validation."""
        with pytest.raises((ValueError, TypeError)):
            {{ pack.id | replace('-', '_') | pascal_case }}Input(
                # Invalid: missing required fields
            )


# =============================================================================
# Performance Tests
# =============================================================================

class TestPerformance:
    """Performance benchmark tests."""

{% if tests.golden | length > 0 %}
{% set first_test = tests.golden[0] %}
    def test_calculation_latency(self, agent):
        """Single calculation should complete within 1 second."""
        import time

        input_data = {{ pack.id | replace('-', '_') | pascal_case }}Input(
{% for key, value in first_test.input.items() %}
            {{ key }}={{ value | tojson }},
{% endfor %}
        )

        start = time.perf_counter()
        result = agent.run(input_data)
        duration = time.perf_counter() - start

        assert duration < 1.0, f"Calculation took {duration:.3f}s, expected < 1s"

    def test_batch_throughput(self, agent):
        """Should handle 100 calculations in under 10 seconds."""
        import time

        input_data = {{ pack.id | replace('-', '_') | pascal_case }}Input(
{% for key, value in first_test.input.items() %}
            {{ key }}={{ value | tojson }},
{% endfor %}
        )

        start = time.perf_counter()
        for _ in range(100):
            agent.run(input_data)
        duration = time.perf_counter() - start

        assert duration < 10.0, f"100 calculations took {duration:.3f}s, expected < 10s"
        print(f"Throughput: {100/duration:.1f} calculations/second")
{% endif %}


# =============================================================================
# Certification Tests
# =============================================================================

class TestCertification:
    """Certification-level tests for audit readiness."""

{% if tests.golden | length > 0 %}
{% set first_test = tests.golden[0] %}
    def test_all_golden_tests_pass(self, agent):
        """All golden tests must pass for certification."""
        golden_test_count = {{ tests.golden | length }}
        passed = 0

        # This is a meta-test - actual golden tests run separately
        # Just verify we have the expected count
        assert golden_test_count >= 1, "At least 1 golden test required"
        print(f"Golden tests defined: {golden_test_count}")

    def test_determinism_100_runs(self, agent):
        """Determinism verified over 100 runs."""
        input_data = {{ pack.id | replace('-', '_') | pascal_case }}Input(
{% for key, value in first_test.input.items() %}
            {{ key }}={{ value | tojson }},
{% endfor %}
        )

        hashes = set()
        for _ in range(100):
            result = agent.run(input_data)
            hashes.add(result.provenance_hash)

        assert len(hashes) == 1, (
            f"DETERMINISM FAILURE: {len(hashes)} unique outputs in 100 runs"
        )
        print("DETERMINISM VERIFIED: 100 identical outputs")
{% endif %}


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])
