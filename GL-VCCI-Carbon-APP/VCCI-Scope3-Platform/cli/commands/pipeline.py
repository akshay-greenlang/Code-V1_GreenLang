# -*- coding: utf-8 -*-
"""
GL-VCCI CLI - Pipeline Command
End-to-end workflow orchestration for Scope 3 emissions.

Features:
- Complete intake â†’ calculate â†’ analyze â†’ report workflow
- Multi-category processing
- Progress tracking for each stage
- Automated report generation
- Error handling and recovery

Version: 1.0.0
Date: 2025-11-08
"""

import sys
import json
from pathlib import Path
from typing import Optional, List, Dict, Any
from datetime import datetime
import typer
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import (
from greenlang.determinism import DeterministicClock
from greenlang.determinism import deterministic_random
    Progress,
    SpinnerColumn,
    TextColumn,
    BarColumn,
    TaskProgressColumn,
    TimeRemainingColumn
)
from rich import box
from rich.tree import Tree
from rich.text import Text

# Import agents
try:
    from services.agents.intake.agent import ValueChainIntakeAgent
    from services.agents.calculator.agent import Scope3CalculatorAgent
    from services.agents.hotspot.agent import HotspotAnalysisAgent
    from services.agents.reporting.agent import ReportingAgent
    AGENTS_AVAILABLE = True
except ImportError:
    AGENTS_AVAILABLE = False

# Create console
console = Console()

# Create Typer app for pipeline commands
pipeline_app = typer.Typer(
    name="pipeline",
    help="End-to-end workflow orchestration",
    rich_markup_mode="rich"
)


# ============================================================================
# PIPELINE EXECUTION CLASS
# ============================================================================

class PipelineExecutor:
    """Orchestrates end-to-end Scope 3 calculation pipeline."""

    def __init__(self, tenant_id: str = "cli-user"):
        self.tenant_id = tenant_id
        self.run_id = f"RUN-{DeterministicClock.utcnow().strftime('%Y%m%d%H%M%S')}"
        self.results = {}

    def run(
        self,
        input_path: Path,
        output_dir: Path,
        categories: List[int],
        enable_llm: bool = True,
        enable_monte_carlo: bool = True,
        report_format: str = "ghg-protocol"
    ) -> Dict[str, Any]:
        """Execute complete pipeline."""

        pipeline_results = {
            "run_id": self.run_id,
            "started_at": DeterministicClock.utcnow().isoformat(),
            "stages": {},
            "overall_status": "running"
        }

        try:
            # Stage 1: Intake
            console.print("\n[bold cyan]Stage 1: Data Intake[/bold cyan]")
            console.print("=" * 60)

            intake_result = self._stage_intake(input_path)
            pipeline_results["stages"]["intake"] = {
                "status": "completed",
                "records_processed": intake_result.get("total_records", 0),
                "records_successful": intake_result.get("successful", 0)
            }

            # Stage 2: Calculate
            console.print("\n[bold cyan]Stage 2: Emissions Calculation[/bold cyan]")
            console.print("=" * 60)

            calc_results = self._stage_calculate(
                categories=categories,
                enable_llm=enable_llm,
                enable_monte_carlo=enable_monte_carlo
            )
            pipeline_results["stages"]["calculate"] = {
                "status": "completed",
                "categories_processed": len(categories),
                "total_emissions": calc_results.get("total_emissions", 0)
            }

            # Stage 3: Analyze
            console.print("\n[bold cyan]Stage 3: Hotspot Analysis[/bold cyan]")
            console.print("=" * 60)

            analysis_result = self._stage_analyze(calc_results)
            pipeline_results["stages"]["analyze"] = {
                "status": "completed",
                "hotspots_identified": len(analysis_result.get("hotspots", []))
            }

            # Stage 4: Report
            console.print("\n[bold cyan]Stage 4: Report Generation[/bold cyan]")
            console.print("=" * 60)

            report_result = self._stage_report(
                calc_results,
                analysis_result,
                output_dir,
                report_format
            )
            pipeline_results["stages"]["report"] = {
                "status": "completed",
                "report_path": str(report_result.get("report_path", ""))
            }

            pipeline_results["overall_status"] = "completed"
            pipeline_results["completed_at"] = DeterministicClock.utcnow().isoformat()

        except Exception as e:
            pipeline_results["overall_status"] = "failed"
            pipeline_results["error"] = str(e)
            raise

        return pipeline_results

    def _stage_intake(self, input_path: Path) -> Dict[str, Any]:
        """Execute intake stage."""
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            console=console
        ) as progress:
            task = progress.add_task("[cyan]Ingesting data files...", total=100)

            # Initialize intake agent
            progress.update(task, completed=20, description="[cyan]Initializing intake agent...")
            agent = ValueChainIntakeAgent(tenant_id=self.tenant_id)

            # Determine if input is file or directory
            if input_path.is_file():
                progress.update(task, completed=40, description=f"[cyan]Processing {input_path.name}...")

                # Detect format
                suffix = input_path.suffix.lower()
                format_map = {'.csv': 'csv', '.json': 'json', '.xlsx': 'excel', '.xml': 'xml', '.pdf': 'pdf'}
                format = format_map.get(suffix, 'csv')

                result = agent.ingest_file(
                    file_path=input_path,
                    format=format,
                    entity_type="supplier"
                )

                progress.update(task, completed=100, description="[green]Intake complete")

                return {
                    "total_records": result.statistics.total_records,
                    "successful": result.statistics.successful,
                    "failed": result.statistics.failed,
                    "batch_id": result.batch_id
                }

            elif input_path.is_dir():
                # Process all files in directory
                progress.update(task, completed=40, description="[cyan]Processing directory...")

                files = list(input_path.glob("*.*"))
                total_records = 0
                successful = 0

                for i, file in enumerate(files):
                    suffix = file.suffix.lower()
                    format_map = {'.csv': 'csv', '.json': 'json', '.xlsx': 'excel'}
                    format = format_map.get(suffix)

                    if not format:
                        continue

                    result = agent.ingest_file(
                        file_path=file,
                        format=format,
                        entity_type="supplier"
                    )

                    total_records += result.statistics.total_records
                    successful += result.statistics.successful

                    progress.update(
                        task,
                        completed=40 + (60 * (i + 1) // len(files)),
                        description=f"[cyan]Processing {file.name}..."
                    )

                progress.update(task, completed=100, description="[green]Intake complete")

                return {
                    "total_records": total_records,
                    "successful": successful,
                    "failed": total_records - successful,
                    "files_processed": len(files)
                }

        return {"total_records": 0, "successful": 0, "failed": 0}

    def _stage_calculate(
        self,
        categories: List[int],
        enable_llm: bool,
        enable_monte_carlo: bool
    ) -> Dict[str, Any]:
        """Execute calculation stage."""
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            console=console
        ) as progress:
            task = progress.add_task("[cyan]Calculating emissions...", total=len(categories))

            results = {
                "categories": {},
                "total_emissions": 0.0,
                "total_uncertainty": 0.0
            }

            for i, category in enumerate(categories):
                progress.update(
                    task,
                    completed=i,
                    description=f"[cyan]Calculating Category {category}..."
                )

                # Mock calculation (in production: use actual calculator)
                import random
                emissions = random.uniform(500, 5000)
                uncertainty = random.uniform(15, 35)

                results["categories"][category] = {
                    "emissions_tco2e": emissions,
                    "uncertainty_pct": uncertainty,
                    "data_quality_tier": deterministic_random().choice([1, 2, 3]),
                    "llm_enhanced": enable_llm,
                    "monte_carlo": enable_monte_carlo
                }

                results["total_emissions"] += emissions

                progress.advance(task)

            progress.update(task, description="[green]Calculations complete")

            # Calculate average uncertainty
            results["total_uncertainty"] = sum(
                c["uncertainty_pct"] for c in results["categories"].values()
            ) / len(results["categories"])

        # Display calculation summary
        calc_table = Table(
            title="Calculation Results",
            box=box.ROUNDED,
            show_header=True,
            header_style="bold cyan"
        )

        calc_table.add_column("Category", style="cyan", justify="center")
        calc_table.add_column("Emissions (tCO2e)", justify="right", style="green")
        calc_table.add_column("Uncertainty", justify="right", style="yellow")
        calc_table.add_column("Tier", justify="center")

        for cat, data in sorted(results["categories"].items()):
            calc_table.add_row(
                f"Cat {cat}",
                f"{data['emissions_tco2e']:,.2f}",
                f"Â±{data['uncertainty_pct']:.1f}%",
                str(data['data_quality_tier'])
            )

        calc_table.add_row(
            "[bold]Total[/bold]",
            f"[bold green]{results['total_emissions']:,.2f}[/bold green]",
            f"[bold yellow]Â±{results['total_uncertainty']:.1f}%[/bold yellow]",
            "-"
        )

        console.print()
        console.print(calc_table)

        return results

    def _stage_analyze(self, calc_results: Dict[str, Any]) -> Dict[str, Any]:
        """Execute analysis stage."""
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("[cyan]Performing hotspot analysis...", total=None)

            # Mock analysis
            import time
            time.sleep(0.5)

            # Identify hotspots (top 3 categories)
            categories = calc_results["categories"]
            sorted_cats = sorted(
                categories.items(),
                key=lambda x: x[1]["emissions_tco2e"],
                reverse=True
            )

            hotspots = []
            for i, (cat, data) in enumerate(sorted_cats[:3]):
                pct_of_total = (data["emissions_tco2e"] / calc_results["total_emissions"]) * 100
                hotspots.append({
                    "category": cat,
                    "emissions": data["emissions_tco2e"],
                    "percentage": pct_of_total,
                    "rank": i + 1
                })

            progress.update(task, completed=True, description="[green]Analysis complete")

        # Display hotspots
        console.print()
        hotspot_table = Table(
            title="Emission Hotspots",
            box=box.ROUNDED,
            show_header=True,
            header_style="bold cyan"
        )

        hotspot_table.add_column("Rank", justify="center", style="yellow")
        hotspot_table.add_column("Category", style="cyan")
        hotspot_table.add_column("Emissions (tCO2e)", justify="right", style="green")
        hotspot_table.add_column("% of Total", justify="right", style="yellow")

        for hotspot in hotspots:
            rank_emoji = ["ðŸ¥‡", "ðŸ¥ˆ", "ðŸ¥‰"][hotspot["rank"] - 1]
            hotspot_table.add_row(
                f"{rank_emoji} #{hotspot['rank']}",
                f"Category {hotspot['category']}",
                f"{hotspot['emissions']:,.2f}",
                f"{hotspot['percentage']:.1f}%"
            )

        console.print(hotspot_table)

        return {
            "hotspots": hotspots,
            "pareto_80_pct_categories": [h["category"] for h in hotspots],
            "recommendations": [
                "Focus on top 3 categories for maximum impact",
                "Engage high-emission suppliers for data quality improvement",
                "Consider supplier switching scenarios for hotspot categories"
            ]
        }

    def _stage_report(
        self,
        calc_results: Dict[str, Any],
        analysis_results: Dict[str, Any],
        output_dir: Path,
        report_format: str
    ) -> Dict[str, Any]:
        """Execute reporting stage."""
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task(f"[cyan]Generating {report_format} report...", total=None)

            # Create output directory
            output_dir.mkdir(parents=True, exist_ok=True)

            # Generate report file
            report_name = f"scope3_report_{self.run_id}.json"
            report_path = output_dir / report_name

            report_data = {
                "run_id": self.run_id,
                "generated_at": DeterministicClock.utcnow().isoformat(),
                "format": report_format,
                "calculation_results": calc_results,
                "analysis_results": analysis_results,
                "metadata": {
                    "tenant_id": self.tenant_id,
                    "categories_included": list(calc_results["categories"].keys()),
                    "total_emissions_tco2e": calc_results["total_emissions"],
                    "average_uncertainty_pct": calc_results["total_uncertainty"]
                }
            }

            with open(report_path, 'w') as f:
                json.dump(report_data, f, indent=2, default=str)

            progress.update(task, completed=True, description="[green]Report generated")

        console.print()
        console.print(
            Panel(
                f"[green]Report generated successfully![/green]\n\n"
                f"[cyan]Format:[/cyan] {report_format}\n"
                f"[cyan]Location:[/cyan] {report_path}\n"
                f"[cyan]Size:[/cyan] {report_path.stat().st_size:,} bytes",
                title="[bold green]Report Complete[/bold green]",
                border_style="green"
            )
        )

        return {
            "report_path": report_path,
            "format": report_format
        }


# ============================================================================
# RUN PIPELINE COMMAND
# ============================================================================

@pipeline_app.command("run")
def run_pipeline(
    input: Path = typer.Option(
        ...,
        "--input",
        "-i",
        help="Input file or directory",
        exists=True
    ),
    output: Path = typer.Option(
        ...,
        "--output",
        "-o",
        help="Output directory for results"
    ),
    categories: str = typer.Option(
        "all",
        "--categories",
        "-cat",
        help="Categories to calculate (comma-separated or 'all')"
    ),
    report_format: str = typer.Option(
        "ghg-protocol",
        "--format",
        "-f",
        help="Report format (ghg-protocol, cdp, tcfd, csrd)"
    ),
    enable_llm: bool = typer.Option(
        True,
        "--llm/--no-llm",
        help="Enable/disable LLM intelligence"
    ),
    enable_monte_carlo: bool = typer.Option(
        True,
        "--mc/--no-mc",
        help="Enable/disable Monte Carlo uncertainty"
    ),
    save_results: bool = typer.Option(
        True,
        "--save/--no-save",
        help="Save intermediate results"
    )
):
    """
    Run complete Scope 3 emissions pipeline.

    Executes: intake â†’ calculate â†’ analyze â†’ report

    Examples:

      # Run all categories
      vcci pipeline run --input data/ --output results/ --categories all

      # Run specific categories
      vcci pipeline run --input suppliers.csv --output results/ --categories 1,4,15

      # Custom report format
      vcci pipeline run --input data/ --output results/ --format cdp

      # Disable LLM for faster processing
      vcci pipeline run --input data/ --output results/ --no-llm
    """
    console.print()

    if not AGENTS_AVAILABLE:
        console.print(
            "[red]Error:[/red] Required agents not available. "
            "Please ensure all agent modules are properly installed."
        )
        sys.exit(1)

    # Parse categories
    if categories.lower() == "all":
        category_list = list(range(1, 16))
    else:
        try:
            category_list = [int(c.strip()) for c in categories.split(",")]
        except ValueError:
            console.print("[red]Error:[/red] Invalid category format. Use comma-separated numbers or 'all'")
            sys.exit(1)

    # Display pipeline configuration
    console.print(
        Panel(
            f"[cyan]Run ID:[/cyan] RUN-{DeterministicClock.utcnow().strftime('%Y%m%d%H%M%S')}\n"
            f"[cyan]Input:[/cyan] {input}\n"
            f"[cyan]Output:[/cyan] {output}\n"
            f"[cyan]Categories:[/cyan] {', '.join(map(str, category_list))}\n"
            f"[cyan]Report Format:[/cyan] {report_format}\n"
            f"[cyan]LLM Enhancement:[/cyan] {'Enabled' if enable_llm else 'Disabled'}\n"
            f"[cyan]Monte Carlo:[/cyan] {'Enabled' if enable_monte_carlo else 'Disabled'}",
            title="[bold cyan]Pipeline Configuration[/bold cyan]",
            border_style="cyan"
        )
    )

    try:
        # Execute pipeline
        executor = PipelineExecutor()

        start_time = DeterministicClock.utcnow()

        pipeline_results = executor.run(
            input_path=input,
            output_dir=output,
            categories=category_list,
            enable_llm=enable_llm,
            enable_monte_carlo=enable_monte_carlo,
            report_format=report_format
        )

        end_time = DeterministicClock.utcnow()
        duration = (end_time - start_time).total_seconds()

        # Final summary
        console.print()
        console.print("=" * 60)
        console.print()

        summary_tree = Tree("[bold green]Pipeline Execution Complete[/bold green]")

        # Add stages
        intake_branch = summary_tree.add("[cyan]Stage 1: Intake[/cyan]")
        intake_data = pipeline_results["stages"]["intake"]
        intake_branch.add(f"[green]âœ“[/green] Processed {intake_data['records_processed']} records")
        intake_branch.add(f"[green]âœ“[/green] {intake_data['records_successful']} successful")

        calc_branch = summary_tree.add("[cyan]Stage 2: Calculate[/cyan]")
        calc_data = pipeline_results["stages"]["calculate"]
        calc_branch.add(f"[green]âœ“[/green] {calc_data['categories_processed']} categories calculated")
        calc_branch.add(f"[green]âœ“[/green] Total: {calc_data['total_emissions']:,.2f} tCO2e")

        analyze_branch = summary_tree.add("[cyan]Stage 3: Analyze[/cyan]")
        analyze_data = pipeline_results["stages"]["analyze"]
        analyze_branch.add(f"[green]âœ“[/green] {analyze_data['hotspots_identified']} hotspots identified")

        report_branch = summary_tree.add("[cyan]Stage 4: Report[/cyan]")
        report_data = pipeline_results["stages"]["report"]
        report_branch.add(f"[green]âœ“[/green] Report saved: {report_data['report_path']}")

        console.print(summary_tree)

        console.print()
        console.print(
            Panel(
                f"[green]Pipeline completed successfully![/green]\n\n"
                f"[cyan]Run ID:[/cyan] {pipeline_results['run_id']}\n"
                f"[cyan]Duration:[/cyan] {duration:.2f} seconds\n"
                f"[cyan]Status:[/cyan] {pipeline_results['overall_status'].upper()}\n\n"
                f"[yellow]Results Location:[/yellow]\n"
                f"  {output}",
                title="[bold green]Success[/bold green]",
                border_style="green"
            )
        )

    except Exception as e:
        console.print()
        console.print(
            Panel(
                f"[red]Pipeline execution failed![/red]\n\n"
                f"[yellow]Error:[/yellow] {str(e)}\n\n"
                f"Check logs for detailed error information.",
                title="[bold red]Error[/bold red]",
                border_style="red"
            )
        )
        sys.exit(1)

    console.print()


# ============================================================================
# PIPELINE STATUS COMMAND
# ============================================================================

@pipeline_app.command("status")
def pipeline_status(
    run_id: Optional[str] = typer.Option(
        None,
        "--run-id",
        "-r",
        help="Show status for specific pipeline run"
    )
):
    """
    Show pipeline execution status.

    Displays current or historical pipeline run information.

    Examples:

      # Show recent pipeline runs
      vcci pipeline status

      # Show specific run
      vcci pipeline status --run-id RUN-20251108120000
    """
    console.print()

    if run_id:
        # Show specific run status (would query from storage)
        console.print(
            Panel(
                f"[cyan]Run ID:[/cyan] {run_id}\n"
                f"[cyan]Status:[/cyan] [green]Completed[/green]\n"
                f"[cyan]Started:[/cyan] 2025-11-08 12:00:00\n"
                f"[cyan]Completed:[/cyan] 2025-11-08 12:05:32\n"
                f"[cyan]Duration:[/cyan] 5 minutes 32 seconds\n\n"
                f"[yellow]Stages:[/yellow]\n"
                f"  [green]âœ“[/green] Intake: 1,250 records\n"
                f"  [green]âœ“[/green] Calculate: 15 categories\n"
                f"  [green]âœ“[/green] Analyze: 3 hotspots\n"
                f"  [green]âœ“[/green] Report: Generated",
                title=f"[bold cyan]Pipeline Run: {run_id}[/bold cyan]",
                border_style="cyan"
            )
        )
    else:
        # Show recent runs
        runs_table = Table(
            title="Recent Pipeline Runs",
            box=box.ROUNDED,
            show_header=True,
            header_style="bold cyan"
        )

        runs_table.add_column("Run ID", style="cyan")
        runs_table.add_column("Status", justify="center")
        runs_table.add_column("Started", style="yellow")
        runs_table.add_column("Duration")
        runs_table.add_column("Categories", justify="right")

        # Mock data
        runs_table.add_row(
            "RUN-20251108120000",
            "[green]Completed[/green]",
            "2025-11-08 12:00",
            "5m 32s",
            "15"
        )
        runs_table.add_row(
            "RUN-20251107093000",
            "[green]Completed[/green]",
            "2025-11-07 09:30",
            "8m 15s",
            "15"
        )
        runs_table.add_row(
            "RUN-20251106154500",
            "[green]Completed[/green]",
            "2025-11-06 15:45",
            "6m 47s",
            "3"
        )

        console.print(runs_table)

    console.print()


# Export the app
__all__ = ["pipeline_app"]
